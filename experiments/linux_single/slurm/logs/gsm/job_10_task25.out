Using persona diversity with 3 different personas
============================================================
GSM Task - Multiagent Debate
============================================================
Model: mistralai/Mistral-7B-Instruct-v0.3
Persona diversity mode:
  Agent 1: a Kantian deontologist who judges all actions strictly by th...
  Agent 2: a deep-sea volcanologist focused on extremes of pressure, he...
  Agent 3: an expert chess grandmaster who analyzes all moves based on ...
Agents: 3
Rounds: 3
Problems: 20
Dataset: /home/ch269957/projects/slm_multiagent_debate/data/gsm8k/test.jsonl
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================

--- Problem 1/20, Round 1, Agent 1/3 ---
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:17:09 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
Using persona diversity with 3 different personas
============================================================
GSM Task - Multiagent Debate
============================================================
Model: mistralai/Mistral-7B-Instruct-v0.3
Persona diversity mode:
  Agent 1: a Kantian deontologist who judges all actions strictly by th...
  Agent 2: a deep-sea volcanologist focused on extremes of pressure, he...
  Agent 3: an expert chess grandmaster who analyzes all moves based on ...
Agents: 3
Rounds: 3
Problems: 20
Dataset: /home/ch269957/projects/slm_multiagent_debate/data/gsm8k/test.jsonl
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================

--- Problem 1/20, Round 1, Agent 1/3 ---
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:17:09 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
INFO 12-04 14:17:10 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:17:10 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:17:10 [model.py:1745] Using max model len 32768
INFO 12-04 14:17:10 [model.py:1745] Using max model len 32768
INFO 12-04 14:17:13 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:17:13 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/transformers_utils/tokenizer.py:287: FutureWarning: It is strongly recommended to run mistral models with `--tokenizer-mode "mistral"` to ensure correct encoding and decoding.
  return get_tokenizer(
/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/transformers_utils/tokenizer.py:287: FutureWarning: It is strongly recommended to run mistral models with `--tokenizer-mode "mistral"` to ensure correct encoding and decoding.
  return get_tokenizer(
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:17:55 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:17:55 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:18:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:44267 backend=nccl
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:18:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:47775 backend=nccl
[W1204 14:18:02.421824034 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:44267 (errno: 97 - Address family not supported by protocol).
[W1204 14:18:02.421824124 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:47775 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:18:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:18:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:18:03 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:18:03 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:18:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:18:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:18:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:18:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=244116)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=244117)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=244117)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:17<00:34, 17.42s/it]
[1;36m(EngineCore_DP0 pid=244116)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:17<00:35, 17.57s/it]
[1;36m(EngineCore_DP0 pid=244117)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:35<00:17, 17.75s/it]
[1;36m(EngineCore_DP0 pid=244116)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:35<00:17, 17.81s/it]
[1;36m(EngineCore_DP0 pid=244117)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:52<00:00, 17.45s/it]
[1;36m(EngineCore_DP0 pid=244116)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:52<00:00, 17.48s/it]
[1;36m(EngineCore_DP0 pid=244117)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:52<00:00, 17.50s/it]
[1;36m(EngineCore_DP0 pid=244116)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:52<00:00, 17.55s/it]
[1;36m(EngineCore_DP0 pid=244116)[0;0m 
[1;36m(EngineCore_DP0 pid=244117)[0;0m 
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:19:00 [default_loader.py:314] Loading weights took 52.83 seconds
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:19:00 [default_loader.py:314] Loading weights took 52.78 seconds
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:19:01 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 56.320989 seconds
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:19:01 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 56.403179 seconds
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:19:31 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:19:31 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:19:31 [backends.py:647] Dynamo bytecode transform time: 30.27 s
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:19:31 [backends.py:647] Dynamo bytecode transform time: 30.33 s
[1;36m(EngineCore_DP0 pid=244116)[0;0m [rank0]:W1204 14:19:33.089000 244116 site-packages/torch/_inductor/triton_bundler.py:396] [0/0] Directory /tmp/torchinductor_ch269957/triton/0/tmp.ea3582ee-9628-4e83-b281-a1bcf28b2f34 is not empty - skipping!
[1;36m(EngineCore_DP0 pid=244116)[0;0m [rank0]:W1204 14:19:33.092000 244116 site-packages/torch/_inductor/triton_bundler.py:396] [0/0] Directory /tmp/torchinductor_ch269957/triton/0/tmp.738c6cb5-ce5a-4f2a-8a63-396cfd3c1adf is not empty - skipping!
[1;36m(EngineCore_DP0 pid=244116)[0;0m [rank0]:W1204 14:19:33.095000 244116 site-packages/torch/_inductor/triton_bundler.py:396] [0/0] Directory /tmp/torchinductor_ch269957/triton/0/tmp.1e888523-5bed-4ffb-8694-158c427a02b1 is not empty - skipping!
[1;36m(EngineCore_DP0 pid=244116)[0;0m [rank0]:W1204 14:19:33.838000 244116 site-packages/torch/_inductor/triton_bundler.py:396] [0/0] Directory /tmp/torchinductor_ch269957/triton/0/tmp.026a6d0d-bb02-41b2-b932-f38eb31fb05d is not empty - skipping!
[1;36m(EngineCore_DP0 pid=244116)[0;0m [rank0]:W1204 14:19:33.841000 244116 site-packages/torch/_inductor/triton_bundler.py:396] [0/0] Directory /tmp/torchinductor_ch269957/triton/0/tmp.8c1fd665-8ee4-4044-837a-059c43482b85 is not empty - skipping!
[1;36m(EngineCore_DP0 pid=244116)[0;0m [rank0]:W1204 14:19:40.779000 244116 site-packages/torch/_inductor/triton_bundler.py:396] [0/0] Directory /tmp/torchinductor_ch269957/triton/0/tmp.33cf3caf-7341-4f1a-8083-34d066f9ca37 is not empty - skipping!
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:19:40 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.782 s
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:19:40 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.783 s
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:19:43 [monitor.py:34] torch.compile takes 38.05 s in total
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:19:43 [monitor.py:34] torch.compile takes 38.11 s in total
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:19:46 [gpu_worker.py:359] Available KV cache memory: 10.77 GiB
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:19:46 [gpu_worker.py:359] Available KV cache memory: 11.94 GiB
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:19:47 [kv_cache_utils.py:1229] GPU KV cache size: 88,192 tokens
[1;36m(EngineCore_DP0 pid=244117)[0;0m INFO 12-04 14:19:47 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.69x
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:19:47 [kv_cache_utils.py:1229] GPU KV cache size: 97,792 tokens
[1;36m(EngineCore_DP0 pid=244116)[0;0m INFO 12-04 14:19:47 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.98x
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842]              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m ERROR 12-04 14:19:47 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 144.00 MiB is free. Process 244117 has 24.91 GiB memory in use. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.80 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=244116)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=244116)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=244116)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=244116)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=244116)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=244116)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244116)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=244116)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=244116)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=244116)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=244116)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244116)[0;0m     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=244116)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=244116)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=244116)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244116)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244116)[0;0m     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=244116)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244116)[0;0m     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=244116)[0;0m     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=244116)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=244116)[0;0m     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=244116)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=244116)[0;0m     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=244116)[0;0m              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244116)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 144.00 MiB is free. Process 244117 has 24.91 GiB memory in use. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.80 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=244117)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|â–         | 1/51 [00:00<00:06,  7.60it/s]
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     self.collective_rpc("compile_or_warm_up_model")
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 429, in compile_or_warm_up_model
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     cuda_graph_memory_bytes = self.model_runner.capture_model()
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4201, in capture_model
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     self._capture_cudagraphs(
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4298, in _capture_cudagraphs
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     self._dummy_run(
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 399, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 152, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return self.forward(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 430, in forward
[1;36m(EngineCore_DP0 pid=244117)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     def forward(
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return fn(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/caching.py", line 53, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return self.optimized_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 837, in call_wrapped
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return self._wrapped_call(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 413, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     raise e
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 400, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "<eval_with_key>.66", line 209, in forward
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = None
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/piecewise_backend.py", line 99, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return self.compiled_graph_for_general_shape(*args)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 268, in compiled_graph_wrapper
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     graph_output = inductor_compiled_graph(*args)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return self._compiled_fn(*args)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 184, in <lambda>
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return CompiledArtifact(lambda *args: compiled_fn(list(args)), None)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]                                           ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     all_outs = call_func_at_runtime_with_args(
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     out = normalize_as_list(f(args))
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]                             ^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return compiled_fn(runtime_args)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/output_code.py", line 613, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     return self.current_callable(inputs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/utils.py", line 2962, in run
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     out = model(new_inputs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]           ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]   File "/tmp/torchinductor_ch269957/fa/cfabegaap63l46e24kdpwi6woqi73dms2wgztmau6s6lpfinbsne.py", line 906, in call
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]     buf3 = empty_strided_cuda((s72, 28672), (28672, 1), torch.bfloat16)
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m ERROR 12-04 14:19:48 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 16.00 MiB is free. Including non-PyTorch memory, this process has 25.04 GiB memory in use. Process 244116 has 19.32 GiB memory in use. Of the allocated memory 24.45 GiB is allocated by PyTorch, with 75.88 MiB allocated in private pools (e.g., CUDA Graphs), and 69.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=244117)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=244117)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=244117)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=244117)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=244117)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=244117)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=244117)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244117)[0;0m     self.collective_rpc("compile_or_warm_up_model")
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=244117)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 429, in compile_or_warm_up_model
[1;36m(EngineCore_DP0 pid=244117)[0;0m     cuda_graph_memory_bytes = self.model_runner.capture_model()
[1;36m(EngineCore_DP0 pid=244117)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4201, in capture_model
[1;36m(EngineCore_DP0 pid=244117)[0;0m     self._capture_cudagraphs(
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4298, in _capture_cudagraphs
[1;36m(EngineCore_DP0 pid=244117)[0;0m     self._dummy_run(
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=244117)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=244117)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=244117)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=244117)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 399, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 152, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return self.forward(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 430, in forward
[1;36m(EngineCore_DP0 pid=244117)[0;0m     def forward(
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return fn(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/caching.py", line 53, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return self.optimized_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 837, in call_wrapped
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return self._wrapped_call(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 413, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 400, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "<eval_with_key>.66", line 209, in forward
[1;36m(EngineCore_DP0 pid=244117)[0;0m     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = None
[1;36m(EngineCore_DP0 pid=244117)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/piecewise_backend.py", line 99, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return self.compiled_graph_for_general_shape(*args)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 268, in compiled_graph_wrapper
[1;36m(EngineCore_DP0 pid=244117)[0;0m     graph_output = inductor_compiled_graph(*args)
[1;36m(EngineCore_DP0 pid=244117)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return self._compiled_fn(*args)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 184, in <lambda>
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return CompiledArtifact(lambda *args: compiled_fn(list(args)), None)
[1;36m(EngineCore_DP0 pid=244117)[0;0m                                           ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
[1;36m(EngineCore_DP0 pid=244117)[0;0m     all_outs = call_func_at_runtime_with_args(
[1;36m(EngineCore_DP0 pid=244117)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
[1;36m(EngineCore_DP0 pid=244117)[0;0m     out = normalize_as_list(f(args))
[1;36m(EngineCore_DP0 pid=244117)[0;0m                             ^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return compiled_fn(runtime_args)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/output_code.py", line 613, in __call__
[1;36m(EngineCore_DP0 pid=244117)[0;0m     return self.current_callable(inputs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/utils.py", line 2962, in run
[1;36m(EngineCore_DP0 pid=244117)[0;0m     out = model(new_inputs)
[1;36m(EngineCore_DP0 pid=244117)[0;0m           ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m   File "/tmp/torchinductor_ch269957/fa/cfabegaap63l46e24kdpwi6woqi73dms2wgztmau6s6lpfinbsne.py", line 906, in call
[1;36m(EngineCore_DP0 pid=244117)[0;0m     buf3 = empty_strided_cuda((s72, 28672), (28672, 1), torch.bfloat16)
[1;36m(EngineCore_DP0 pid=244117)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244117)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 16.00 MiB is free. Including non-PyTorch memory, this process has 25.04 GiB memory in use. Process 244116 has 19.32 GiB memory in use. Of the allocated memory 24.45 GiB is allocated by PyTorch, with 75.88 MiB allocated in private pools (e.g., CUDA Graphs), and 69.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:19:48.194511719 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:19:49.993749404 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:20:15 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:20:15 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
INFO 12-04 14:20:15 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:20:15 [model.py:1745] Using max model len 32768
INFO 12-04 14:20:15 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:20:15 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:20:15 [model.py:1745] Using max model len 32768
INFO 12-04 14:20:15 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:21:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:21:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:21:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:51903 backend=nccl
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:21:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:44729 backend=nccl
[W1204 14:21:06.076937829 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:44729 (errno: 97 - Address family not supported by protocol).
[W1204 14:21:06.076937896 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:51903 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:21:06 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:21:06 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:21:06 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:21:06 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:21:08 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:21:08 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:21:08 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:21:08 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=244616)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=244619)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=244616)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:24<00:48, 24.20s/it]
[1;36m(EngineCore_DP0 pid=244619)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:24<00:48, 24.08s/it]
[1;36m(EngineCore_DP0 pid=244619)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:49<00:24, 24.72s/it]
[1;36m(EngineCore_DP0 pid=244616)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:49<00:24, 24.77s/it]
[1;36m(EngineCore_DP0 pid=244619)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:12<00:00, 24.09s/it]
[1;36m(EngineCore_DP0 pid=244616)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:12<00:00, 24.12s/it]
[1;36m(EngineCore_DP0 pid=244619)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:12<00:00, 24.20s/it]
[1;36m(EngineCore_DP0 pid=244616)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:12<00:00, 24.24s/it]
[1;36m(EngineCore_DP0 pid=244616)[0;0m 
[1;36m(EngineCore_DP0 pid=244619)[0;0m 
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:22:22 [default_loader.py:314] Loading weights took 72.83 seconds
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:22:22 [default_loader.py:314] Loading weights took 72.95 seconds
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:22:23 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 75.206228 seconds
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:22:23 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 75.206838 seconds
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:22:45 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:22:45 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:22:45 [backends.py:647] Dynamo bytecode transform time: 22.21 s
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:22:45 [backends.py:647] Dynamo bytecode transform time: 22.21 s
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:22:54 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.540 s
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:22:54 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.540 s
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:22:57 [monitor.py:34] torch.compile takes 29.75 s in total
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:22:57 [monitor.py:34] torch.compile takes 29.75 s in total
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:23:00 [gpu_worker.py:359] Available KV cache memory: 10.97 GiB
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:23:00 [gpu_worker.py:359] Available KV cache memory: 11.94 GiB
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:23:00 [kv_cache_utils.py:1229] GPU KV cache size: 89,856 tokens
[1;36m(EngineCore_DP0 pid=244616)[0;0m INFO 12-04 14:23:00 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.74x
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:23:00 [kv_cache_utils.py:1229] GPU KV cache size: 97,792 tokens
[1;36m(EngineCore_DP0 pid=244619)[0;0m INFO 12-04 14:23:00 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.98x
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842]              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m ERROR 12-04 14:23:01 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 334.00 MiB is free. Process 244616 has 25.10 GiB memory in use. Including non-PyTorch memory, this process has 18.95 GiB memory in use. Of the allocated memory 18.43 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=244619)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=244619)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=244619)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=244619)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=244619)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=244619)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244619)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=244619)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=244619)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=244619)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=244619)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244619)[0;0m     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=244619)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=244619)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=244619)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244619)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244619)[0;0m     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=244619)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244619)[0;0m     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=244619)[0;0m     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=244619)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=244619)[0;0m     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=244619)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=244619)[0;0m     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=244619)[0;0m              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244619)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 334.00 MiB is free. Process 244616 has 25.10 GiB memory in use. Including non-PyTorch memory, this process has 18.95 GiB memory in use. Of the allocated memory 18.43 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:23:02.152181148 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(EngineCore_DP0 pid=244616)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|â–         | 1/51 [00:00<00:05,  9.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–Œ         | 3/51 [00:00<00:04, 11.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–‰         | 5/51 [00:00<00:04, 11.17it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|â–ˆâ–Ž        | 7/51 [00:00<00:03, 11.31it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 9/51 [00:00<00:03, 11.62it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 11/51 [00:00<00:03, 11.76it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 13/51 [00:01<00:03, 12.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|â–ˆâ–ˆâ–‰       | 15/51 [00:01<00:02, 12.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 17/51 [00:01<00:03, 11.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 19/51 [00:01<00:02, 11.46it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 21/51 [00:01<00:02, 11.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/51 [00:01<00:02, 12.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 25/51 [00:02<00:02, 12.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 27/51 [00:02<00:01, 12.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 29/51 [00:02<00:01, 13.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 31/51 [00:02<00:01, 14.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 33/51 [00:02<00:01, 14.71it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 35/51 [00:02<00:01, 15.22it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 37/51 [00:02<00:00, 15.53it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 39/51 [00:03<00:00, 14.01it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 41/51 [00:03<00:00, 14.43it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/51 [00:03<00:00, 12.57it/s]
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     self.collective_rpc("compile_or_warm_up_model")
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 429, in compile_or_warm_up_model
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     cuda_graph_memory_bytes = self.model_runner.capture_model()
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4201, in capture_model
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     self._capture_cudagraphs(
[1;36m(EngineCore_DP0 pid=244616)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4308, in _capture_cudagraphs
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     self._dummy_run(
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3898, in _dummy_run
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]     logit_indices_device = torch.from_numpy(logit_indices).to(
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m ERROR 12-04 14:23:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 2.00 MiB is free. Including non-PyTorch memory, this process has 25.43 GiB memory in use. Process 244619 has 18.95 GiB memory in use. Of the allocated memory 24.68 GiB is allocated by PyTorch, with 81.88 MiB allocated in private pools (e.g., CUDA Graphs), and 16.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=244616)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=244616)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=244616)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=244616)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=244616)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244616)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=244616)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=244616)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=244616)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=244616)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
[1;36m(EngineCore_DP0 pid=244616)[0;0m     self.collective_rpc("compile_or_warm_up_model")
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=244616)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=244616)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=244616)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244616)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 429, in compile_or_warm_up_model
[1;36m(EngineCore_DP0 pid=244616)[0;0m     cuda_graph_memory_bytes = self.model_runner.capture_model()
[1;36m(EngineCore_DP0 pid=244616)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4201, in capture_model
[1;36m(EngineCore_DP0 pid=244616)[0;0m     self._capture_cudagraphs(
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4308, in _capture_cudagraphs
[1;36m(EngineCore_DP0 pid=244616)[0;0m     self._dummy_run(
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=244616)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=244616)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3898, in _dummy_run
[1;36m(EngineCore_DP0 pid=244616)[0;0m     logit_indices_device = torch.from_numpy(logit_indices).to(
[1;36m(EngineCore_DP0 pid=244616)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=244616)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 2.00 MiB is free. Including non-PyTorch memory, this process has 25.43 GiB memory in use. Process 244619 has 18.95 GiB memory in use. Of the allocated memory 24.68 GiB is allocated by PyTorch, with 81.88 MiB allocated in private pools (e.g., CUDA Graphs), and 16.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:23:05.722847460 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:23:29 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:23:29 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
INFO 12-04 14:23:29 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:23:29 [model.py:1745] Using max model len 32768
INFO 12-04 14:23:29 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:23:29 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:23:29 [model.py:1745] Using max model len 32768
INFO 12-04 14:23:29 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:24:25 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:24:25 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:24:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:43593 backend=nccl
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:24:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:36435 backend=nccl
[W1204 14:24:30.575672435 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:36435 (errno: 97 - Address family not supported by protocol).
[W1204 14:24:30.575996477 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:43593 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:24:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:24:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:24:31 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:24:31 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:24:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:24:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:24:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:24:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=245139)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=245140)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=245140)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:25<00:51, 25.92s/it]
[1;36m(EngineCore_DP0 pid=245139)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:26<00:52, 26.03s/it]
[1;36m(EngineCore_DP0 pid=245140)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:50<00:25, 25.17s/it]
[1;36m(EngineCore_DP0 pid=245139)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:50<00:25, 25.21s/it]
[1;36m(EngineCore_DP0 pid=245140)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:13<00:00, 24.21s/it]
[1;36m(EngineCore_DP0 pid=245139)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:13<00:00, 24.23s/it]
[1;36m(EngineCore_DP0 pid=245140)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:13<00:00, 24.54s/it]
[1;36m(EngineCore_DP0 pid=245140)[0;0m 
[1;36m(EngineCore_DP0 pid=245139)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:13<00:00, 24.58s/it]
[1;36m(EngineCore_DP0 pid=245139)[0;0m 
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:25:48 [default_loader.py:314] Loading weights took 73.87 seconds
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:25:48 [default_loader.py:314] Loading weights took 73.98 seconds
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:25:48 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 76.189169 seconds
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:25:48 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 76.183096 seconds
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:26:09 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:26:09 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:26:09 [backends.py:647] Dynamo bytecode transform time: 20.06 s
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:26:09 [backends.py:647] Dynamo bytecode transform time: 20.06 s
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:26:18 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.629 s
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:26:18 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.629 s
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:26:21 [monitor.py:34] torch.compile takes 27.69 s in total
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:26:21 [monitor.py:34] torch.compile takes 27.69 s in total
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:26:23 [gpu_worker.py:359] Available KV cache memory: 11.50 GiB
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:26:23 [gpu_worker.py:359] Available KV cache memory: 11.94 GiB
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:26:24 [kv_cache_utils.py:1229] GPU KV cache size: 94,208 tokens
[1;36m(EngineCore_DP0 pid=245140)[0;0m INFO 12-04 14:26:24 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.88x
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:26:24 [kv_cache_utils.py:1229] GPU KV cache size: 97,808 tokens
[1;36m(EngineCore_DP0 pid=245139)[0;0m INFO 12-04 14:26:24 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.98x
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842]              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m ERROR 12-04 14:26:24 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 368.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 20.00 MiB is free. Including non-PyTorch memory, this process has 22.01 GiB memory in use. Process 245139 has 22.35 GiB memory in use. Of the allocated memory 21.49 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=245140)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842]              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m ERROR 12-04 14:26:24 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 20.00 MiB is free. Process 245140 has 22.01 GiB memory in use. Including non-PyTorch memory, this process has 22.35 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 45.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=245139)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=245140)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245139)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=245140)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=245140)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=245140)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=245139)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=245139)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=245139)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245139)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245139)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245140)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245140)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245140)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245140)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245140)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245139)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245139)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245139)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245140)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245140)[0;0m     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245140)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245140)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245139)[0;0m     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245139)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245139)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245139)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245140)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245140)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245140)[0;0m     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=245140)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245139)[0;0m     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=245139)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245139)[0;0m     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245140)[0;0m     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=245140)[0;0m     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=245139)[0;0m     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=245139)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245140)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245140)[0;0m     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245140)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245139)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245139)[0;0m     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=245140)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245140)[0;0m     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=245140)[0;0m              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245139)[0;0m              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245140)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 368.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 20.00 MiB is free. Including non-PyTorch memory, this process has 22.01 GiB memory in use. Process 245139 has 22.35 GiB memory in use. Of the allocated memory 21.49 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=245139)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 20.00 MiB is free. Process 245140 has 22.01 GiB memory in use. Including non-PyTorch memory, this process has 22.35 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 45.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:26:25.495166243 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:26:25.496200669 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:51 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:51 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
INFO 12-04 14:26:51 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:26:51 [model.py:1745] Using max model len 32768
INFO 12-04 14:26:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:26:51 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:26:51 [model.py:1745] Using max model len 32768
INFO 12-04 14:26:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:27:46 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:27:46 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:27:52 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:40757 backend=nccl
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:27:52 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:46439 backend=nccl
[W1204 14:27:52.014488634 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:46439 (errno: 97 - Address family not supported by protocol).
[W1204 14:27:52.014705285 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:40757 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:27:52 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:27:52 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:27:52 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:27:52 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:27:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:27:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:27:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:27:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=245420)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=245419)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=245419)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:23<00:47, 23.72s/it]
[1;36m(EngineCore_DP0 pid=245420)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:23<00:47, 23.85s/it]
[1;36m(EngineCore_DP0 pid=245419)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:48<00:24, 24.17s/it]
[1;36m(EngineCore_DP0 pid=245420)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:48<00:24, 24.22s/it]
[1;36m(EngineCore_DP0 pid=245419)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:10<00:00, 23.48s/it]
[1;36m(EngineCore_DP0 pid=245420)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:10<00:00, 23.51s/it]
[1;36m(EngineCore_DP0 pid=245419)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:10<00:00, 23.62s/it]
[1;36m(EngineCore_DP0 pid=245419)[0;0m 
[1;36m(EngineCore_DP0 pid=245420)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:10<00:00, 23.66s/it]
[1;36m(EngineCore_DP0 pid=245420)[0;0m 
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:29:06 [default_loader.py:314] Loading weights took 71.11 seconds
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:29:06 [default_loader.py:314] Loading weights took 71.24 seconds
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:29:07 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 73.672766 seconds
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:29:07 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 73.671040 seconds
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:29:29 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:29:29 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:29:29 [backends.py:647] Dynamo bytecode transform time: 21.76 s
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:29:29 [backends.py:647] Dynamo bytecode transform time: 21.76 s
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:29:38 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.639 s
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:29:38 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.639 s
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:29:41 [monitor.py:34] torch.compile takes 29.40 s in total
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:29:41 [monitor.py:34] torch.compile takes 29.40 s in total
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:29:44 [gpu_worker.py:359] Available KV cache memory: 10.77 GiB
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:29:44 [gpu_worker.py:359] Available KV cache memory: 11.94 GiB
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:29:45 [kv_cache_utils.py:1229] GPU KV cache size: 88,192 tokens
[1;36m(EngineCore_DP0 pid=245420)[0;0m INFO 12-04 14:29:45 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.69x
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:29:45 [kv_cache_utils.py:1229] GPU KV cache size: 97,792 tokens
[1;36m(EngineCore_DP0 pid=245419)[0;0m INFO 12-04 14:29:45 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.98x
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842]              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m ERROR 12-04 14:29:45 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 144.00 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Process 245420 has 24.91 GiB memory in use. Of the allocated memory 18.80 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=245419)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=245419)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=245419)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=245419)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=245419)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245419)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245419)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245419)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245419)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245419)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245419)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245419)[0;0m     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245419)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245419)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245419)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245419)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245419)[0;0m     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=245419)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245419)[0;0m     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=245419)[0;0m     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=245419)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245419)[0;0m     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245419)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245419)[0;0m     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=245419)[0;0m              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245419)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 144.00 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Process 245420 has 24.91 GiB memory in use. Of the allocated memory 18.80 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=245420)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|â–         | 1/51 [00:00<00:05,  9.40it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|â–         | 1/51 [00:00<00:06,  7.36it/s]
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.collective_rpc("compile_or_warm_up_model")
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 429, in compile_or_warm_up_model
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     cuda_graph_memory_bytes = self.model_runner.capture_model()
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4201, in capture_model
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self._capture_cudagraphs(
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4298, in _capture_cudagraphs
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self._dummy_run(
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 399, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 152, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return self.forward(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 430, in forward
[1;36m(EngineCore_DP0 pid=245420)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     def forward(
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return fn(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/caching.py", line 53, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return self.optimized_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 837, in call_wrapped
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return self._wrapped_call(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 413, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     raise e
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 400, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "<eval_with_key>.66", line 209, in forward
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = None
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/piecewise_backend.py", line 99, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return self.compiled_graph_for_general_shape(*args)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 268, in compiled_graph_wrapper
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     graph_output = inductor_compiled_graph(*args)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return self._compiled_fn(*args)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 184, in <lambda>
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return CompiledArtifact(lambda *args: compiled_fn(list(args)), None)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]                                           ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     all_outs = call_func_at_runtime_with_args(
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     out = normalize_as_list(f(args))
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]                             ^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return compiled_fn(runtime_args)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/output_code.py", line 613, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return self.current_callable(inputs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/utils.py", line 2962, in run
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     out = model(new_inputs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]           ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/tmp/torchinductor_ch269957/fa/cfabegaap63l46e24kdpwi6woqi73dms2wgztmau6s6lpfinbsne.py", line 906, in call
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]     buf3 = empty_strided_cuda((s72, 28672), (28672, 1), torch.bfloat16)
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m ERROR 12-04 14:29:45 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 16.00 MiB is free. Process 245419 has 19.32 GiB memory in use. Including non-PyTorch memory, this process has 25.04 GiB memory in use. Of the allocated memory 24.45 GiB is allocated by PyTorch, with 75.88 MiB allocated in private pools (e.g., CUDA Graphs), and 69.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=245420)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=245420)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=245420)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=245420)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245420)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245420)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245420)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245420)[0;0m     self.collective_rpc("compile_or_warm_up_model")
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245420)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 429, in compile_or_warm_up_model
[1;36m(EngineCore_DP0 pid=245420)[0;0m     cuda_graph_memory_bytes = self.model_runner.capture_model()
[1;36m(EngineCore_DP0 pid=245420)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4201, in capture_model
[1;36m(EngineCore_DP0 pid=245420)[0;0m     self._capture_cudagraphs(
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4298, in _capture_cudagraphs
[1;36m(EngineCore_DP0 pid=245420)[0;0m     self._dummy_run(
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=245420)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=245420)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=245420)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=245420)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 399, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 152, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return self.forward(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 430, in forward
[1;36m(EngineCore_DP0 pid=245420)[0;0m     def forward(
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return fn(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/caching.py", line 53, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return self.optimized_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 837, in call_wrapped
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return self._wrapped_call(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 413, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/graph_module.py", line 400, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "<eval_with_key>.66", line 209, in forward
[1;36m(EngineCore_DP0 pid=245420)[0;0m     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = None
[1;36m(EngineCore_DP0 pid=245420)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/piecewise_backend.py", line 99, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return self.compiled_graph_for_general_shape(*args)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 268, in compiled_graph_wrapper
[1;36m(EngineCore_DP0 pid=245420)[0;0m     graph_output = inductor_compiled_graph(*args)
[1;36m(EngineCore_DP0 pid=245420)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return self._compiled_fn(*args)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 184, in <lambda>
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return CompiledArtifact(lambda *args: compiled_fn(list(args)), None)
[1;36m(EngineCore_DP0 pid=245420)[0;0m                                           ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
[1;36m(EngineCore_DP0 pid=245420)[0;0m     all_outs = call_func_at_runtime_with_args(
[1;36m(EngineCore_DP0 pid=245420)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
[1;36m(EngineCore_DP0 pid=245420)[0;0m     out = normalize_as_list(f(args))
[1;36m(EngineCore_DP0 pid=245420)[0;0m                             ^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return compiled_fn(runtime_args)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/output_code.py", line 613, in __call__
[1;36m(EngineCore_DP0 pid=245420)[0;0m     return self.current_callable(inputs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/utils.py", line 2962, in run
[1;36m(EngineCore_DP0 pid=245420)[0;0m     out = model(new_inputs)
[1;36m(EngineCore_DP0 pid=245420)[0;0m           ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m   File "/tmp/torchinductor_ch269957/fa/cfabegaap63l46e24kdpwi6woqi73dms2wgztmau6s6lpfinbsne.py", line 906, in call
[1;36m(EngineCore_DP0 pid=245420)[0;0m     buf3 = empty_strided_cuda((s72, 28672), (28672, 1), torch.bfloat16)
[1;36m(EngineCore_DP0 pid=245420)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245420)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 16.00 MiB is free. Process 245419 has 19.32 GiB memory in use. Including non-PyTorch memory, this process has 25.04 GiB memory in use. Of the allocated memory 24.45 GiB is allocated by PyTorch, with 75.88 MiB allocated in private pools (e.g., CUDA Graphs), and 69.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:29:46.391383029 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:29:47.837359726 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:30:13 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:30:13 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
INFO 12-04 14:30:13 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:30:13 [model.py:1745] Using max model len 32768
INFO 12-04 14:30:13 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:30:13 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:30:13 [model.py:1745] Using max model len 32768
INFO 12-04 14:30:13 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:31:11 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:31:11 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:31:18 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:33731 backend=nccl
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:31:18 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:48343 backend=nccl
[W1204 14:31:18.021587613 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:33731 (errno: 97 - Address family not supported by protocol).
[W1204 14:31:18.021581639 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:48343 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:31:18 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:31:18 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:31:18 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:31:18 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:31:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:31:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:31:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:31:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=245712)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=245709)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=245712)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:27<00:54, 27.27s/it]
[1;36m(EngineCore_DP0 pid=245709)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:27<00:54, 27.13s/it]
[1;36m(EngineCore_DP0 pid=245712)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:54<00:27, 27.18s/it]
[1;36m(EngineCore_DP0 pid=245709)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:54<00:27, 27.12s/it]
[1;36m(EngineCore_DP0 pid=245712)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:17<00:00, 25.35s/it]
[1;36m(EngineCore_DP0 pid=245709)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:17<00:00, 25.31s/it]
[1;36m(EngineCore_DP0 pid=245712)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:17<00:00, 25.85s/it]
[1;36m(EngineCore_DP0 pid=245712)[0;0m 
[1;36m(EngineCore_DP0 pid=245709)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:17<00:00, 25.81s/it]
[1;36m(EngineCore_DP0 pid=245709)[0;0m 
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:32:39 [default_loader.py:314] Loading weights took 77.81 seconds
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:32:39 [default_loader.py:314] Loading weights took 77.67 seconds
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:32:40 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 80.318723 seconds
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:32:40 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 80.319422 seconds
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:33:02 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:33:02 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:33:02 [backends.py:647] Dynamo bytecode transform time: 21.38 s
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:33:02 [backends.py:647] Dynamo bytecode transform time: 21.38 s
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:33:11 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.684 s
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:33:11 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.684 s
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:33:14 [monitor.py:34] torch.compile takes 29.07 s in total
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:33:14 [monitor.py:34] torch.compile takes 29.07 s in total
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:33:17 [gpu_worker.py:359] Available KV cache memory: 10.91 GiB
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:33:17 [gpu_worker.py:359] Available KV cache memory: 11.94 GiB
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:33:18 [kv_cache_utils.py:1229] GPU KV cache size: 89,344 tokens
[1;36m(EngineCore_DP0 pid=245712)[0;0m INFO 12-04 14:33:18 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.73x
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:33:18 [kv_cache_utils.py:1229] GPU KV cache size: 97,792 tokens
[1;36m(EngineCore_DP0 pid=245709)[0;0m INFO 12-04 14:33:18 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.98x
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842]              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m ERROR 12-04 14:33:18 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 78.00 MiB is free. Process 245712 has 21.62 GiB memory in use. Including non-PyTorch memory, this process has 22.68 GiB memory in use. Of the allocated memory 22.16 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=245709)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842]              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m ERROR 12-04 14:33:18 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 350.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 78.00 MiB is free. Including non-PyTorch memory, this process has 21.62 GiB memory in use. Process 245709 has 22.68 GiB memory in use. Of the allocated memory 21.10 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=245712)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=245712)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245709)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=245712)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=245712)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=245712)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=245709)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=245709)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=245709)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=245709)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245709)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245709)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=245712)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245712)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=245712)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245712)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245712)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245712)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=245709)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=245709)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=245709)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245709)[0;0m     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245712)[0;0m     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245712)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245712)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=245709)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=245709)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=245709)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245709)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=245712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245712)[0;0m     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=245712)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245709)[0;0m     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=245709)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245709)[0;0m     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=245712)[0;0m     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=245712)[0;0m     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=245712)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=245709)[0;0m     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=245709)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245709)[0;0m     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245712)[0;0m     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=245712)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245712)[0;0m     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=245709)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245709)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=245709)[0;0m     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=245709)[0;0m              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=245712)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 350.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 78.00 MiB is free. Including non-PyTorch memory, this process has 21.62 GiB memory in use. Process 245709 has 22.68 GiB memory in use. Of the allocated memory 21.10 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=245709)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 78.00 MiB is free. Process 245712 has 21.62 GiB memory in use. Including non-PyTorch memory, this process has 22.68 GiB memory in use. Of the allocated memory 22.16 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:33:19.397014443 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:33:19.396996801 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:33:47 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:33:47 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
INFO 12-04 14:33:47 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:33:47 [model.py:1745] Using max model len 32768
INFO 12-04 14:33:47 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:33:47 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:33:47 [model.py:1745] Using max model len 32768
INFO 12-04 14:33:47 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:34:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:34:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:34:50 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:34277 backend=nccl
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:34:50 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:39729 backend=nccl
[W1204 14:34:50.904220494 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:34277 (errno: 97 - Address family not supported by protocol).
[W1204 14:34:50.904095644 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:39729 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:34:50 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:34:50 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:34:50 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:34:50 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:34:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:34:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:34:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:34:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=246092)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=246093)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=246092)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:24<00:48, 24.34s/it]
[1;36m(EngineCore_DP0 pid=246093)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:24<00:48, 24.18s/it]
[1;36m(EngineCore_DP0 pid=246092)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:50<00:25, 25.19s/it]
[1;36m(EngineCore_DP0 pid=246093)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:49<00:25, 25.12s/it]
[1;36m(EngineCore_DP0 pid=246092)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:13<00:00, 24.20s/it]
[1;36m(EngineCore_DP0 pid=246093)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:12<00:00, 24.16s/it]
[1;36m(EngineCore_DP0 pid=246092)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:13<00:00, 24.38s/it]
[1;36m(EngineCore_DP0 pid=246092)[0;0m 
[1;36m(EngineCore_DP0 pid=246093)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [01:12<00:00, 24.33s/it]
[1;36m(EngineCore_DP0 pid=246093)[0;0m 
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:36:07 [default_loader.py:314] Loading weights took 73.41 seconds
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:36:07 [default_loader.py:314] Loading weights took 73.26 seconds
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:36:08 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 75.948514 seconds
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:36:08 [gpu_model_runner.py:3338] Model loading took 13.5084 GiB memory and 75.948078 seconds
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:36:30 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:36:30 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/289b0e59ba/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:36:30 [backends.py:647] Dynamo bytecode transform time: 21.64 s
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:36:30 [backends.py:647] Dynamo bytecode transform time: 21.64 s
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:36:39 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.552 s
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:36:39 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 7.552 s
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:36:42 [monitor.py:34] torch.compile takes 29.19 s in total
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:36:42 [monitor.py:34] torch.compile takes 29.19 s in total
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:36:45 [gpu_worker.py:359] Available KV cache memory: 11.94 GiB
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:36:45 [gpu_worker.py:359] Available KV cache memory: 11.94 GiB
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:36:45 [kv_cache_utils.py:1229] GPU KV cache size: 97,792 tokens
[1;36m(EngineCore_DP0 pid=246092)[0;0m INFO 12-04 14:36:45 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.98x
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:36:45 [kv_cache_utils.py:1229] GPU KV cache size: 97,792 tokens
[1;36m(EngineCore_DP0 pid=246093)[0;0m INFO 12-04 14:36:45 [kv_cache_utils.py:1234] Maximum concurrency for 32,768 tokens per request: 2.98x
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842]              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m ERROR 12-04 14:36:45 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 138.00 MiB is free. Process 246092 has 22.31 GiB memory in use. Including non-PyTorch memory, this process has 21.94 GiB memory in use. Of the allocated memory 21.41 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=246093)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842]              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m ERROR 12-04 14:36:45 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 138.00 MiB is free. Including non-PyTorch memory, this process has 22.31 GiB memory in use. Process 246093 has 21.94 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=246092)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=246093)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=246092)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=246093)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=246093)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=246093)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=246093)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=246093)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=246093)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=246093)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=246093)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=246093)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246093)[0;0m     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=246093)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=246093)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=246093)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=246093)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246093)[0;0m     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=246093)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246093)[0;0m     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=246093)[0;0m     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=246093)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=246093)[0;0m     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=246093)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246093)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=246093)[0;0m     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=246093)[0;0m              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=246092)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=246092)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=246092)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=246092)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=246093)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 138.00 MiB is free. Process 246092 has 22.31 GiB memory in use. Including non-PyTorch memory, this process has 21.94 GiB memory in use. Of the allocated memory 21.41 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=246092)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=246092)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=246092)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=246092)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 247, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=246092)[0;0m     self.model_executor.initialize_from_config(kv_cache_configs)
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 115, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246092)[0;0m     self.collective_rpc("initialize_from_config", args=(kv_cache_configs,))
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=246092)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=246092)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=246092)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=246092)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 319, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246092)[0;0m     self.worker.initialize_from_config(kv_cache_config)  # type: ignore
[1;36m(EngineCore_DP0 pid=246092)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 404, in initialize_from_config
[1;36m(EngineCore_DP0 pid=246092)[0;0m     self.model_runner.initialize_kv_cache(kv_cache_config)
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 5007, in initialize_kv_cache
[1;36m(EngineCore_DP0 pid=246092)[0;0m     kv_caches = self.initialize_kv_cache_tensors(
[1;36m(EngineCore_DP0 pid=246092)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4933, in initialize_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=246092)[0;0m     kv_cache_raw_tensors = self._allocate_kv_cache_tensors(kv_cache_config)
[1;36m(EngineCore_DP0 pid=246092)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4718, in _allocate_kv_cache_tensors
[1;36m(EngineCore_DP0 pid=246092)[0;0m     tensor = torch.zeros(
[1;36m(EngineCore_DP0 pid=246092)[0;0m              ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=246092)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 138.00 MiB is free. Including non-PyTorch memory, this process has 22.31 GiB memory in use. Process 246093 has 21.94 GiB memory in use. Of the allocated memory 21.79 GiB is allocated by PyTorch, and 3.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:36:47.076703454 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:36:47.105633143 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:13 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: mistralai/Mistral-7B-Instruct-v0.3 (backend=vllm)
[ModelCache] Using max_model_len=32768 for mistralai/Mistral-7B-Instruct-v0.3
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:14 [utils.py:253] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'mistralai/Mistral-7B-Instruct-v0.3'}
INFO 12-04 14:37:14 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:37:14 [model.py:1745] Using max model len 32768
INFO 12-04 14:37:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:37:14 [model.py:631] Resolved architecture: MistralForCausalLM
INFO 12-04 14:37:14 [model.py:1745] Using max model len 32768
INFO 12-04 14:37:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=246341)[0;0m INFO 12-04 14:38:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=246340)[0;0m INFO 12-04 14:38:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=246341)[0;0m INFO 12-04 14:38:09 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:42603 backend=nccl
[1;36m(EngineCore_DP0 pid=246340)[0;0m INFO 12-04 14:38:09 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.101:43907 backend=nccl
[W1204 14:38:09.419966907 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:42603 (errno: 97 - Address family not supported by protocol).
[W1204 14:38:09.419966863 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-2.rc.tch.harvard.edu]:43907 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=246341)[0;0m INFO 12-04 14:38:09 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=246340)[0;0m INFO 12-04 14:38:09 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=246341)[0;0m INFO 12-04 14:38:10 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=246340)[0;0m INFO 12-04 14:38:10 [gpu_model_runner.py:3259] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...
[1;36m(EngineCore_DP0 pid=246341)[0;0m INFO 12-04 14:38:12 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=246341)[0;0m INFO 12-04 14:38:12 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=246340)[0;0m INFO 12-04 14:38:12 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=246340)[0;0m INFO 12-04 14:38:12 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=246340)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=246341)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
slurmstepd-gpu-26-2: error: *** STEP 12735860.0 ON gpu-26-2 CANCELLED AT 2025-12-04T14:38:17 ***
