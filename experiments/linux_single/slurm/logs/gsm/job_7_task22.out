Using persona diversity with 3 different personas
============================================================
GSM Task - Multiagent Debate
============================================================
Model: meta-llama/Llama-3.2-3B-Instruct
Persona diversity mode:
  Agent 1: a Kantian deontologist who judges all actions strictly by th...
  Agent 2: a cosmic horror narrator who frames the problem as an ancien...
  Agent 3: a Renaissance painter who values perspective, light, shadow,...
Agents: 3
Rounds: 3
Problems: 20
Dataset: /home/ch269957/projects/slm_multiagent_debate/data/gsm8k/test.jsonl
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================

--- Problem 1/20, Round 1, Agent 1/3 ---
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:58:35 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Using persona diversity with 3 different personas
============================================================
GSM Task - Multiagent Debate
============================================================
Model: meta-llama/Llama-3.2-3B-Instruct
Persona diversity mode:
  Agent 1: a Kantian deontologist who judges all actions strictly by th...
  Agent 2: a cosmic horror narrator who frames the problem as an ancien...
  Agent 3: a Renaissance painter who values perspective, light, shadow,...
Agents: 3
Rounds: 3
Problems: 20
Dataset: /home/ch269957/projects/slm_multiagent_debate/data/gsm8k/test.jsonl
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================

--- Problem 1/20, Round 1, Agent 1/3 ---
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:58:35 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 13:58:35 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 13:58:35 [model.py:1745] Using max model len 131072
INFO 12-04 13:58:35 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 13:58:35 [model.py:1745] Using max model len 131072
INFO 12-04 13:58:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:58:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=526008)[0;0m INFO 12-04 13:58:53 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=526004)[0;0m INFO 12-04 13:58:53 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=526004)[0;0m INFO 12-04 13:58:54 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:56867 backend=nccl
[1;36m(EngineCore_DP0 pid=526008)[0;0m INFO 12-04 13:58:54 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:60671 backend=nccl
[W1204 13:58:54.108777092 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:60671 (errno: 97 - Address family not supported by protocol).
[W1204 13:58:54.108777102 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:56867 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=526008)[0;0m INFO 12-04 13:58:54 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=526004)[0;0m INFO 12-04 13:58:54 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=526008)[0;0m INFO 12-04 13:58:55 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=526004)[0;0m INFO 12-04 13:58:55 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=526008)[0;0m INFO 12-04 13:58:56 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=526008)[0;0m INFO 12-04 13:58:56 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=526004)[0;0m INFO 12-04 13:58:56 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=526004)[0;0m INFO 12-04 13:58:56 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=526004)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=526008)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=526008)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:14<00:14, 14.67s/it]
[1;36m(EngineCore_DP0 pid=526004)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:14<00:14, 14.72s/it]
[1;36m(EngineCore_DP0 pid=526008)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:19<00:00,  8.79s/it]
[1;36m(EngineCore_DP0 pid=526004)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:19<00:00,  8.81s/it]
[1;36m(EngineCore_DP0 pid=526008)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:19<00:00,  9.67s/it]
[1;36m(EngineCore_DP0 pid=526008)[0;0m 
[1;36m(EngineCore_DP0 pid=526004)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:19<00:00,  9.70s/it]
[1;36m(EngineCore_DP0 pid=526004)[0;0m 
[1;36m(EngineCore_DP0 pid=526008)[0;0m INFO 12-04 13:59:16 [default_loader.py:314] Loading weights took 19.42 seconds
[1;36m(EngineCore_DP0 pid=526004)[0;0m INFO 12-04 13:59:16 [default_loader.py:314] Loading weights took 19.57 seconds
[1;36m(EngineCore_DP0 pid=526008)[0;0m INFO 12-04 13:59:16 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 20.667270 seconds
[1;36m(EngineCore_DP0 pid=526004)[0;0m INFO 12-04 13:59:16 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 20.764960 seconds
[1;36m(EngineCore_DP0 pid=526008)[0;0m INFO 12-04 13:59:26 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=526004)[0;0m INFO 12-04 13:59:26 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=526008)[0;0m INFO 12-04 13:59:26 [backends.py:647] Dynamo bytecode transform time: 9.57 s
[1;36m(EngineCore_DP0 pid=526004)[0;0m INFO 12-04 13:59:26 [backends.py:647] Dynamo bytecode transform time: 9.47 s
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f4590024fb0>' raised:
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842] 
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=526008)[0;0m ERROR 12-04 13:59:27 [core.py:842] 
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fceb42839b0>' raised:
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842] 
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=526004)[0;0m ERROR 12-04 13:59:27 [core.py:842] 
[1;36m(EngineCore_DP0 pid=526004)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=526008)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=526004)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=526004)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=526004)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=526004)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=526004)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=526004)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=526004)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=526004)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=526004)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=526004)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=526004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=526004)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=526004)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=526004)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=526004)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=526004)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=526004)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=526004)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=526008)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=526008)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=526004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=526004)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=526004)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=526004)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=526004)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=526004)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=526004)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=526004)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=526004)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=526004)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=526004)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=526008)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=526008)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=526008)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=526008)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=526008)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=526008)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=526008)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=526008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=526008)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=526008)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=526008)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=526008)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=526008)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=526008)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=526008)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=526008)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=526008)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=526004)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=526004)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=526004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=526004)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=526004)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=526004)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=526004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=526004)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=526004)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=526004)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=526004)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=526004)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=526004)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=526004)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=526004)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=526004)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=526004)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=526004)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fceb42839b0>' raised:
[1;36m(EngineCore_DP0 pid=526004)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=526004)[0;0m 
[1;36m(EngineCore_DP0 pid=526004)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=526008)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=526008)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=526008)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=526008)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=526008)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=526008)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=526008)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=526008)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=526008)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=526004)[0;0m 
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=526008)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=526008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=526008)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=526008)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=526008)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=526008)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=526008)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=526008)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=526008)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=526008)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=526008)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=526008)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=526008)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=526008)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=526008)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=526008)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=526008)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=526008)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f4590024fb0>' raised:
[1;36m(EngineCore_DP0 pid=526008)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=526008)[0;0m 
[1;36m(EngineCore_DP0 pid=526008)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=526008)[0;0m 
[rank0]:[W1204 13:59:28.485528776 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:59:28.485524813 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:59:49 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:59:49 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 13:59:49 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 13:59:49 [model.py:1745] Using max model len 131072
INFO 12-04 13:59:49 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:59:49 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 13:59:49 [model.py:1745] Using max model len 131072
INFO 12-04 13:59:49 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=528516)[0;0m INFO 12-04 14:00:03 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=528513)[0;0m INFO 12-04 14:00:03 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=528513)[0;0m INFO 12-04 14:00:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:36765 backend=nccl
[1;36m(EngineCore_DP0 pid=528516)[0;0m INFO 12-04 14:00:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:52067 backend=nccl
[W1204 14:00:04.370763265 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:36765 (errno: 97 - Address family not supported by protocol).
[W1204 14:00:04.371213832 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:52067 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=528516)[0;0m INFO 12-04 14:00:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=528513)[0;0m INFO 12-04 14:00:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=528516)[0;0m INFO 12-04 14:00:05 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=528513)[0;0m INFO 12-04 14:00:05 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=528513)[0;0m INFO 12-04 14:00:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=528513)[0;0m INFO 12-04 14:00:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=528516)[0;0m INFO 12-04 14:00:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=528516)[0;0m INFO 12-04 14:00:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=528516)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=528513)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=528516)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=528513)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.10s/it]
[1;36m(EngineCore_DP0 pid=528516)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=528516)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=528516)[0;0m 
[1;36m(EngineCore_DP0 pid=528516)[0;0m INFO 12-04 14:00:08 [default_loader.py:314] Loading weights took 1.69 seconds
[1;36m(EngineCore_DP0 pid=528513)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=528513)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
[1;36m(EngineCore_DP0 pid=528513)[0;0m 
[1;36m(EngineCore_DP0 pid=528513)[0;0m INFO 12-04 14:00:08 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=528516)[0;0m INFO 12-04 14:00:09 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.807214 seconds
[1;36m(EngineCore_DP0 pid=528513)[0;0m INFO 12-04 14:00:09 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.915413 seconds
[1;36m(EngineCore_DP0 pid=528513)[0;0m INFO 12-04 14:00:17 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=528516)[0;0m INFO 12-04 14:00:17 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=528513)[0;0m INFO 12-04 14:00:17 [backends.py:647] Dynamo bytecode transform time: 8.01 s
[1;36m(EngineCore_DP0 pid=528516)[0;0m INFO 12-04 14:00:17 [backends.py:647] Dynamo bytecode transform time: 8.12 s
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f339c0f8920>' raised:
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842] 
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=528516)[0;0m ERROR 12-04 14:00:18 [core.py:842] 
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7efd641c2480>' raised:
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842] 
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=528513)[0;0m ERROR 12-04 14:00:18 [core.py:842] 
[1;36m(EngineCore_DP0 pid=528516)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=528513)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=528516)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=528513)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=528513)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=528513)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=528516)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=528516)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=528516)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=528516)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=528516)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=528513)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=528513)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=528513)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=528513)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=528513)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=528513)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=528513)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=528513)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=528513)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=528516)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=528516)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=528516)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=528516)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=528516)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=528516)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=528516)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=528516)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=528516)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=528516)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=528516)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=528516)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=528516)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=528516)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=528516)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=528513)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=528513)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=528513)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=528513)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=528513)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=528513)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=528513)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=528513)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=528513)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=528513)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=528513)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=528513)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=528513)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=528516)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=528516)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=528516)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=528516)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=528516)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=528516)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=528516)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=528516)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=528516)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=528516)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=528516)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=528516)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=528516)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=528516)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=528513)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=528513)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=528513)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=528513)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=528513)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=528513)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=528513)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=528513)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=528513)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=528513)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=528513)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=528513)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=528513)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=528513)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=528513)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=528513)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=528516)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=528516)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=528516)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=528516)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=528516)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=528516)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=528516)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=528516)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=528516)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528516)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=528516)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=528516)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f339c0f8920>' raised:
[1;36m(EngineCore_DP0 pid=528516)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=528516)[0;0m 
[1;36m(EngineCore_DP0 pid=528516)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=528516)[0;0m 
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=528513)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=528513)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=528513)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=528513)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=528513)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7efd641c2480>' raised:
[1;36m(EngineCore_DP0 pid=528513)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=528513)[0;0m 
[1;36m(EngineCore_DP0 pid=528513)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=528513)[0;0m 
[rank0]:[W1204 14:00:18.301014937 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:00:18.301885980 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:00:40 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:00:40 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:00:40 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:00:40 [model.py:1745] Using max model len 131072
INFO 12-04 14:00:40 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:00:40 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:00:40 [model.py:1745] Using max model len 131072
INFO 12-04 14:00:40 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=529370)[0;0m INFO 12-04 14:00:53 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=529373)[0;0m INFO 12-04 14:00:53 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=529373)[0;0m INFO 12-04 14:00:54 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:52331 backend=nccl
[1;36m(EngineCore_DP0 pid=529370)[0;0m INFO 12-04 14:00:54 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:58613 backend=nccl
[W1204 14:00:54.876562458 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:52331 (errno: 97 - Address family not supported by protocol).
[W1204 14:00:54.876562658 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:58613 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=529373)[0;0m INFO 12-04 14:00:54 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=529370)[0;0m INFO 12-04 14:00:54 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=529373)[0;0m INFO 12-04 14:00:54 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=529370)[0;0m INFO 12-04 14:00:54 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=529373)[0;0m INFO 12-04 14:00:55 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=529373)[0;0m INFO 12-04 14:00:55 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=529370)[0;0m INFO 12-04 14:00:55 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=529370)[0;0m INFO 12-04 14:00:55 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=529373)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=529370)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=529373)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=529370)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=529373)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=529373)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=529373)[0;0m 
[1;36m(EngineCore_DP0 pid=529373)[0;0m INFO 12-04 14:00:58 [default_loader.py:314] Loading weights took 1.69 seconds
[1;36m(EngineCore_DP0 pid=529370)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=529370)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=529370)[0;0m 
[1;36m(EngineCore_DP0 pid=529370)[0;0m INFO 12-04 14:00:58 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=529373)[0;0m INFO 12-04 14:00:58 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.865730 seconds
[1;36m(EngineCore_DP0 pid=529370)[0;0m INFO 12-04 14:00:58 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.953881 seconds
[1;36m(EngineCore_DP0 pid=529370)[0;0m INFO 12-04 14:01:07 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=529373)[0;0m INFO 12-04 14:01:07 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=529373)[0;0m INFO 12-04 14:01:07 [backends.py:647] Dynamo bytecode transform time: 8.67 s
[1;36m(EngineCore_DP0 pid=529370)[0;0m INFO 12-04 14:01:07 [backends.py:647] Dynamo bytecode transform time: 8.60 s
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f60c01db950>' raised:
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842] 
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=529373)[0;0m ERROR 12-04 14:01:08 [core.py:842] 
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f60b41cea50>' raised:
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842] 
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=529370)[0;0m ERROR 12-04 14:01:08 [core.py:842] 
[1;36m(EngineCore_DP0 pid=529373)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=529370)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=529373)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=529370)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=529370)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=529370)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=529373)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=529373)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=529373)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=529373)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=529373)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=529373)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=529370)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=529370)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=529370)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=529370)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=529370)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=529370)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=529370)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=529370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=529370)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=529370)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=529373)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=529373)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=529373)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=529373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=529373)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=529373)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=529373)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=529373)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=529373)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=529373)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=529373)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=529373)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=529373)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=529373)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=529373)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=529370)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=529370)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=529370)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=529370)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=529370)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=529370)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=529370)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=529370)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=529370)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=529370)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=529370)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=529370)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=529370)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=529373)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=529373)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=529373)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=529373)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=529373)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=529373)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=529373)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=529373)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=529373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=529373)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=529373)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=529373)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=529373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=529370)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=529370)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=529370)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=529370)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=529370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=529370)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=529370)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=529370)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=529370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=529370)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=529370)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=529370)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=529370)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=529370)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=529370)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=529370)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=529373)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=529373)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=529373)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=529373)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=529373)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=529373)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=529373)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=529373)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=529373)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=529373)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=529373)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f60c01db950>' raised:
[1;36m(EngineCore_DP0 pid=529373)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=529373)[0;0m 
[1;36m(EngineCore_DP0 pid=529373)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=529373)[0;0m 
[1;36m(EngineCore_DP0 pid=529370)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=529370)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=529370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=529370)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=529370)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f60b41cea50>' raised:
[1;36m(EngineCore_DP0 pid=529370)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=529370)[0;0m 
[1;36m(EngineCore_DP0 pid=529370)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=529370)[0;0m 
[rank0]:[W1204 14:01:09.488550152 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:01:09.501022575 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:01:30 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:01:30 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:01:30 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:01:30 [model.py:1745] Using max model len 131072
INFO 12-04 14:01:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:01:30 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:01:30 [model.py:1745] Using max model len 131072
INFO 12-04 14:01:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=531992)[0;0m INFO 12-04 14:01:47 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=531989)[0;0m INFO 12-04 14:01:47 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=531989)[0;0m INFO 12-04 14:01:49 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:48887 backend=nccl
[1;36m(EngineCore_DP0 pid=531992)[0;0m INFO 12-04 14:01:49 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:34861 backend=nccl
[W1204 14:01:49.124959223 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:48887 (errno: 97 - Address family not supported by protocol).
[W1204 14:01:49.126431477 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:34861 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=531992)[0;0m INFO 12-04 14:01:49 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=531989)[0;0m INFO 12-04 14:01:49 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=531992)[0;0m INFO 12-04 14:01:50 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=531989)[0;0m INFO 12-04 14:01:50 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=531989)[0;0m INFO 12-04 14:01:51 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=531989)[0;0m INFO 12-04 14:01:51 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=531992)[0;0m INFO 12-04 14:01:51 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=531992)[0;0m INFO 12-04 14:01:51 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=531989)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=531992)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=531989)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=531992)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=531989)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=531989)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=531989)[0;0m 
[1;36m(EngineCore_DP0 pid=531989)[0;0m INFO 12-04 14:01:53 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=531992)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=531992)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=531992)[0;0m 
[1;36m(EngineCore_DP0 pid=531992)[0;0m INFO 12-04 14:01:53 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=531989)[0;0m INFO 12-04 14:01:53 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.862770 seconds
[1;36m(EngineCore_DP0 pid=531992)[0;0m INFO 12-04 14:01:54 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.961709 seconds
[1;36m(EngineCore_DP0 pid=531992)[0;0m INFO 12-04 14:02:03 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=531989)[0;0m INFO 12-04 14:02:03 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=531992)[0;0m INFO 12-04 14:02:03 [backends.py:647] Dynamo bytecode transform time: 8.73 s
[1;36m(EngineCore_DP0 pid=531989)[0;0m INFO 12-04 14:02:03 [backends.py:647] Dynamo bytecode transform time: 8.83 s
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd3802c7860>' raised:
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842] 
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=531992)[0;0m ERROR 12-04 14:02:03 [core.py:842] 
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f628b613bf0>' raised:
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842] 
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=531989)[0;0m ERROR 12-04 14:02:03 [core.py:842] 
[1;36m(EngineCore_DP0 pid=531992)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=531989)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=531992)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=531989)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=531989)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=531989)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=531989)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=531992)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=531992)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=531992)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=531992)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=531992)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=531992)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=531992)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=531989)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=531989)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=531989)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=531989)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=531989)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=531989)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=531989)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=531989)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=531989)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=531989)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=531992)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=531992)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=531992)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=531992)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=531992)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=531992)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=531992)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=531992)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=531992)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=531992)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=531992)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=531992)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=531992)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=531992)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=531992)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=531989)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=531989)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=531989)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=531989)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=531989)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=531989)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=531989)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=531989)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=531989)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=531989)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=531989)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=531989)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=531989)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=531992)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=531992)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=531992)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=531992)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=531992)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=531992)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=531992)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=531992)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=531992)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=531992)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=531992)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=531992)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=531989)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=531989)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=531989)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=531989)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=531989)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=531989)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=531989)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=531989)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=531989)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=531989)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=531989)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=531989)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=531989)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=531989)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=531989)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=531989)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=531989)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531989)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=531989)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=531992)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=531992)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=531992)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=531992)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=531992)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=531992)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=531992)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=531992)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=531992)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=531992)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=531992)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd3802c7860>' raised:
[1;36m(EngineCore_DP0 pid=531992)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=531992)[0;0m 
[1;36m(EngineCore_DP0 pid=531992)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=531992)[0;0m 
[1;36m(EngineCore_DP0 pid=531989)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f628b613bf0>' raised:
[1;36m(EngineCore_DP0 pid=531989)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=531989)[0;0m 
[1;36m(EngineCore_DP0 pid=531989)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=531989)[0;0m 
[rank0]:[W1204 14:02:04.911642923 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:02:04.911890546 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:02:25 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:02:25 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:02:25 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:02:25 [model.py:1745] Using max model len 131072
INFO 12-04 14:02:25 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:02:25 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:02:25 [model.py:1745] Using max model len 131072
INFO 12-04 14:02:25 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=534342)[0;0m INFO 12-04 14:02:37 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=534346)[0;0m INFO 12-04 14:02:37 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=534342)[0;0m INFO 12-04 14:02:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:59731 backend=nccl
[W1204 14:02:38.264749606 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:59731 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=534342)[0;0m INFO 12-04 14:02:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=534346)[0;0m INFO 12-04 14:02:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:50017 backend=nccl
[W1204 14:02:38.383703339 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:50017 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=534346)[0;0m INFO 12-04 14:02:39 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=534342)[0;0m INFO 12-04 14:02:39 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=534346)[0;0m INFO 12-04 14:02:39 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=534342)[0;0m INFO 12-04 14:02:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=534342)[0;0m INFO 12-04 14:02:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=534346)[0;0m INFO 12-04 14:02:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=534346)[0;0m INFO 12-04 14:02:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=534342)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=534346)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=534342)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=534346)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=534342)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=534342)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=534342)[0;0m 
[1;36m(EngineCore_DP0 pid=534342)[0;0m INFO 12-04 14:02:42 [default_loader.py:314] Loading weights took 1.72 seconds
[1;36m(EngineCore_DP0 pid=534346)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=534346)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=534346)[0;0m 
[1;36m(EngineCore_DP0 pid=534346)[0;0m INFO 12-04 14:02:42 [default_loader.py:314] Loading weights took 1.72 seconds
[1;36m(EngineCore_DP0 pid=534342)[0;0m INFO 12-04 14:02:43 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.821430 seconds
[1;36m(EngineCore_DP0 pid=534346)[0;0m INFO 12-04 14:02:43 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.835715 seconds
[1;36m(EngineCore_DP0 pid=534342)[0;0m INFO 12-04 14:02:51 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=534346)[0;0m INFO 12-04 14:02:51 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=534342)[0;0m INFO 12-04 14:02:51 [backends.py:647] Dynamo bytecode transform time: 8.18 s
[1;36m(EngineCore_DP0 pid=534346)[0;0m INFO 12-04 14:02:51 [backends.py:647] Dynamo bytecode transform time: 8.06 s
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=534346)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5918119550>' raised:
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842] 
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=534342)[0;0m ERROR 12-04 14:02:52 [core.py:842] 
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f1c000a5e20>' raised:
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842] 
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=534346)[0;0m ERROR 12-04 14:02:52 [core.py:842] 
[1;36m(EngineCore_DP0 pid=534342)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=534346)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=534342)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=534342)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=534342)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=534342)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=534342)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=534342)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=534342)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=534342)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=534342)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=534342)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=534342)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=534342)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=534342)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=534342)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=534342)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=534342)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=534342)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=534342)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=534342)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=534342)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=534342)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=534342)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=534342)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=534342)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=534342)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=534342)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=534342)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=534342)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=534342)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=534342)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=534342)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=534342)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=534342)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=534342)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=534342)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=534342)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=534342)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=534342)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=534342)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=534342)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=534342)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=534342)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=534342)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=534342)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=534342)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=534342)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5918119550>' raised:
[1;36m(EngineCore_DP0 pid=534342)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=534342)[0;0m 
[1;36m(EngineCore_DP0 pid=534342)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=534342)[0;0m 
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=534346)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=534346)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=534346)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=534346)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=534346)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=534346)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=534346)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=534346)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=534346)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=534346)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=534346)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=534346)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=534346)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=534346)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=534346)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=534346)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=534346)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=534346)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=534346)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=534346)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=534346)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=534346)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=534346)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=534346)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=534346)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=534346)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=534346)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=534346)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=534346)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=534346)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=534346)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=534346)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=534346)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=534346)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=534346)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=534346)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=534346)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=534346)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=534346)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=534346)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=534346)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=534346)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=534346)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=534346)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=534346)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=534346)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=534346)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f1c000a5e20>' raised:
[1;36m(EngineCore_DP0 pid=534346)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=534346)[0;0m 
[1;36m(EngineCore_DP0 pid=534346)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=534346)[0;0m 
[rank0]:[W1204 14:02:52.351911671 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:02:52.368826926 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:03:14 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:03:14 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:03:14 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:03:14 [model.py:1745] Using max model len 131072
INFO 12-04 14:03:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:03:14 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:03:14 [model.py:1745] Using max model len 131072
INFO 12-04 14:03:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=535370)[0;0m INFO 12-04 14:03:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=535366)[0;0m INFO 12-04 14:03:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=535370)[0;0m INFO 12-04 14:03:28 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:51967 backend=nccl
[1;36m(EngineCore_DP0 pid=535366)[0;0m INFO 12-04 14:03:28 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:57117 backend=nccl
[W1204 14:03:28.878397578 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:51967 (errno: 97 - Address family not supported by protocol).
[W1204 14:03:28.880943469 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:57117 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=535370)[0;0m INFO 12-04 14:03:28 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=535366)[0;0m INFO 12-04 14:03:28 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=535370)[0;0m INFO 12-04 14:03:28 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=535366)[0;0m INFO 12-04 14:03:28 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=535370)[0;0m INFO 12-04 14:03:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=535370)[0;0m INFO 12-04 14:03:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=535366)[0;0m INFO 12-04 14:03:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=535366)[0;0m INFO 12-04 14:03:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=535370)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=535366)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=535370)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=535366)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.12s/it]
[1;36m(EngineCore_DP0 pid=535370)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=535370)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=535370)[0;0m 
[1;36m(EngineCore_DP0 pid=535370)[0;0m INFO 12-04 14:03:31 [default_loader.py:314] Loading weights took 1.69 seconds
[1;36m(EngineCore_DP0 pid=535366)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=535366)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=535366)[0;0m 
[1;36m(EngineCore_DP0 pid=535366)[0;0m INFO 12-04 14:03:32 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=535370)[0;0m INFO 12-04 14:03:32 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.744018 seconds
[1;36m(EngineCore_DP0 pid=535366)[0;0m INFO 12-04 14:03:32 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.844667 seconds
[1;36m(EngineCore_DP0 pid=535370)[0;0m INFO 12-04 14:03:40 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=535370)[0;0m INFO 12-04 14:03:40 [backends.py:647] Dynamo bytecode transform time: 7.77 s
[1;36m(EngineCore_DP0 pid=535366)[0;0m INFO 12-04 14:03:40 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=535366)[0;0m INFO 12-04 14:03:40 [backends.py:647] Dynamo bytecode transform time: 7.71 s
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f9834127d10>' raised:
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=535370)[0;0m ERROR 12-04 14:03:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=535370)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=535370)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=535370)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=535370)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=535370)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=535370)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=535370)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=535370)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=535370)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=535370)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=535370)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=535370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=535370)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=535370)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=535370)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=535370)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=535370)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=535370)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=535370)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=535370)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=535370)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=535370)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=535370)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=535370)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=535370)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=535370)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=535370)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=535370)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=535370)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=535370)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=535370)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=535370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=535370)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=535370)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=535370)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=535370)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=535370)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=535370)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=535370)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=535370)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=535370)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=535370)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=535370)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=535370)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=535370)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535370)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=535370)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=535370)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f9834127d10>' raised:
[1;36m(EngineCore_DP0 pid=535370)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=535370)[0;0m 
[1;36m(EngineCore_DP0 pid=535370)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=535370)[0;0m 
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fdda8247410>' raised:
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=535366)[0;0m ERROR 12-04 14:03:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=535366)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=535366)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=535366)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=535366)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=535366)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=535366)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=535366)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=535366)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=535366)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=535366)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=535366)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=535366)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=535366)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=535366)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=535366)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=535366)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=535366)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=535366)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=535366)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=535366)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=535366)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=535366)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=535366)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=535366)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=535366)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=535366)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=535366)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=535366)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=535366)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=535366)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=535366)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=535366)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=535366)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=535366)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=535366)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=535366)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=535366)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=535366)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=535366)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=535366)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=535366)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=535366)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=535366)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=535366)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=535366)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=535366)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=535366)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=535366)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fdda8247410>' raised:
[1;36m(EngineCore_DP0 pid=535366)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=535366)[0;0m 
[1;36m(EngineCore_DP0 pid=535366)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=535366)[0;0m 
[rank0]:[W1204 14:03:42.472091295 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:03:42.506858566 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:04:03 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:04:03 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:04:03 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:04:03 [model.py:1745] Using max model len 131072
INFO 12-04 14:04:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:04:03 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:04:03 [model.py:1745] Using max model len 131072
INFO 12-04 14:04:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=536800)[0;0m INFO 12-04 14:04:16 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=536797)[0;0m INFO 12-04 14:04:16 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=536797)[0;0m INFO 12-04 14:04:17 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:36789 backend=nccl
[1;36m(EngineCore_DP0 pid=536800)[0;0m INFO 12-04 14:04:17 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:48669 backend=nccl
[W1204 14:04:17.227385800 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:36789 (errno: 97 - Address family not supported by protocol).
[W1204 14:04:17.228818967 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:48669 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=536797)[0;0m INFO 12-04 14:04:17 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=536800)[0;0m INFO 12-04 14:04:17 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=536797)[0;0m INFO 12-04 14:04:18 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=536800)[0;0m INFO 12-04 14:04:18 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=536797)[0;0m INFO 12-04 14:04:19 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=536797)[0;0m INFO 12-04 14:04:19 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=536800)[0;0m INFO 12-04 14:04:19 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=536800)[0;0m INFO 12-04 14:04:19 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=536800)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=536797)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=536800)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=536797)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=536800)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=536800)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=536800)[0;0m 
[1;36m(EngineCore_DP0 pid=536800)[0;0m INFO 12-04 14:04:21 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=536797)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=536797)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=536797)[0;0m 
[1;36m(EngineCore_DP0 pid=536797)[0;0m INFO 12-04 14:04:21 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=536800)[0;0m INFO 12-04 14:04:21 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.762692 seconds
[1;36m(EngineCore_DP0 pid=536797)[0;0m INFO 12-04 14:04:22 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.835736 seconds
[1;36m(EngineCore_DP0 pid=536800)[0;0m INFO 12-04 14:04:30 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=536800)[0;0m INFO 12-04 14:04:30 [backends.py:647] Dynamo bytecode transform time: 7.96 s
[1;36m(EngineCore_DP0 pid=536797)[0;0m INFO 12-04 14:04:30 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=536797)[0;0m INFO 12-04 14:04:30 [backends.py:647] Dynamo bytecode transform time: 7.92 s
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f3e4f693500>' raised:
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842] 
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=536800)[0;0m ERROR 12-04 14:04:30 [core.py:842] 
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f91481ff620>' raised:
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842] 
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=536797)[0;0m ERROR 12-04 14:04:30 [core.py:842] 
[1;36m(EngineCore_DP0 pid=536800)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=536800)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=536800)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=536800)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=536800)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=536800)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=536800)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=536800)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=536800)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=536800)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=536800)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=536800)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=536800)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=536800)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=536800)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=536800)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=536800)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=536800)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=536800)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=536800)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=536800)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=536800)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=536800)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=536800)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=536800)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=536800)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=536800)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=536800)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=536800)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=536800)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=536800)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=536800)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=536800)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=536800)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=536800)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=536800)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=536800)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=536800)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=536800)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=536800)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=536800)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=536800)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=536800)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=536800)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=536800)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536800)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=536800)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=536800)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f3e4f693500>' raised:
[1;36m(EngineCore_DP0 pid=536800)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=536800)[0;0m 
[1;36m(EngineCore_DP0 pid=536800)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=536800)[0;0m 
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=536797)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=536797)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=536797)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=536797)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=536797)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=536797)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=536797)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=536797)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=536797)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=536797)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=536797)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=536797)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=536797)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=536797)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=536797)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=536797)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=536797)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=536797)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=536797)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=536797)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=536797)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=536797)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=536797)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=536797)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=536797)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=536797)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=536797)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=536797)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=536797)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=536797)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=536797)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=536797)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=536797)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=536797)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=536797)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=536797)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=536797)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=536797)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=536797)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=536797)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=536797)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=536797)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=536797)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=536797)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=536797)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=536797)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=536797)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f91481ff620>' raised:
[1;36m(EngineCore_DP0 pid=536797)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=536797)[0;0m 
[1;36m(EngineCore_DP0 pid=536797)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=536797)[0;0m 
[rank0]:[W1204 14:04:31.050596611 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:04:31.050662797 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:04:52 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:04:52 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:04:53 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:04:53 [model.py:1745] Using max model len 131072
INFO 12-04 14:04:53 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:04:53 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:04:53 [model.py:1745] Using max model len 131072
INFO 12-04 14:04:53 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=538292)[0;0m INFO 12-04 14:05:05 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=538295)[0;0m INFO 12-04 14:05:05 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=538295)[0;0m INFO 12-04 14:05:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:36943 backend=nccl
[1;36m(EngineCore_DP0 pid=538292)[0;0m INFO 12-04 14:05:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:36223 backend=nccl
[W1204 14:05:06.352527958 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:36943 (errno: 97 - Address family not supported by protocol).
[W1204 14:05:06.355452419 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:36223 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=538295)[0;0m INFO 12-04 14:05:06 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=538292)[0;0m INFO 12-04 14:05:07 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=538292)[0;0m INFO 12-04 14:05:07 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=538295)[0;0m INFO 12-04 14:05:07 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=538292)[0;0m INFO 12-04 14:05:08 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=538292)[0;0m INFO 12-04 14:05:08 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=538295)[0;0m INFO 12-04 14:05:08 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=538295)[0;0m INFO 12-04 14:05:08 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=538295)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=538292)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=538295)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=538292)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=538295)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=538295)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=538295)[0;0m 
[1;36m(EngineCore_DP0 pid=538295)[0;0m INFO 12-04 14:05:10 [default_loader.py:314] Loading weights took 1.69 seconds
[1;36m(EngineCore_DP0 pid=538292)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=538292)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=538292)[0;0m 
[1;36m(EngineCore_DP0 pid=538292)[0;0m INFO 12-04 14:05:10 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=538295)[0;0m INFO 12-04 14:05:11 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.846516 seconds
[1;36m(EngineCore_DP0 pid=538292)[0;0m INFO 12-04 14:05:11 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.915862 seconds
[1;36m(EngineCore_DP0 pid=538292)[0;0m INFO 12-04 14:05:19 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=538295)[0;0m INFO 12-04 14:05:19 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=538292)[0;0m INFO 12-04 14:05:19 [backends.py:647] Dynamo bytecode transform time: 7.81 s
[1;36m(EngineCore_DP0 pid=538295)[0;0m INFO 12-04 14:05:19 [backends.py:647] Dynamo bytecode transform time: 7.86 s
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5ea491f710>' raised:
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842] 
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=538292)[0;0m ERROR 12-04 14:05:19 [core.py:842] 
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f94842b08f0>' raised:
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842] 
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=538295)[0;0m ERROR 12-04 14:05:19 [core.py:842] 
[1;36m(EngineCore_DP0 pid=538292)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=538295)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=538292)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=538295)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=538295)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=538295)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=538292)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=538292)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=538292)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=538292)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=538292)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=538292)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=538292)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=538295)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=538295)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=538295)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=538295)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=538295)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=538295)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=538295)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=538295)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=538295)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=538295)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=538295)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=538292)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=538292)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=538292)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=538292)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=538292)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=538292)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=538292)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=538292)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=538292)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=538292)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=538292)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=538292)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=538292)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=538292)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=538292)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=538295)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=538295)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=538295)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=538295)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=538295)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=538295)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=538295)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=538295)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=538295)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=538295)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=538295)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=538295)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=538295)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=538292)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=538292)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=538292)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=538292)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=538292)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=538292)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=538292)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=538292)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=538292)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=538292)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=538292)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=538292)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=538295)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=538295)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=538295)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=538295)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=538295)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=538295)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=538295)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=538295)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=538295)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=538295)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=538295)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=538295)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=538295)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=538295)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=538295)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=538295)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=538295)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=538292)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=538292)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=538292)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=538292)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=538292)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=538292)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=538292)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=538292)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=538292)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=538292)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5ea491f710>' raised:
[1;36m(EngineCore_DP0 pid=538292)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=538292)[0;0m 
[1;36m(EngineCore_DP0 pid=538292)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=538292)[0;0m 
[1;36m(EngineCore_DP0 pid=538295)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=538295)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=538295)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f94842b08f0>' raised:
[1;36m(EngineCore_DP0 pid=538295)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=538295)[0;0m 
[1;36m(EngineCore_DP0 pid=538295)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=538295)[0;0m 
[rank0]:[W1204 14:05:20.042838405 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:05:20.043138514 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:05:41 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:05:41 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:05:42 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:05:42 [model.py:1745] Using max model len 131072
INFO 12-04 14:05:42 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:05:42 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:05:42 [model.py:1745] Using max model len 131072
INFO 12-04 14:05:42 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=539200)[0;0m INFO 12-04 14:05:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=539197)[0;0m INFO 12-04 14:05:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=539200)[0;0m INFO 12-04 14:05:56 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:40455 backend=nccl
[1;36m(EngineCore_DP0 pid=539197)[0;0m INFO 12-04 14:05:56 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:53495 backend=nccl
[W1204 14:05:56.704084735 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:40455 (errno: 97 - Address family not supported by protocol).
[W1204 14:05:56.705394057 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:53495 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=539200)[0;0m INFO 12-04 14:05:56 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=539197)[0;0m INFO 12-04 14:05:56 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=539200)[0;0m INFO 12-04 14:05:56 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=539197)[0;0m INFO 12-04 14:05:56 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=539200)[0;0m INFO 12-04 14:05:57 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=539200)[0;0m INFO 12-04 14:05:57 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=539197)[0;0m INFO 12-04 14:05:57 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=539197)[0;0m INFO 12-04 14:05:57 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=539200)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=539197)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=539200)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=539197)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.10s/it]
[1;36m(EngineCore_DP0 pid=539200)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=539200)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=539200)[0;0m 
[1;36m(EngineCore_DP0 pid=539200)[0;0m INFO 12-04 14:05:59 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=539197)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=539197)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=539197)[0;0m 
[1;36m(EngineCore_DP0 pid=539197)[0;0m INFO 12-04 14:05:59 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=539200)[0;0m INFO 12-04 14:06:00 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.709870 seconds
[1;36m(EngineCore_DP0 pid=539197)[0;0m INFO 12-04 14:06:00 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.856468 seconds
[1;36m(EngineCore_DP0 pid=539200)[0;0m INFO 12-04 14:06:08 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=539200)[0;0m INFO 12-04 14:06:08 [backends.py:647] Dynamo bytecode transform time: 7.74 s
[1;36m(EngineCore_DP0 pid=539197)[0;0m INFO 12-04 14:06:08 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=539197)[0;0m INFO 12-04 14:06:08 [backends.py:647] Dynamo bytecode transform time: 7.62 s
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f299c1f3d40>' raised:
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842] 
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=539200)[0;0m ERROR 12-04 14:06:09 [core.py:842] 
[1;36m(EngineCore_DP0 pid=539200)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=539200)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=539200)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=539200)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=539200)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=539200)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=539200)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=539200)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=539200)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=539200)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=539200)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=539200)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=539200)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=539200)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=539200)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=539200)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=539200)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=539200)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=539200)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=539200)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=539200)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=539200)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=539200)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=539200)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=539200)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=539200)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=539200)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=539200)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=539200)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=539200)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=539200)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=539200)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=539200)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=539200)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=539200)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=539200)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=539200)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=539200)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=539200)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=539200)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=539200)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=539200)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=539200)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=539200)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=539200)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539200)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=539200)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=539200)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f299c1f3d40>' raised:
[1;36m(EngineCore_DP0 pid=539200)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=539200)[0;0m 
[1;36m(EngineCore_DP0 pid=539200)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=539200)[0;0m 
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f68202984a0>' raised:
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842] 
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=539197)[0;0m ERROR 12-04 14:06:09 [core.py:842] 
[1;36m(EngineCore_DP0 pid=539197)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=539197)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=539197)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=539197)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=539197)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=539197)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=539197)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=539197)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=539197)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=539197)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=539197)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=539197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=539197)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=539197)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=539197)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=539197)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=539197)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=539197)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=539197)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=539197)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=539197)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=539197)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=539197)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=539197)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=539197)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=539197)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=539197)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=539197)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=539197)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=539197)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=539197)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=539197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=539197)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=539197)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=539197)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=539197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=539197)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=539197)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=539197)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=539197)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=539197)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=539197)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=539197)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=539197)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=539197)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=539197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=539197)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=539197)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f68202984a0>' raised:
[1;36m(EngineCore_DP0 pid=539197)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=539197)[0;0m 
[1;36m(EngineCore_DP0 pid=539197)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=539197)[0;0m 
[rank0]:[W1204 14:06:09.191124044 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:06:09.261568051 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:06:30 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:06:31 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:06:31 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:06:31 [model.py:1745] Using max model len 131072
INFO 12-04 14:06:31 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:06:31 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:06:31 [model.py:1745] Using max model len 131072
INFO 12-04 14:06:31 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=540926)[0;0m INFO 12-04 14:06:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=540929)[0;0m INFO 12-04 14:06:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=540929)[0;0m INFO 12-04 14:06:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:50121 backend=nccl
[1;36m(EngineCore_DP0 pid=540926)[0;0m INFO 12-04 14:06:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:38629 backend=nccl
[W1204 14:06:45.840993630 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:50121 (errno: 97 - Address family not supported by protocol).
[W1204 14:06:45.842499584 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:38629 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=540929)[0;0m INFO 12-04 14:06:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=540926)[0;0m INFO 12-04 14:06:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=540926)[0;0m INFO 12-04 14:06:45 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=540929)[0;0m INFO 12-04 14:06:45 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=540926)[0;0m INFO 12-04 14:06:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=540926)[0;0m INFO 12-04 14:06:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=540929)[0;0m INFO 12-04 14:06:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=540929)[0;0m INFO 12-04 14:06:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=540929)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=540926)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=540929)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=540926)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=540929)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=540929)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=540929)[0;0m 
[1;36m(EngineCore_DP0 pid=540929)[0;0m INFO 12-04 14:06:49 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=540926)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=540926)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=540926)[0;0m 
[1;36m(EngineCore_DP0 pid=540926)[0;0m INFO 12-04 14:06:49 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=540929)[0;0m INFO 12-04 14:06:49 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.797851 seconds
[1;36m(EngineCore_DP0 pid=540926)[0;0m INFO 12-04 14:06:49 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.925639 seconds
[1;36m(EngineCore_DP0 pid=540929)[0;0m INFO 12-04 14:06:58 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=540929)[0;0m INFO 12-04 14:06:58 [backends.py:647] Dynamo bytecode transform time: 8.34 s
[1;36m(EngineCore_DP0 pid=540926)[0;0m INFO 12-04 14:06:58 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=540926)[0;0m INFO 12-04 14:06:58 [backends.py:647] Dynamo bytecode transform time: 8.23 s
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f1e20179f40>' raised:
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=540929)[0;0m ERROR 12-04 14:06:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=540929)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=540929)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=540929)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=540929)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=540929)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=540929)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=540929)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=540929)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=540929)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=540929)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=540929)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=540929)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=540929)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=540929)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=540929)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=540929)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=540929)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=540929)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=540929)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=540929)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=540929)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=540929)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=540929)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=540929)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=540929)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=540929)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=540929)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=540929)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=540929)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=540929)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=540929)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=540929)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=540929)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=540929)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=540929)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=540929)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=540929)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=540929)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=540929)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=540929)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=540929)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=540929)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=540929)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=540929)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=540929)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540929)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=540929)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=540929)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f1e20179f40>' raised:
[1;36m(EngineCore_DP0 pid=540929)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=540929)[0;0m 
[1;36m(EngineCore_DP0 pid=540929)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=540929)[0;0m 
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fdd240517c0>' raised:
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=540926)[0;0m ERROR 12-04 14:06:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=540926)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=540926)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=540926)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=540926)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=540926)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=540926)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=540926)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=540926)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=540926)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=540926)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=540926)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=540926)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=540926)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=540926)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=540926)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=540926)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=540926)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=540926)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=540926)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=540926)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=540926)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=540926)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=540926)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=540926)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=540926)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=540926)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=540926)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=540926)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=540926)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=540926)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=540926)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=540926)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=540926)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=540926)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=540926)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=540926)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=540926)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=540926)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=540926)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=540926)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=540926)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=540926)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=540926)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=540926)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=540926)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=540926)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=540926)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=540926)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fdd240517c0>' raised:
[1;36m(EngineCore_DP0 pid=540926)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=540926)[0;0m 
[1;36m(EngineCore_DP0 pid=540926)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=540926)[0;0m 
[rank0]:[W1204 14:06:59.073241588 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:06:59.081403539 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:07:20 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:07:20 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:07:21 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:07:21 [model.py:1745] Using max model len 131072
INFO 12-04 14:07:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:07:21 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:07:21 [model.py:1745] Using max model len 131072
INFO 12-04 14:07:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=541950)[0;0m INFO 12-04 14:07:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=541953)[0;0m INFO 12-04 14:07:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=541950)[0;0m INFO 12-04 14:07:37 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:50045 backend=nccl
[1;36m(EngineCore_DP0 pid=541953)[0;0m INFO 12-04 14:07:37 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:35499 backend=nccl
[W1204 14:07:37.198125712 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:50045 (errno: 97 - Address family not supported by protocol).
[W1204 14:07:37.198388885 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:35499 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=541953)[0;0m INFO 12-04 14:07:37 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=541950)[0;0m INFO 12-04 14:07:37 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=541950)[0;0m INFO 12-04 14:07:38 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=541953)[0;0m INFO 12-04 14:07:38 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=541950)[0;0m INFO 12-04 14:07:39 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=541950)[0;0m INFO 12-04 14:07:39 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=541953)[0;0m INFO 12-04 14:07:39 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=541953)[0;0m INFO 12-04 14:07:39 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=541953)[0;0m INFO 12-04 14:07:40 [weight_utils.py:441] Time spent downloading weights for meta-llama/Llama-3.2-3B-Instruct: 0.561258 seconds
[1;36m(EngineCore_DP0 pid=541953)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=541950)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=541953)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.12s/it]
[1;36m(EngineCore_DP0 pid=541950)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.10s/it]
[1;36m(EngineCore_DP0 pid=541953)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=541953)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=541953)[0;0m 
[1;36m(EngineCore_DP0 pid=541953)[0;0m INFO 12-04 14:07:41 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=541950)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=541950)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=541950)[0;0m 
[1;36m(EngineCore_DP0 pid=541950)[0;0m INFO 12-04 14:07:41 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=541953)[0;0m INFO 12-04 14:07:42 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.258638 seconds
[1;36m(EngineCore_DP0 pid=541950)[0;0m INFO 12-04 14:07:42 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.377655 seconds
[1;36m(EngineCore_DP0 pid=541953)[0;0m INFO 12-04 14:07:50 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=541953)[0;0m INFO 12-04 14:07:50 [backends.py:647] Dynamo bytecode transform time: 7.92 s
[1;36m(EngineCore_DP0 pid=541950)[0;0m INFO 12-04 14:07:50 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=541950)[0;0m INFO 12-04 14:07:50 [backends.py:647] Dynamo bytecode transform time: 7.87 s
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5d5013a540>' raised:
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=541953)[0;0m ERROR 12-04 14:07:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=541953)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=541953)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=541953)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=541953)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=541953)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=541953)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=541953)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=541953)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=541953)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=541953)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=541953)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=541953)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=541953)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=541953)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=541953)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=541953)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=541953)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=541953)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=541953)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=541953)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=541953)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=541953)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=541953)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=541953)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=541953)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=541953)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=541953)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=541953)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=541953)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=541953)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=541953)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=541953)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=541953)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=541953)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=541953)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=541953)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=541953)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=541953)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=541953)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=541953)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=541953)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=541953)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=541953)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=541953)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=541953)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541953)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=541953)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=541953)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5d5013a540>' raised:
[1;36m(EngineCore_DP0 pid=541953)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=541953)[0;0m 
[1;36m(EngineCore_DP0 pid=541953)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=541953)[0;0m 
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f88394b3d40>' raised:
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=541950)[0;0m ERROR 12-04 14:07:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=541950)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=541950)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=541950)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=541950)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=541950)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=541950)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=541950)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=541950)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=541950)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=541950)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=541950)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=541950)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=541950)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=541950)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=541950)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=541950)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=541950)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=541950)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=541950)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=541950)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=541950)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=541950)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=541950)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=541950)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=541950)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=541950)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=541950)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=541950)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=541950)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=541950)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=541950)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=541950)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=541950)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=541950)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=541950)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=541950)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=541950)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=541950)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=541950)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=541950)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=541950)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=541950)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=541950)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=541950)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=541950)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=541950)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=541950)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=541950)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f88394b3d40>' raised:
[1;36m(EngineCore_DP0 pid=541950)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=541950)[0;0m 
[1;36m(EngineCore_DP0 pid=541950)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=541950)[0;0m 
[rank0]:[W1204 14:07:51.373380304 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:07:52.415976173 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:08:13 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:08:13 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:08:13 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:08:13 [model.py:1745] Using max model len 131072
INFO 12-04 14:08:13 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:08:13 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:08:13 [model.py:1745] Using max model len 131072
INFO 12-04 14:08:13 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=543849)[0;0m INFO 12-04 14:08:25 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=543856)[0;0m INFO 12-04 14:08:25 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=543849)[0;0m INFO 12-04 14:08:26 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:48983 backend=nccl
[W1204 14:08:26.921397511 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:48983 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=543849)[0;0m INFO 12-04 14:08:26 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=543849)[0;0m INFO 12-04 14:08:26 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=543856)[0;0m INFO 12-04 14:08:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:53011 backend=nccl
[W1204 14:08:27.599632154 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:53011 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=543856)[0;0m INFO 12-04 14:08:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=543856)[0;0m INFO 12-04 14:08:27 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=543849)[0;0m INFO 12-04 14:08:27 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=543849)[0;0m INFO 12-04 14:08:27 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=543849)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=543856)[0;0m INFO 12-04 14:08:28 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=543856)[0;0m INFO 12-04 14:08:28 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=543856)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=543849)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.00it/s]
[1;36m(EngineCore_DP0 pid=543849)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.39it/s]
[1;36m(EngineCore_DP0 pid=543849)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=543849)[0;0m 
[1;36m(EngineCore_DP0 pid=543849)[0;0m INFO 12-04 14:08:29 [default_loader.py:314] Loading weights took 1.58 seconds
[1;36m(EngineCore_DP0 pid=543856)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.07s/it]
[1;36m(EngineCore_DP0 pid=543849)[0;0m INFO 12-04 14:08:30 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.742479 seconds
[1;36m(EngineCore_DP0 pid=543856)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=543856)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
[1;36m(EngineCore_DP0 pid=543856)[0;0m 
[1;36m(EngineCore_DP0 pid=543856)[0;0m INFO 12-04 14:08:30 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=543856)[0;0m INFO 12-04 14:08:31 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.740261 seconds
[1;36m(EngineCore_DP0 pid=543849)[0;0m INFO 12-04 14:08:38 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=543849)[0;0m INFO 12-04 14:08:38 [backends.py:647] Dynamo bytecode transform time: 7.89 s
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fdec41d8ec0>' raised:
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842] 
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=543849)[0;0m ERROR 12-04 14:08:38 [core.py:842] 
[1;36m(EngineCore_DP0 pid=543849)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=543849)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=543849)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=543849)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=543849)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=543849)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=543849)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=543849)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=543849)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=543849)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=543849)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=543849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=543849)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=543849)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=543849)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=543849)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=543849)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=543849)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=543849)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=543849)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=543849)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=543849)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=543849)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=543849)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=543849)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=543849)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=543849)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=543849)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=543849)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=543849)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=543849)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=543849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=543849)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=543849)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=543849)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=543849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=543849)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=543849)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=543849)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=543849)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=543849)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=543849)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=543849)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=543849)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=543849)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=543849)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=543849)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fdec41d8ec0>' raised:
[1;36m(EngineCore_DP0 pid=543849)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=543849)[0;0m 
[1;36m(EngineCore_DP0 pid=543849)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=543849)[0;0m 
[1;36m(EngineCore_DP0 pid=543856)[0;0m INFO 12-04 14:08:39 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=543856)[0;0m INFO 12-04 14:08:39 [backends.py:647] Dynamo bytecode transform time: 7.57 s
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f84b981bf80>' raised:
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842] 
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=543856)[0;0m ERROR 12-04 14:08:39 [core.py:842] 
[1;36m(EngineCore_DP0 pid=543856)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=543856)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=543856)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=543856)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=543856)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=543856)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=543856)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=543856)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=543856)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=543856)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=543856)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=543856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=543856)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=543856)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=543856)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=543856)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=543856)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=543856)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=543856)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=543856)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=543856)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=543856)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=543856)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=543856)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=543856)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=543856)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=543856)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=543856)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=543856)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=543856)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=543856)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=543856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=543856)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=543856)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=543856)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=543856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=543856)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=543856)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=543856)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=543856)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=543856)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=543856)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=543856)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=543856)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=543856)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=543856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=543856)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=543856)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f84b981bf80>' raised:
[1;36m(EngineCore_DP0 pid=543856)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=543856)[0;0m 
[1;36m(EngineCore_DP0 pid=543856)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=543856)[0;0m 
[rank0]:[W1204 14:08:39.076770875 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:08:40.642200308 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:09:00 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:09:00 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:09:00 [model.py:1745] Using max model len 131072
INFO 12-04 14:09:00 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:09:01 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:09:01 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:09:01 [model.py:1745] Using max model len 131072
INFO 12-04 14:09:01 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=546174)[0;0m INFO 12-04 14:09:15 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=546095)[0;0m INFO 12-04 14:09:15 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=546174)[0;0m INFO 12-04 14:09:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:43423 backend=nccl
[1;36m(EngineCore_DP0 pid=546095)[0;0m INFO 12-04 14:09:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:56365 backend=nccl
[W1204 14:09:16.007602421 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:43423 (errno: 97 - Address family not supported by protocol).
[W1204 14:09:16.009107614 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:56365 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=546095)[0;0m INFO 12-04 14:09:16 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=546174)[0;0m INFO 12-04 14:09:16 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=546095)[0;0m INFO 12-04 14:09:17 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=546174)[0;0m INFO 12-04 14:09:17 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=546095)[0;0m INFO 12-04 14:09:18 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=546095)[0;0m INFO 12-04 14:09:18 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=546174)[0;0m INFO 12-04 14:09:18 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=546174)[0;0m INFO 12-04 14:09:18 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=546095)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=546174)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=546095)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=546174)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.12s/it]
[1;36m(EngineCore_DP0 pid=546095)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=546095)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=546095)[0;0m 
[1;36m(EngineCore_DP0 pid=546095)[0;0m INFO 12-04 14:09:20 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=546174)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=546174)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=546174)[0;0m 
[1;36m(EngineCore_DP0 pid=546174)[0;0m INFO 12-04 14:09:20 [default_loader.py:314] Loading weights took 1.69 seconds
[1;36m(EngineCore_DP0 pid=546095)[0;0m INFO 12-04 14:09:20 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.788230 seconds
[1;36m(EngineCore_DP0 pid=546174)[0;0m INFO 12-04 14:09:20 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.838664 seconds
[1;36m(EngineCore_DP0 pid=546095)[0;0m INFO 12-04 14:09:29 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=546095)[0;0m INFO 12-04 14:09:29 [backends.py:647] Dynamo bytecode transform time: 7.85 s
[1;36m(EngineCore_DP0 pid=546174)[0;0m INFO 12-04 14:09:29 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=546174)[0;0m INFO 12-04 14:09:29 [backends.py:647] Dynamo bytecode transform time: 7.80 s
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fca101d2f30>' raised:
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=546095)[0;0m ERROR 12-04 14:09:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=546095)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=546095)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=546095)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=546095)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=546095)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=546095)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=546095)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=546095)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=546095)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=546095)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=546095)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=546095)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=546095)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=546095)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=546095)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=546095)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=546095)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=546095)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=546095)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=546095)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=546095)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=546095)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=546095)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=546095)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=546095)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=546095)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=546095)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=546095)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=546095)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=546095)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=546095)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=546095)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=546095)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=546095)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=546095)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=546095)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=546095)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=546095)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=546095)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=546095)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=546095)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=546095)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=546095)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=546095)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=546095)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546095)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=546095)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=546095)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fca101d2f30>' raised:
[1;36m(EngineCore_DP0 pid=546095)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=546095)[0;0m 
[1;36m(EngineCore_DP0 pid=546095)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=546095)[0;0m 
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f0938213d70>' raised:
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=546174)[0;0m ERROR 12-04 14:09:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=546174)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=546174)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=546174)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=546174)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=546174)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=546174)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=546174)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=546174)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=546174)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=546174)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=546174)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=546174)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=546174)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=546174)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=546174)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=546174)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=546174)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=546174)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=546174)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=546174)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=546174)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=546174)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=546174)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=546174)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=546174)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=546174)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=546174)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=546174)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=546174)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=546174)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=546174)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=546174)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=546174)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=546174)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=546174)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=546174)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=546174)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=546174)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=546174)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=546174)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=546174)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=546174)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=546174)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=546174)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=546174)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=546174)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=546174)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=546174)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f0938213d70>' raised:
[1;36m(EngineCore_DP0 pid=546174)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=546174)[0;0m 
[1;36m(EngineCore_DP0 pid=546174)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=546174)[0;0m 
[rank0]:[W1204 14:09:30.898258202 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:09:30.945519063 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:09:51 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:09:51 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:09:51 [model.py:1745] Using max model len 131072
INFO 12-04 14:09:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:09:51 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:09:52 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:09:52 [model.py:1745] Using max model len 131072
INFO 12-04 14:09:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=547264)[0;0m INFO 12-04 14:10:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=547267)[0;0m INFO 12-04 14:10:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=547264)[0;0m INFO 12-04 14:10:05 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:48749 backend=nccl
[W1204 14:10:05.000233163 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:48749 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=547267)[0;0m INFO 12-04 14:10:05 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:51539 backend=nccl
[W1204 14:10:05.022849090 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:51539 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=547264)[0;0m INFO 12-04 14:10:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=547267)[0;0m INFO 12-04 14:10:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=547264)[0;0m INFO 12-04 14:10:06 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=547267)[0;0m INFO 12-04 14:10:06 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=547264)[0;0m INFO 12-04 14:10:07 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=547264)[0;0m INFO 12-04 14:10:07 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=547267)[0;0m INFO 12-04 14:10:07 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=547267)[0;0m INFO 12-04 14:10:07 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=547267)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=547264)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=547267)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=547264)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.10s/it]
[1;36m(EngineCore_DP0 pid=547267)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=547267)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=547267)[0;0m 
[1;36m(EngineCore_DP0 pid=547267)[0;0m INFO 12-04 14:10:09 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=547264)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=547264)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
[1;36m(EngineCore_DP0 pid=547264)[0;0m 
[1;36m(EngineCore_DP0 pid=547264)[0;0m INFO 12-04 14:10:09 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=547267)[0;0m INFO 12-04 14:10:09 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.749665 seconds
[1;36m(EngineCore_DP0 pid=547264)[0;0m INFO 12-04 14:10:09 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.896753 seconds
[1;36m(EngineCore_DP0 pid=547267)[0;0m INFO 12-04 14:10:17 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=547264)[0;0m INFO 12-04 14:10:17 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=547267)[0;0m INFO 12-04 14:10:17 [backends.py:647] Dynamo bytecode transform time: 7.82 s
[1;36m(EngineCore_DP0 pid=547264)[0;0m INFO 12-04 14:10:17 [backends.py:647] Dynamo bytecode transform time: 7.77 s
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f28b411e360>' raised:
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842] 
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=547264)[0;0m ERROR 12-04 14:10:18 [core.py:842] 
[1;36m(EngineCore_DP0 pid=547264)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=547264)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=547264)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=547264)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=547264)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=547264)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=547264)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=547264)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=547264)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=547264)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=547264)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=547264)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=547264)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=547264)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=547264)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=547264)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=547264)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=547264)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fea94123d40>' raised:
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842] 
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=547267)[0;0m ERROR 12-04 14:10:18 [core.py:842] 
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=547264)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=547264)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=547264)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=547264)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=547264)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=547264)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=547264)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=547264)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=547264)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=547264)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=547264)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=547264)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=547264)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=547264)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=547264)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=547264)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=547264)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=547264)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=547264)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=547264)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=547264)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=547264)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=547264)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=547264)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=547264)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=547264)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=547264)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547264)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=547264)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=547264)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f28b411e360>' raised:
[1;36m(EngineCore_DP0 pid=547264)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=547264)[0;0m 
[1;36m(EngineCore_DP0 pid=547264)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=547264)[0;0m 
[1;36m(EngineCore_DP0 pid=547267)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=547267)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=547267)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=547267)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=547267)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=547267)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=547267)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=547267)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=547267)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=547267)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=547267)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=547267)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=547267)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=547267)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=547267)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=547267)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=547267)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=547267)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=547267)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=547267)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=547267)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=547267)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=547267)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=547267)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=547267)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=547267)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=547267)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=547267)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=547267)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=547267)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=547267)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=547267)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=547267)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=547267)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=547267)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=547267)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=547267)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=547267)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=547267)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=547267)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=547267)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=547267)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=547267)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=547267)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=547267)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=547267)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=547267)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=547267)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fea94123d40>' raised:
[1;36m(EngineCore_DP0 pid=547267)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=547267)[0;0m 
[1;36m(EngineCore_DP0 pid=547267)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=547267)[0;0m 
[rank0]:[W1204 14:10:19.575619017 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:10:19.579745138 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:10:40 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:10:40 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:10:40 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:10:40 [model.py:1745] Using max model len 131072
INFO 12-04 14:10:40 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:10:40 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:10:40 [model.py:1745] Using max model len 131072
INFO 12-04 14:10:40 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=548831)[0;0m INFO 12-04 14:10:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=548828)[0;0m INFO 12-04 14:10:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=548828)[0;0m INFO 12-04 14:10:55 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:57351 backend=nccl
[1;36m(EngineCore_DP0 pid=548831)[0;0m INFO 12-04 14:10:55 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:48587 backend=nccl
[W1204 14:10:56.408807816 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:57351 (errno: 97 - Address family not supported by protocol).
[W1204 14:10:56.411657182 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:48587 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=548831)[0;0m INFO 12-04 14:10:56 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=548828)[0;0m INFO 12-04 14:10:56 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=548831)[0;0m INFO 12-04 14:10:56 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=548828)[0;0m INFO 12-04 14:10:56 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=548828)[0;0m INFO 12-04 14:10:57 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=548828)[0;0m INFO 12-04 14:10:57 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=548831)[0;0m INFO 12-04 14:10:57 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=548831)[0;0m INFO 12-04 14:10:57 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=548831)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=548828)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=548831)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=548828)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=548831)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=548831)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=548831)[0;0m 
[1;36m(EngineCore_DP0 pid=548831)[0;0m INFO 12-04 14:10:59 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=548828)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=548828)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=548828)[0;0m 
[1;36m(EngineCore_DP0 pid=548828)[0;0m INFO 12-04 14:10:59 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=548831)[0;0m INFO 12-04 14:11:00 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.753812 seconds
[1;36m(EngineCore_DP0 pid=548828)[0;0m INFO 12-04 14:11:00 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.861525 seconds
[1;36m(EngineCore_DP0 pid=548831)[0;0m INFO 12-04 14:11:08 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=548831)[0;0m INFO 12-04 14:11:08 [backends.py:647] Dynamo bytecode transform time: 7.87 s
[1;36m(EngineCore_DP0 pid=548828)[0;0m INFO 12-04 14:11:08 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=548828)[0;0m INFO 12-04 14:11:08 [backends.py:647] Dynamo bytecode transform time: 7.84 s
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fe4681109b0>' raised:
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842] 
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=548831)[0;0m ERROR 12-04 14:11:08 [core.py:842] 
[1;36m(EngineCore_DP0 pid=548831)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=548831)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=548831)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=548831)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=548831)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=548831)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=548831)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=548831)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=548831)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=548831)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=548831)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=548831)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=548831)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=548831)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=548831)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=548831)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=548831)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=548831)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=548831)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=548831)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=548831)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=548831)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=548831)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=548831)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=548831)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=548831)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=548831)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=548831)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=548831)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=548831)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=548831)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=548831)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=548831)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=548831)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=548831)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=548831)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=548831)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=548831)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=548831)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=548831)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=548831)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=548831)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=548831)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=548831)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=548831)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548831)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=548831)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=548831)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fe4681109b0>' raised:
[1;36m(EngineCore_DP0 pid=548831)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=548831)[0;0m 
[1;36m(EngineCore_DP0 pid=548831)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=548831)[0;0m 
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc0a15af8c0>' raised:
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842] 
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=548828)[0;0m ERROR 12-04 14:11:08 [core.py:842] 
[1;36m(EngineCore_DP0 pid=548828)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=548828)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=548828)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=548828)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=548828)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=548828)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=548828)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=548828)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=548828)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=548828)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=548828)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=548828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=548828)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=548828)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=548828)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=548828)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=548828)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=548828)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=548828)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=548828)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=548828)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=548828)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=548828)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=548828)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=548828)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=548828)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=548828)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=548828)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=548828)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=548828)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=548828)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=548828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=548828)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=548828)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=548828)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=548828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=548828)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=548828)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=548828)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=548828)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=548828)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=548828)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=548828)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=548828)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=548828)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=548828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=548828)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=548828)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc0a15af8c0>' raised:
[1;36m(EngineCore_DP0 pid=548828)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=548828)[0;0m 
[1;36m(EngineCore_DP0 pid=548828)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=548828)[0;0m 
[rank0]:[W1204 14:11:09.110596242 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:11:09.124431564 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:11:30 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:11:30 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:11:31 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:11:31 [model.py:1745] Using max model len 131072
INFO 12-04 14:11:31 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:11:31 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:11:31 [model.py:1745] Using max model len 131072
INFO 12-04 14:11:31 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=549713)[0;0m INFO 12-04 14:11:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=549710)[0;0m INFO 12-04 14:11:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=549710)[0;0m INFO 12-04 14:11:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:33781 backend=nccl
[1;36m(EngineCore_DP0 pid=549713)[0;0m INFO 12-04 14:11:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:54529 backend=nccl
[W1204 14:11:45.046616619 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:33781 (errno: 97 - Address family not supported by protocol).
[W1204 14:11:45.048810202 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:54529 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=549710)[0;0m INFO 12-04 14:11:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=549713)[0;0m INFO 12-04 14:11:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=549710)[0;0m INFO 12-04 14:11:46 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=549713)[0;0m INFO 12-04 14:11:46 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=549710)[0;0m INFO 12-04 14:11:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=549710)[0;0m INFO 12-04 14:11:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=549713)[0;0m INFO 12-04 14:11:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=549713)[0;0m INFO 12-04 14:11:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=549713)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=549710)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=549713)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=549710)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=549713)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=549713)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=549713)[0;0m 
[1;36m(EngineCore_DP0 pid=549713)[0;0m INFO 12-04 14:11:49 [default_loader.py:314] Loading weights took 1.72 seconds
[1;36m(EngineCore_DP0 pid=549710)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=549710)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=549710)[0;0m 
[1;36m(EngineCore_DP0 pid=549710)[0;0m INFO 12-04 14:11:49 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=549713)[0;0m INFO 12-04 14:11:49 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.922339 seconds
[1;36m(EngineCore_DP0 pid=549710)[0;0m INFO 12-04 14:11:50 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.005543 seconds
[1;36m(EngineCore_DP0 pid=549710)[0;0m INFO 12-04 14:11:58 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=549710)[0;0m INFO 12-04 14:11:58 [backends.py:647] Dynamo bytecode transform time: 8.00 s
[1;36m(EngineCore_DP0 pid=549713)[0;0m INFO 12-04 14:11:58 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=549713)[0;0m INFO 12-04 14:11:58 [backends.py:647] Dynamo bytecode transform time: 8.08 s
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f22dc23a7e0>' raised:
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=549713)[0;0m ERROR 12-04 14:11:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f65f4260d70>' raised:
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=549710)[0;0m ERROR 12-04 14:11:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=549713)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=549710)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=549713)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=549713)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=549713)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=549713)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=549713)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=549713)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=549713)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=549713)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=549713)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=549713)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=549713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=549713)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=549713)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=549713)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=549713)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=549713)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=549713)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=549713)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=549713)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=549713)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=549713)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=549713)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=549713)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=549713)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=549713)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=549713)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=549713)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=549713)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=549713)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=549713)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=549713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=549713)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=549713)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=549713)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=549713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=549713)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=549713)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=549713)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=549713)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=549713)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=549713)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=549713)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=549713)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=549713)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=549713)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=549713)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f22dc23a7e0>' raised:
[1;36m(EngineCore_DP0 pid=549713)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=549713)[0;0m 
[1;36m(EngineCore_DP0 pid=549713)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=549713)[0;0m 
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=549710)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=549710)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=549710)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=549710)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=549710)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=549710)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=549710)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=549710)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=549710)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=549710)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=549710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=549710)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=549710)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=549710)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=549710)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=549710)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=549710)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=549710)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=549710)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=549710)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=549710)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=549710)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=549710)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=549710)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=549710)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=549710)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=549710)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=549710)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=549710)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=549710)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=549710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=549710)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=549710)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=549710)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=549710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=549710)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=549710)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=549710)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=549710)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=549710)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=549710)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=549710)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=549710)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=549710)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=549710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=549710)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=549710)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f65f4260d70>' raised:
[1;36m(EngineCore_DP0 pid=549710)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=549710)[0;0m 
[1;36m(EngineCore_DP0 pid=549710)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=549710)[0;0m 
[rank0]:[W1204 14:11:59.115788105 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:11:59.137896891 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:12:20 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:12:21 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:12:21 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:12:21 [model.py:1745] Using max model len 131072
INFO 12-04 14:12:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:12:21 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:12:21 [model.py:1745] Using max model len 131072
INFO 12-04 14:12:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=551360)[0;0m INFO 12-04 14:12:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=551363)[0;0m INFO 12-04 14:12:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=551360)[0;0m INFO 12-04 14:12:36 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:42295 backend=nccl
[1;36m(EngineCore_DP0 pid=551363)[0;0m INFO 12-04 14:12:36 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:33907 backend=nccl
[W1204 14:12:36.202710279 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:42295 (errno: 97 - Address family not supported by protocol).
[W1204 14:12:36.205297777 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:33907 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=551360)[0;0m INFO 12-04 14:12:36 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=551363)[0;0m INFO 12-04 14:12:36 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=551360)[0;0m INFO 12-04 14:12:37 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=551363)[0;0m INFO 12-04 14:12:37 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=551363)[0;0m INFO 12-04 14:12:38 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=551363)[0;0m INFO 12-04 14:12:38 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=551360)[0;0m INFO 12-04 14:12:38 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=551360)[0;0m INFO 12-04 14:12:38 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=551363)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=551360)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=551363)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=551360)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.10s/it]
[1;36m(EngineCore_DP0 pid=551363)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=551363)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=551363)[0;0m 
[1;36m(EngineCore_DP0 pid=551363)[0;0m INFO 12-04 14:12:40 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=551360)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=551360)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=551360)[0;0m 
[1;36m(EngineCore_DP0 pid=551360)[0;0m INFO 12-04 14:12:40 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=551363)[0;0m INFO 12-04 14:12:40 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.884296 seconds
[1;36m(EngineCore_DP0 pid=551360)[0;0m INFO 12-04 14:12:41 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.963630 seconds
[1;36m(EngineCore_DP0 pid=551363)[0;0m INFO 12-04 14:12:49 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=551363)[0;0m INFO 12-04 14:12:49 [backends.py:647] Dynamo bytecode transform time: 8.04 s
[1;36m(EngineCore_DP0 pid=551360)[0;0m INFO 12-04 14:12:49 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=551360)[0;0m INFO 12-04 14:12:49 [backends.py:647] Dynamo bytecode transform time: 8.00 s
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f1b9422b9b0>' raised:
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842] 
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=551363)[0;0m ERROR 12-04 14:12:49 [core.py:842] 
[1;36m(EngineCore_DP0 pid=551363)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=551363)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=551363)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=551363)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=551363)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=551363)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=551363)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=551363)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=551363)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=551363)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=551363)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=551363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=551363)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=551363)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=551363)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=551363)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=551363)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=551363)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=551363)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=551363)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=551363)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=551363)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=551363)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=551363)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=551363)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=551363)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=551363)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=551363)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=551363)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=551363)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=551363)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=551363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=551363)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=551363)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=551363)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=551363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=551363)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=551363)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=551363)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=551363)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=551363)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=551363)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=551363)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=551363)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=551363)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=551363)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=551363)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f1b9422b9b0>' raised:
[1;36m(EngineCore_DP0 pid=551363)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=551363)[0;0m 
[1;36m(EngineCore_DP0 pid=551363)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=551363)[0;0m 
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd2a4082960>' raised:
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842] 
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=551360)[0;0m ERROR 12-04 14:12:49 [core.py:842] 
[1;36m(EngineCore_DP0 pid=551360)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=551360)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=551360)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=551360)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=551360)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=551360)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=551360)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=551360)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=551360)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=551360)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=551360)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=551360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=551360)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=551360)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=551360)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=551360)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=551360)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=551360)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=551360)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=551360)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=551360)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=551360)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=551360)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=551360)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=551360)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=551360)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=551360)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=551360)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=551360)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=551360)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=551360)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=551360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=551360)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=551360)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=551360)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=551360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=551360)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=551360)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=551360)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=551360)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=551360)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=551360)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=551360)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=551360)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=551360)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=551360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=551360)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=551360)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd2a4082960>' raised:
[1;36m(EngineCore_DP0 pid=551360)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=551360)[0;0m 
[1;36m(EngineCore_DP0 pid=551360)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=551360)[0;0m 
[rank0]:[W1204 14:12:50.125263899 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:12:50.147187283 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:13:11 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:13:12 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:13:12 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:13:12 [model.py:1745] Using max model len 131072
INFO 12-04 14:13:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:13:12 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:13:12 [model.py:1745] Using max model len 131072
INFO 12-04 14:13:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=552688)[0;0m INFO 12-04 14:13:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=552691)[0;0m INFO 12-04 14:13:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=552688)[0;0m INFO 12-04 14:13:28 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:47213 backend=nccl
[1;36m(EngineCore_DP0 pid=552691)[0;0m INFO 12-04 14:13:28 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:36743 backend=nccl
[W1204 14:13:28.904065598 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:47213 (errno: 97 - Address family not supported by protocol).
[W1204 14:13:28.908074941 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:36743 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=552688)[0;0m INFO 12-04 14:13:28 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=552691)[0;0m INFO 12-04 14:13:28 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=552688)[0;0m INFO 12-04 14:13:28 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=552691)[0;0m INFO 12-04 14:13:28 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=552688)[0;0m INFO 12-04 14:13:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=552688)[0;0m INFO 12-04 14:13:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=552691)[0;0m INFO 12-04 14:13:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=552691)[0;0m INFO 12-04 14:13:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=552688)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=552691)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=552688)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=552691)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.12s/it]
[1;36m(EngineCore_DP0 pid=552688)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=552688)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=552688)[0;0m 
[1;36m(EngineCore_DP0 pid=552688)[0;0m INFO 12-04 14:13:32 [default_loader.py:314] Loading weights took 1.69 seconds
[1;36m(EngineCore_DP0 pid=552691)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=552691)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=552691)[0;0m 
[1;36m(EngineCore_DP0 pid=552691)[0;0m INFO 12-04 14:13:32 [default_loader.py:314] Loading weights took 1.69 seconds
[1;36m(EngineCore_DP0 pid=552688)[0;0m INFO 12-04 14:13:32 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.792520 seconds
[1;36m(EngineCore_DP0 pid=552691)[0;0m INFO 12-04 14:13:32 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.893329 seconds
[1;36m(EngineCore_DP0 pid=552688)[0;0m INFO 12-04 14:13:40 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=552688)[0;0m INFO 12-04 14:13:40 [backends.py:647] Dynamo bytecode transform time: 7.91 s
[1;36m(EngineCore_DP0 pid=552691)[0;0m INFO 12-04 14:13:40 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=552691)[0;0m INFO 12-04 14:13:40 [backends.py:647] Dynamo bytecode transform time: 7.90 s
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc6f42a2ba0>' raised:
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=552688)[0;0m ERROR 12-04 14:13:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=552688)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=552688)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=552688)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=552688)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=552688)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=552688)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=552688)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=552688)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=552688)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=552688)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=552688)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=552688)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=552688)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=552688)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=552688)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=552688)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=552688)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=552688)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=552688)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=552688)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=552688)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=552688)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=552688)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=552688)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=552688)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=552688)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=552688)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=552688)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=552688)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=552688)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=552688)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=552688)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=552688)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=552688)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=552688)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=552688)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=552688)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=552688)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=552688)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=552688)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=552688)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=552688)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=552688)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=552688)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=552688)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552688)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=552688)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=552688)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc6f42a2ba0>' raised:
[1;36m(EngineCore_DP0 pid=552688)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=552688)[0;0m 
[1;36m(EngineCore_DP0 pid=552688)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=552688)[0;0m 
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb72025b830>' raised:
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=552691)[0;0m ERROR 12-04 14:13:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=552691)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=552691)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=552691)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=552691)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=552691)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=552691)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=552691)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=552691)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=552691)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=552691)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=552691)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=552691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=552691)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=552691)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=552691)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=552691)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=552691)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=552691)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=552691)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=552691)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=552691)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=552691)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=552691)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=552691)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=552691)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=552691)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=552691)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=552691)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=552691)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=552691)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=552691)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=552691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=552691)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=552691)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=552691)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=552691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=552691)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=552691)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=552691)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=552691)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=552691)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=552691)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=552691)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=552691)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=552691)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=552691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=552691)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=552691)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb72025b830>' raised:
[1;36m(EngineCore_DP0 pid=552691)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=552691)[0;0m 
[1;36m(EngineCore_DP0 pid=552691)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=552691)[0;0m 
[rank0]:[W1204 14:13:42.663591625 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:13:42.754662157 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:14:03 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:14:03 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:14:03 [model.py:1745] Using max model len 131072
INFO 12-04 14:14:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:14:03 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:14:03 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:14:03 [model.py:1745] Using max model len 131072
INFO 12-04 14:14:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=554142)[0;0m INFO 12-04 14:14:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=554145)[0;0m INFO 12-04 14:14:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=554142)[0;0m INFO 12-04 14:14:19 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:38743 backend=nccl
[1;36m(EngineCore_DP0 pid=554145)[0;0m INFO 12-04 14:14:19 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:49727 backend=nccl
[W1204 14:14:19.680993615 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:38743 (errno: 97 - Address family not supported by protocol).
[W1204 14:14:19.683876672 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:49727 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=554142)[0;0m INFO 12-04 14:14:19 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=554145)[0;0m INFO 12-04 14:14:19 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=554142)[0;0m INFO 12-04 14:14:19 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=554145)[0;0m INFO 12-04 14:14:19 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=554142)[0;0m INFO 12-04 14:14:20 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=554142)[0;0m INFO 12-04 14:14:20 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=554145)[0;0m INFO 12-04 14:14:20 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=554145)[0;0m INFO 12-04 14:14:20 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=554142)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=554145)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=554142)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.12s/it]
[1;36m(EngineCore_DP0 pid=554145)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=554142)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=554142)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=554142)[0;0m 
[1;36m(EngineCore_DP0 pid=554142)[0;0m INFO 12-04 14:14:22 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=554145)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=554145)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=554145)[0;0m 
[1;36m(EngineCore_DP0 pid=554145)[0;0m INFO 12-04 14:14:22 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=554142)[0;0m INFO 12-04 14:14:23 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.822238 seconds
[1;36m(EngineCore_DP0 pid=554145)[0;0m INFO 12-04 14:14:23 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.936831 seconds
[1;36m(EngineCore_DP0 pid=554142)[0;0m INFO 12-04 14:14:31 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=554142)[0;0m INFO 12-04 14:14:31 [backends.py:647] Dynamo bytecode transform time: 7.95 s
[1;36m(EngineCore_DP0 pid=554145)[0;0m INFO 12-04 14:14:31 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=554145)[0;0m INFO 12-04 14:14:31 [backends.py:647] Dynamo bytecode transform time: 7.88 s
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f53f41a33b0>' raised:
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842] 
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=554142)[0;0m ERROR 12-04 14:14:32 [core.py:842] 
[1;36m(EngineCore_DP0 pid=554142)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=554142)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=554142)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=554142)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=554142)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=554142)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=554142)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=554142)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=554142)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=554142)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=554142)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=554142)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=554142)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=554142)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=554142)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=554142)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=554142)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=554142)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=554142)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=554142)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=554142)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=554142)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=554142)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=554142)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=554142)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=554142)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=554142)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=554142)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=554142)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=554142)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=554142)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=554142)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=554142)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=554142)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=554142)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=554142)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=554142)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=554142)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=554142)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=554142)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=554142)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=554142)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=554142)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=554142)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=554142)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554142)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=554142)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=554142)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f53f41a33b0>' raised:
[1;36m(EngineCore_DP0 pid=554142)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=554142)[0;0m 
[1;36m(EngineCore_DP0 pid=554142)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=554142)[0;0m 
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f6e6a27f7d0>' raised:
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842] 
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=554145)[0;0m ERROR 12-04 14:14:32 [core.py:842] 
[1;36m(EngineCore_DP0 pid=554145)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=554145)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=554145)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=554145)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=554145)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=554145)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=554145)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=554145)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=554145)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=554145)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=554145)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=554145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=554145)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=554145)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=554145)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=554145)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=554145)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=554145)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=554145)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=554145)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=554145)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=554145)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=554145)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=554145)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=554145)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=554145)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=554145)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=554145)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=554145)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=554145)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=554145)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=554145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=554145)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=554145)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=554145)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=554145)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=554145)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=554145)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=554145)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=554145)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=554145)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=554145)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=554145)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=554145)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=554145)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=554145)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=554145)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=554145)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f6e6a27f7d0>' raised:
[1;36m(EngineCore_DP0 pid=554145)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=554145)[0;0m 
[1;36m(EngineCore_DP0 pid=554145)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=554145)[0;0m 
[rank0]:[W1204 14:14:33.510083765 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:14:33.548671117 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:14:54 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:14:54 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:14:54 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:14:54 [model.py:1745] Using max model len 131072
INFO 12-04 14:14:54 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:14:54 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:14:54 [model.py:1745] Using max model len 131072
INFO 12-04 14:14:54 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=556080)[0;0m INFO 12-04 14:15:07 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=556068)[0;0m INFO 12-04 14:15:07 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=556080)[0;0m INFO 12-04 14:15:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:52381 backend=nccl
[1;36m(EngineCore_DP0 pid=556068)[0;0m INFO 12-04 14:15:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:43553 backend=nccl
[W1204 14:15:08.377792097 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:52381 (errno: 97 - Address family not supported by protocol).
[W1204 14:15:08.380399870 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:43553 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=556080)[0;0m INFO 12-04 14:15:09 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=556068)[0;0m INFO 12-04 14:15:09 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=556080)[0;0m INFO 12-04 14:15:09 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=556068)[0;0m INFO 12-04 14:15:09 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=556080)[0;0m INFO 12-04 14:15:10 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=556080)[0;0m INFO 12-04 14:15:10 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=556068)[0;0m INFO 12-04 14:15:10 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=556068)[0;0m INFO 12-04 14:15:10 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=556080)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=556068)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=556080)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=556068)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=556080)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=556080)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=556080)[0;0m 
[1;36m(EngineCore_DP0 pid=556080)[0;0m INFO 12-04 14:15:12 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=556068)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=556068)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=556068)[0;0m 
[1;36m(EngineCore_DP0 pid=556068)[0;0m INFO 12-04 14:15:12 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=556080)[0;0m INFO 12-04 14:15:13 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.782013 seconds
[1;36m(EngineCore_DP0 pid=556068)[0;0m INFO 12-04 14:15:13 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.886591 seconds
[1;36m(EngineCore_DP0 pid=556080)[0;0m INFO 12-04 14:15:21 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=556080)[0;0m INFO 12-04 14:15:21 [backends.py:647] Dynamo bytecode transform time: 7.94 s
[1;36m(EngineCore_DP0 pid=556068)[0;0m INFO 12-04 14:15:21 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=556068)[0;0m INFO 12-04 14:15:21 [backends.py:647] Dynamo bytecode transform time: 7.86 s
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fbcb502b080>' raised:
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842] 
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=556068)[0;0m ERROR 12-04 14:15:21 [core.py:842] 
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7efd5ce270b0>' raised:
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842] 
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=556080)[0;0m ERROR 12-04 14:15:21 [core.py:842] 
[1;36m(EngineCore_DP0 pid=556068)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=556080)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=556068)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=556080)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=556080)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=556080)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=556068)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=556068)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=556068)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=556068)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=556068)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=556068)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=556080)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=556080)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=556080)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=556080)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=556080)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=556080)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=556080)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=556080)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=556080)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=556080)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=556068)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=556068)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=556068)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=556068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=556068)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=556068)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=556068)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=556068)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=556068)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=556068)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=556068)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=556068)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=556068)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=556068)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=556068)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=556080)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=556080)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=556080)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=556080)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=556080)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=556080)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=556080)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=556080)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=556080)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=556080)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=556080)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=556080)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=556080)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=556068)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=556068)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=556068)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=556068)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=556068)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=556068)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=556068)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=556068)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=556068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=556068)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=556068)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=556068)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=556068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=556080)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=556080)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=556080)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=556080)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=556080)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=556080)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=556080)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=556080)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=556080)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=556080)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=556080)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=556080)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=556080)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=556080)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=556080)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=556080)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=556068)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=556068)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=556068)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=556068)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=556068)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=556068)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=556068)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=556068)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=556068)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=556068)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=556068)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fbcb502b080>' raised:
[1;36m(EngineCore_DP0 pid=556068)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=556068)[0;0m 
[1;36m(EngineCore_DP0 pid=556068)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=556068)[0;0m 
[1;36m(EngineCore_DP0 pid=556080)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=556080)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=556080)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=556080)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=556080)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7efd5ce270b0>' raised:
[1;36m(EngineCore_DP0 pid=556080)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=556080)[0;0m 
[1;36m(EngineCore_DP0 pid=556080)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=556080)[0;0m 
[rank0]:[W1204 14:15:22.141425471 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:15:22.141366944 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:15:43 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:15:43 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:15:44 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:15:44 [model.py:1745] Using max model len 131072
INFO 12-04 14:15:44 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:15:44 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:15:44 [model.py:1745] Using max model len 131072
INFO 12-04 14:15:44 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=558245)[0;0m INFO 12-04 14:16:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=558248)[0;0m INFO 12-04 14:16:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=558245)[0;0m INFO 12-04 14:16:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:43193 backend=nccl
[1;36m(EngineCore_DP0 pid=558248)[0;0m INFO 12-04 14:16:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:45601 backend=nccl
[W1204 14:16:01.314021954 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:43193 (errno: 97 - Address family not supported by protocol).
[W1204 14:16:01.316366466 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:45601 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=558245)[0;0m INFO 12-04 14:16:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=558248)[0;0m INFO 12-04 14:16:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=558245)[0;0m INFO 12-04 14:16:02 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=558248)[0;0m INFO 12-04 14:16:02 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=558248)[0;0m INFO 12-04 14:16:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=558248)[0;0m INFO 12-04 14:16:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=558245)[0;0m INFO 12-04 14:16:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=558245)[0;0m INFO 12-04 14:16:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=558248)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=558245)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=558248)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.18s/it]
[1;36m(EngineCore_DP0 pid=558245)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=558248)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.28it/s]
[1;36m(EngineCore_DP0 pid=558248)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.19it/s]
[1;36m(EngineCore_DP0 pid=558248)[0;0m 
[1;36m(EngineCore_DP0 pid=558248)[0;0m INFO 12-04 14:16:05 [default_loader.py:314] Loading weights took 1.74 seconds
[1;36m(EngineCore_DP0 pid=558245)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.28it/s]
[1;36m(EngineCore_DP0 pid=558245)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=558245)[0;0m 
[1;36m(EngineCore_DP0 pid=558245)[0;0m INFO 12-04 14:16:05 [default_loader.py:314] Loading weights took 1.73 seconds
[1;36m(EngineCore_DP0 pid=558248)[0;0m INFO 12-04 14:16:06 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.890139 seconds
[1;36m(EngineCore_DP0 pid=558245)[0;0m INFO 12-04 14:16:06 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.964484 seconds
[1;36m(EngineCore_DP0 pid=558245)[0;0m INFO 12-04 14:16:14 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=558248)[0;0m INFO 12-04 14:16:14 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=558245)[0;0m INFO 12-04 14:16:14 [backends.py:647] Dynamo bytecode transform time: 8.12 s
[1;36m(EngineCore_DP0 pid=558248)[0;0m INFO 12-04 14:16:14 [backends.py:647] Dynamo bytecode transform time: 8.18 s
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f3ebc332ab0>' raised:
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=558245)[0;0m ERROR 12-04 14:16:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f7d402ac200>' raised:
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=558248)[0;0m ERROR 12-04 14:16:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=558245)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=558248)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=558245)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=558248)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=558248)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=558245)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=558245)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=558245)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=558245)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=558248)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=558248)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=558248)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=558248)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=558248)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=558248)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=558248)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=558248)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=558248)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=558248)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=558245)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=558245)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=558245)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=558245)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=558245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=558245)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=558245)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=558245)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=558245)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=558245)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=558245)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=558245)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=558245)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=558245)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=558248)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=558248)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=558248)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=558248)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=558248)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=558248)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=558248)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=558248)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=558248)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=558248)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=558248)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=558248)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=558245)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=558245)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=558245)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=558245)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=558245)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=558245)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=558245)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=558245)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=558245)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=558245)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=558245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=558245)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=558248)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=558248)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=558248)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=558248)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=558248)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=558248)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=558248)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=558248)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=558248)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=558248)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=558248)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=558248)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=558248)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=558248)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=558248)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=558248)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=558248)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=558248)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=558245)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=558245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=558245)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=558245)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=558245)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=558245)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=558245)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=558245)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=558245)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=558245)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=558245)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=558245)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=558245)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f3ebc332ab0>' raised:
[1;36m(EngineCore_DP0 pid=558245)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=558245)[0;0m 
[1;36m(EngineCore_DP0 pid=558245)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=558245)[0;0m 
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=558248)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=558248)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=558248)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=558248)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=558248)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f7d402ac200>' raised:
[1;36m(EngineCore_DP0 pid=558248)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=558248)[0;0m 
[1;36m(EngineCore_DP0 pid=558248)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=558248)[0;0m 
[rank0]:[W1204 14:16:16.451692650 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:16:16.451892101 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:16:37 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:16:37 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:16:37 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:16:37 [model.py:1745] Using max model len 131072
INFO 12-04 14:16:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:16:37 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:16:37 [model.py:1745] Using max model len 131072
INFO 12-04 14:16:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=559925)[0;0m INFO 12-04 14:16:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=559922)[0;0m INFO 12-04 14:16:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=559925)[0;0m INFO 12-04 14:16:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:60267 backend=nccl
[1;36m(EngineCore_DP0 pid=559922)[0;0m INFO 12-04 14:16:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:35419 backend=nccl
[W1204 14:16:53.482885940 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:60267 (errno: 97 - Address family not supported by protocol).
[W1204 14:16:53.483811084 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:35419 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=559925)[0;0m INFO 12-04 14:16:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=559922)[0;0m INFO 12-04 14:16:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=559925)[0;0m INFO 12-04 14:16:53 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=559922)[0;0m INFO 12-04 14:16:53 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=559925)[0;0m INFO 12-04 14:16:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=559925)[0;0m INFO 12-04 14:16:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=559922)[0;0m INFO 12-04 14:16:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=559922)[0;0m INFO 12-04 14:16:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=559925)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=559922)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=559925)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=559922)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=559925)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=559925)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=559925)[0;0m 
[1;36m(EngineCore_DP0 pid=559925)[0;0m INFO 12-04 14:16:56 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=559922)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=559922)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=559922)[0;0m 
[1;36m(EngineCore_DP0 pid=559922)[0;0m INFO 12-04 14:16:56 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=559925)[0;0m INFO 12-04 14:16:57 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.825432 seconds
[1;36m(EngineCore_DP0 pid=559922)[0;0m INFO 12-04 14:16:57 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.940672 seconds
[1;36m(EngineCore_DP0 pid=559925)[0;0m INFO 12-04 14:17:05 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=559925)[0;0m INFO 12-04 14:17:05 [backends.py:647] Dynamo bytecode transform time: 7.74 s
[1;36m(EngineCore_DP0 pid=559922)[0;0m INFO 12-04 14:17:05 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=559922)[0;0m INFO 12-04 14:17:05 [backends.py:647] Dynamo bytecode transform time: 7.78 s
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8f084eaae0>' raised:
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842] 
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=559925)[0;0m ERROR 12-04 14:17:05 [core.py:842] 
[1;36m(EngineCore_DP0 pid=559925)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=559925)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=559925)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=559925)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=559925)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=559925)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=559925)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=559925)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=559925)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=559925)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=559925)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=559925)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=559925)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=559925)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=559925)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=559925)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=559925)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=559925)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=559925)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=559925)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=559925)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=559925)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=559925)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=559925)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=559925)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=559925)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=559925)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=559925)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=559925)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=559925)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=559925)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=559925)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=559925)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=559925)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=559925)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=559925)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=559925)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=559925)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=559925)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=559925)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=559925)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=559925)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=559925)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=559925)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=559925)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559925)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=559925)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=559925)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8f084eaae0>' raised:
[1;36m(EngineCore_DP0 pid=559925)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=559925)[0;0m 
[1;36m(EngineCore_DP0 pid=559925)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=559925)[0;0m 
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc97007a1b0>' raised:
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842] 
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=559922)[0;0m ERROR 12-04 14:17:06 [core.py:842] 
[1;36m(EngineCore_DP0 pid=559922)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=559922)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=559922)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=559922)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=559922)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=559922)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=559922)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=559922)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=559922)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=559922)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=559922)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=559922)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=559922)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=559922)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=559922)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=559922)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=559922)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=559922)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=559922)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=559922)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=559922)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=559922)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=559922)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=559922)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=559922)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=559922)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=559922)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=559922)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=559922)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=559922)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=559922)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=559922)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=559922)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=559922)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=559922)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=559922)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=559922)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=559922)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=559922)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=559922)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=559922)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=559922)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=559922)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=559922)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=559922)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=559922)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=559922)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=559922)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc97007a1b0>' raised:
[1;36m(EngineCore_DP0 pid=559922)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=559922)[0;0m 
[1;36m(EngineCore_DP0 pid=559922)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=559922)[0;0m 
[rank0]:[W1204 14:17:06.066792162 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:17:06.312104404 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:17:27 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:17:28 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:17:28 [model.py:1745] Using max model len 131072
INFO 12-04 14:17:28 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:17:28 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:17:28 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:17:28 [model.py:1745] Using max model len 131072
INFO 12-04 14:17:28 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=561594)[0;0m INFO 12-04 14:17:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=561597)[0;0m INFO 12-04 14:17:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=561594)[0;0m INFO 12-04 14:17:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:50533 backend=nccl
[1;36m(EngineCore_DP0 pid=561597)[0;0m INFO 12-04 14:17:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:47039 backend=nccl
[W1204 14:17:45.990706404 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:50533 (errno: 97 - Address family not supported by protocol).
[W1204 14:17:45.993771725 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:47039 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=561594)[0;0m INFO 12-04 14:17:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=561597)[0;0m INFO 12-04 14:17:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=561594)[0;0m INFO 12-04 14:17:46 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=561597)[0;0m INFO 12-04 14:17:46 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=561594)[0;0m INFO 12-04 14:17:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=561594)[0;0m INFO 12-04 14:17:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=561597)[0;0m INFO 12-04 14:17:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=561597)[0;0m INFO 12-04 14:17:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=561597)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=561594)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=561597)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=561594)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=561597)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=561597)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=561597)[0;0m 
[1;36m(EngineCore_DP0 pid=561597)[0;0m INFO 12-04 14:17:49 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=561594)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=561594)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=561594)[0;0m 
[1;36m(EngineCore_DP0 pid=561594)[0;0m INFO 12-04 14:17:49 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=561597)[0;0m INFO 12-04 14:17:49 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.758931 seconds
[1;36m(EngineCore_DP0 pid=561594)[0;0m INFO 12-04 14:17:49 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.871427 seconds
[1;36m(EngineCore_DP0 pid=561597)[0;0m INFO 12-04 14:17:58 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=561594)[0;0m INFO 12-04 14:17:58 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=561597)[0;0m INFO 12-04 14:17:58 [backends.py:647] Dynamo bytecode transform time: 8.06 s
[1;36m(EngineCore_DP0 pid=561594)[0;0m INFO 12-04 14:17:58 [backends.py:647] Dynamo bytecode transform time: 7.95 s
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f36e430a510>' raised:
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=561594)[0;0m ERROR 12-04 14:17:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f501022f230>' raised:
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=561597)[0;0m ERROR 12-04 14:17:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=561594)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=561594)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=561594)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=561594)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=561594)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=561594)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=561594)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=561594)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=561594)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=561594)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=561594)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=561594)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=561594)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=561594)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=561594)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=561594)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=561594)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=561594)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=561594)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=561594)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=561594)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=561594)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=561594)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=561594)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=561594)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=561594)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=561594)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=561594)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=561594)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=561594)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=561594)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=561594)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=561594)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=561594)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=561594)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=561594)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=561594)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=561594)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=561594)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=561594)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=561594)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=561594)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=561594)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=561594)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=561594)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561594)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=561594)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=561594)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f36e430a510>' raised:
[1;36m(EngineCore_DP0 pid=561594)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=561594)[0;0m 
[1;36m(EngineCore_DP0 pid=561594)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=561594)[0;0m 
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=561597)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=561597)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=561597)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=561597)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=561597)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=561597)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=561597)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=561597)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=561597)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=561597)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=561597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=561597)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=561597)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=561597)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=561597)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=561597)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=561597)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=561597)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=561597)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=561597)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=561597)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=561597)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=561597)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=561597)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=561597)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=561597)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=561597)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=561597)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=561597)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=561597)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=561597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=561597)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=561597)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=561597)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=561597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=561597)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=561597)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=561597)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=561597)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=561597)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=561597)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=561597)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=561597)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=561597)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=561597)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=561597)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=561597)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f501022f230>' raised:
[1;36m(EngineCore_DP0 pid=561597)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=561597)[0;0m 
[1;36m(EngineCore_DP0 pid=561597)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=561597)[0;0m 
[rank0]:[W1204 14:17:59.798570960 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:17:59.798571010 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:18:20 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:18:20 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:18:20 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:18:20 [model.py:1745] Using max model len 131072
INFO 12-04 14:18:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:18:20 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:18:20 [model.py:1745] Using max model len 131072
INFO 12-04 14:18:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=563017)[0;0m INFO 12-04 14:18:33 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=563014)[0;0m INFO 12-04 14:18:33 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=563014)[0;0m INFO 12-04 14:18:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:59299 backend=nccl
[1;36m(EngineCore_DP0 pid=563017)[0;0m INFO 12-04 14:18:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:38797 backend=nccl
[W1204 14:18:34.925307806 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:59299 (errno: 97 - Address family not supported by protocol).
[W1204 14:18:34.927092478 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:38797 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=563017)[0;0m INFO 12-04 14:18:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=563014)[0;0m INFO 12-04 14:18:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=563017)[0;0m INFO 12-04 14:18:34 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=563014)[0;0m INFO 12-04 14:18:34 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=563017)[0;0m INFO 12-04 14:18:35 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=563017)[0;0m INFO 12-04 14:18:35 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=563014)[0;0m INFO 12-04 14:18:35 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=563014)[0;0m INFO 12-04 14:18:35 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=563017)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=563014)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=563017)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=563014)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.12s/it]
[1;36m(EngineCore_DP0 pid=563017)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=563017)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=563017)[0;0m 
[1;36m(EngineCore_DP0 pid=563017)[0;0m INFO 12-04 14:18:38 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=563014)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=563014)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=563014)[0;0m 
[1;36m(EngineCore_DP0 pid=563014)[0;0m INFO 12-04 14:18:38 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=563017)[0;0m INFO 12-04 14:18:38 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.751086 seconds
[1;36m(EngineCore_DP0 pid=563014)[0;0m INFO 12-04 14:18:38 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.842366 seconds
[1;36m(EngineCore_DP0 pid=563017)[0;0m INFO 12-04 14:18:47 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=563017)[0;0m INFO 12-04 14:18:47 [backends.py:647] Dynamo bytecode transform time: 8.23 s
[1;36m(EngineCore_DP0 pid=563014)[0;0m INFO 12-04 14:18:47 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=563014)[0;0m INFO 12-04 14:18:47 [backends.py:647] Dynamo bytecode transform time: 8.18 s
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fcd703c96d0>' raised:
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=563017)[0;0m ERROR 12-04 14:18:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=563017)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=563017)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=563017)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=563017)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=563017)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=563017)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=563017)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=563017)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=563017)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=563017)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=563017)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=563017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=563017)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=563017)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=563017)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=563017)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=563017)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=563017)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=563017)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=563017)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=563017)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=563017)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=563017)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=563017)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=563017)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=563017)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=563017)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=563017)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=563017)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=563017)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=563017)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=563017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=563017)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=563017)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=563017)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=563017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=563017)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=563017)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=563017)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=563017)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=563017)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=563017)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=563017)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=563017)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=563017)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=563017)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=563017)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fcd703c96d0>' raised:
[1;36m(EngineCore_DP0 pid=563017)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=563017)[0;0m 
[1;36m(EngineCore_DP0 pid=563017)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=563017)[0;0m 
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb5d0343d40>' raised:
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=563014)[0;0m ERROR 12-04 14:18:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=563014)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=563014)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=563014)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=563014)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=563014)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=563014)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=563014)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=563014)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=563014)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=563014)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=563014)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=563014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=563014)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=563014)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=563014)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=563014)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=563014)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=563014)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=563014)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=563014)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=563014)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=563014)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=563014)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=563014)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=563014)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=563014)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=563014)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=563014)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=563014)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=563014)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=563014)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=563014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=563014)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=563014)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=563014)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=563014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=563014)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=563014)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=563014)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=563014)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=563014)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=563014)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=563014)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=563014)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=563014)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=563014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=563014)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=563014)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb5d0343d40>' raised:
[1;36m(EngineCore_DP0 pid=563014)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=563014)[0;0m 
[1;36m(EngineCore_DP0 pid=563014)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=563014)[0;0m 
[rank0]:[W1204 14:18:48.023942994 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:18:48.054973585 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:19:09 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:19:09 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:19:10 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:19:10 [model.py:1745] Using max model len 131072
INFO 12-04 14:19:10 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:19:10 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:19:10 [model.py:1745] Using max model len 131072
INFO 12-04 14:19:10 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=564465)[0;0m INFO 12-04 14:19:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=564468)[0;0m INFO 12-04 14:19:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=564468)[0;0m INFO 12-04 14:19:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:51393 backend=nccl
[1;36m(EngineCore_DP0 pid=564465)[0;0m INFO 12-04 14:19:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:54425 backend=nccl
[W1204 14:19:27.359092327 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:51393 (errno: 97 - Address family not supported by protocol).
[W1204 14:19:27.359584753 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:54425 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=564465)[0;0m INFO 12-04 14:19:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=564468)[0;0m INFO 12-04 14:19:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=564468)[0;0m INFO 12-04 14:19:28 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=564465)[0;0m INFO 12-04 14:19:28 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=564468)[0;0m INFO 12-04 14:19:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=564468)[0;0m INFO 12-04 14:19:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=564465)[0;0m INFO 12-04 14:19:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=564465)[0;0m INFO 12-04 14:19:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=564465)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=564468)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=564465)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=564468)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=564465)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=564465)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=564465)[0;0m 
[1;36m(EngineCore_DP0 pid=564465)[0;0m INFO 12-04 14:19:31 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=564468)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=564468)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=564468)[0;0m 
[1;36m(EngineCore_DP0 pid=564468)[0;0m INFO 12-04 14:19:31 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=564465)[0;0m INFO 12-04 14:19:32 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.848813 seconds
[1;36m(EngineCore_DP0 pid=564468)[0;0m INFO 12-04 14:19:32 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.973691 seconds
[1;36m(EngineCore_DP0 pid=564468)[0;0m INFO 12-04 14:19:40 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=564465)[0;0m INFO 12-04 14:19:40 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=564465)[0;0m INFO 12-04 14:19:40 [backends.py:647] Dynamo bytecode transform time: 8.42 s
[1;36m(EngineCore_DP0 pid=564468)[0;0m INFO 12-04 14:19:40 [backends.py:647] Dynamo bytecode transform time: 8.30 s
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f4974119af0>' raised:
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=564465)[0;0m ERROR 12-04 14:19:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f76f030f890>' raised:
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=564468)[0;0m ERROR 12-04 14:19:41 [core.py:842] 
[1;36m(EngineCore_DP0 pid=564465)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=564468)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=564465)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=564468)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=564468)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=564468)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=564468)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=564465)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=564465)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=564465)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=564465)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=564465)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=564465)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=564465)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=564465)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=564465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=564468)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=564468)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=564468)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=564468)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=564468)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=564468)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=564468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=564468)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=564468)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=564468)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=564468)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=564468)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=564468)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=564468)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=564468)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=564468)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=564465)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=564465)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=564465)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=564465)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=564465)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=564465)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=564465)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=564465)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=564465)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=564465)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=564465)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=564465)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=564465)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=564468)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=564468)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=564468)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=564468)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=564468)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=564468)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=564468)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=564468)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=564468)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=564468)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=564468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=564465)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=564465)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=564465)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=564465)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=564465)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=564465)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=564465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=564465)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=564465)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=564465)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=564465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=564465)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=564465)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=564465)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=564468)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=564468)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=564468)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=564468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=564468)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=564468)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=564468)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=564468)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=564468)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=564468)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=564468)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=564468)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=564468)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=564468)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=564468)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f76f030f890>' raised:
[1;36m(EngineCore_DP0 pid=564468)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=564468)[0;0m 
[1;36m(EngineCore_DP0 pid=564468)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=564468)[0;0m 
[1;36m(EngineCore_DP0 pid=564465)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=564465)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=564465)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=564465)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=564465)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=564465)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=564465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=564465)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=564465)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f4974119af0>' raised:
[1;36m(EngineCore_DP0 pid=564465)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=564465)[0;0m 
[1;36m(EngineCore_DP0 pid=564465)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=564465)[0;0m 
[rank0]:[W1204 14:19:42.613112997 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:19:42.613231014 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:20:03 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:20:03 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:20:03 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:20:03 [model.py:1745] Using max model len 131072
INFO 12-04 14:20:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:20:03 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:20:03 [model.py:1745] Using max model len 131072
INFO 12-04 14:20:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=565766)[0;0m INFO 12-04 14:20:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=565763)[0;0m INFO 12-04 14:20:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=565763)[0;0m INFO 12-04 14:20:20 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:59415 backend=nccl
[1;36m(EngineCore_DP0 pid=565766)[0;0m INFO 12-04 14:20:20 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:33749 backend=nccl
[W1204 14:20:20.585400111 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:59415 (errno: 97 - Address family not supported by protocol).
[W1204 14:20:20.588617695 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:33749 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=565766)[0;0m INFO 12-04 14:20:20 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=565763)[0;0m INFO 12-04 14:20:20 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=565766)[0;0m INFO 12-04 14:20:20 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=565763)[0;0m INFO 12-04 14:20:20 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=565763)[0;0m INFO 12-04 14:20:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=565763)[0;0m INFO 12-04 14:20:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=565766)[0;0m INFO 12-04 14:20:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=565766)[0;0m INFO 12-04 14:20:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=565763)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=565766)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=565763)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=565766)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=565763)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=565763)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=565763)[0;0m 
[1;36m(EngineCore_DP0 pid=565763)[0;0m INFO 12-04 14:20:23 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=565766)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=565766)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=565766)[0;0m 
[1;36m(EngineCore_DP0 pid=565766)[0;0m INFO 12-04 14:20:23 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=565763)[0;0m INFO 12-04 14:20:24 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.771505 seconds
[1;36m(EngineCore_DP0 pid=565766)[0;0m INFO 12-04 14:20:24 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.898659 seconds
[1;36m(EngineCore_DP0 pid=565763)[0;0m INFO 12-04 14:20:32 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=565763)[0;0m INFO 12-04 14:20:32 [backends.py:647] Dynamo bytecode transform time: 8.04 s
[1;36m(EngineCore_DP0 pid=565766)[0;0m INFO 12-04 14:20:32 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=565766)[0;0m INFO 12-04 14:20:32 [backends.py:647] Dynamo bytecode transform time: 7.94 s
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f18f81fb710>' raised:
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842] 
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=565763)[0;0m ERROR 12-04 14:20:33 [core.py:842] 
[1;36m(EngineCore_DP0 pid=565763)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=565763)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=565763)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=565763)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=565763)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=565763)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=565763)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=565763)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=565763)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=565763)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565763)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=565763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=565763)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=565763)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565763)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565763)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=565763)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=565763)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565763)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=565763)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=565763)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=565763)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=565763)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=565763)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=565763)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=565763)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=565763)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565763)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565763)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=565763)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=565763)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=565763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=565763)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=565763)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=565763)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=565763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=565763)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=565763)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=565763)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=565763)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=565763)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=565763)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=565763)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=565763)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=565763)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=565763)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=565763)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f18f81fb710>' raised:
[1;36m(EngineCore_DP0 pid=565763)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=565763)[0;0m 
[1;36m(EngineCore_DP0 pid=565763)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=565763)[0;0m 
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f05c4180140>' raised:
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842] 
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=565766)[0;0m ERROR 12-04 14:20:33 [core.py:842] 
[1;36m(EngineCore_DP0 pid=565766)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=565766)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=565766)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=565766)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=565766)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=565766)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=565766)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=565766)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=565766)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=565766)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565766)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=565766)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=565766)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=565766)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565766)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565766)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=565766)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=565766)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565766)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=565766)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=565766)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=565766)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=565766)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=565766)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=565766)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=565766)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=565766)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565766)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565766)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=565766)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=565766)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=565766)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=565766)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=565766)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=565766)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=565766)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=565766)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=565766)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=565766)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=565766)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=565766)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=565766)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=565766)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=565766)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=565766)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565766)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=565766)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=565766)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f05c4180140>' raised:
[1;36m(EngineCore_DP0 pid=565766)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=565766)[0;0m 
[1;36m(EngineCore_DP0 pid=565766)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=565766)[0;0m 
[rank0]:[W1204 14:20:34.587545585 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:20:34.591017120 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:20:55 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:20:55 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:20:55 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:20:55 [model.py:1745] Using max model len 131072
INFO 12-04 14:20:55 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:20:55 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:20:55 [model.py:1745] Using max model len 131072
INFO 12-04 14:20:55 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=565937)[0;0m INFO 12-04 14:21:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=565934)[0;0m INFO 12-04 14:21:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=565937)[0;0m INFO 12-04 14:21:12 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:45343 backend=nccl
[1;36m(EngineCore_DP0 pid=565934)[0;0m INFO 12-04 14:21:12 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:58435 backend=nccl
[W1204 14:21:12.996777311 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:45343 (errno: 97 - Address family not supported by protocol).
[W1204 14:21:12.998007636 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:58435 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=565934)[0;0m INFO 12-04 14:21:12 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=565937)[0;0m INFO 12-04 14:21:12 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=565937)[0;0m INFO 12-04 14:21:13 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=565934)[0;0m INFO 12-04 14:21:13 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=565937)[0;0m INFO 12-04 14:21:14 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=565937)[0;0m INFO 12-04 14:21:14 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=565934)[0;0m INFO 12-04 14:21:14 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=565934)[0;0m INFO 12-04 14:21:14 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=565937)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=565934)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=565937)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.07s/it]
[1;36m(EngineCore_DP0 pid=565934)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.12s/it]
[1;36m(EngineCore_DP0 pid=565937)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.35it/s]
[1;36m(EngineCore_DP0 pid=565937)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.27it/s]
[1;36m(EngineCore_DP0 pid=565937)[0;0m 
[1;36m(EngineCore_DP0 pid=565937)[0;0m INFO 12-04 14:21:16 [default_loader.py:314] Loading weights took 1.64 seconds
[1;36m(EngineCore_DP0 pid=565934)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=565934)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=565934)[0;0m 
[1;36m(EngineCore_DP0 pid=565934)[0;0m INFO 12-04 14:21:16 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=565937)[0;0m INFO 12-04 14:21:16 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.799883 seconds
[1;36m(EngineCore_DP0 pid=565934)[0;0m INFO 12-04 14:21:17 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.178750 seconds
[1;36m(EngineCore_DP0 pid=565937)[0;0m INFO 12-04 14:21:25 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=565937)[0;0m INFO 12-04 14:21:25 [backends.py:647] Dynamo bytecode transform time: 8.39 s
[1;36m(EngineCore_DP0 pid=565934)[0;0m INFO 12-04 14:21:25 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=565934)[0;0m INFO 12-04 14:21:25 [backends.py:647] Dynamo bytecode transform time: 8.17 s
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f38d8160230>' raised:
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842] 
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=565937)[0;0m ERROR 12-04 14:21:25 [core.py:842] 
[1;36m(EngineCore_DP0 pid=565937)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=565937)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=565937)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=565937)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=565937)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=565937)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=565937)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=565937)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=565937)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=565937)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565937)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=565937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=565937)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=565937)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565937)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565937)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=565937)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=565937)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565937)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=565937)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=565937)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=565937)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=565937)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=565937)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=565937)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=565937)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=565937)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565937)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565937)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=565937)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=565937)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=565937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=565937)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=565937)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=565937)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=565937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=565937)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=565937)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=565937)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=565937)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=565937)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=565937)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=565937)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=565937)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=565937)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=565937)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=565937)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f38d8160230>' raised:
[1;36m(EngineCore_DP0 pid=565937)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=565937)[0;0m 
[1;36m(EngineCore_DP0 pid=565937)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=565937)[0;0m 
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f7b200d3830>' raised:
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842] 
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=565934)[0;0m ERROR 12-04 14:21:26 [core.py:842] 
[1;36m(EngineCore_DP0 pid=565934)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=565934)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=565934)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=565934)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=565934)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=565934)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=565934)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=565934)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=565934)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=565934)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565934)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=565934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=565934)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=565934)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565934)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=565934)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=565934)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=565934)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=565934)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=565934)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=565934)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=565934)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=565934)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=565934)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=565934)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=565934)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=565934)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565934)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=565934)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=565934)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=565934)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=565934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=565934)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=565934)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=565934)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=565934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=565934)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=565934)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=565934)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=565934)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=565934)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=565934)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=565934)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=565934)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=565934)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=565934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=565934)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=565934)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f7b200d3830>' raised:
[1;36m(EngineCore_DP0 pid=565934)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=565934)[0;0m 
[1;36m(EngineCore_DP0 pid=565934)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=565934)[0;0m 
[rank0]:[W1204 14:21:26.067704470 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:21:26.265468538 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:21:47 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:21:47 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:21:47 [model.py:1745] Using max model len 131072
INFO 12-04 14:21:47 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:21:47 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:21:48 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:21:48 [model.py:1745] Using max model len 131072
INFO 12-04 14:21:48 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=566317)[0;0m INFO 12-04 14:22:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=566320)[0;0m INFO 12-04 14:22:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=566317)[0;0m INFO 12-04 14:22:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:48367 backend=nccl
[1;36m(EngineCore_DP0 pid=566320)[0;0m INFO 12-04 14:22:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:52571 backend=nccl
[W1204 14:22:02.610270607 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:48367 (errno: 97 - Address family not supported by protocol).
[W1204 14:22:02.610261564 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:52571 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=566320)[0;0m INFO 12-04 14:22:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=566317)[0;0m INFO 12-04 14:22:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=566317)[0;0m INFO 12-04 14:22:02 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=566320)[0;0m INFO 12-04 14:22:02 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=566320)[0;0m INFO 12-04 14:22:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=566320)[0;0m INFO 12-04 14:22:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=566317)[0;0m INFO 12-04 14:22:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=566317)[0;0m INFO 12-04 14:22:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=566320)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=566317)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=566320)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=566317)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=566320)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=566320)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=566320)[0;0m 
[1;36m(EngineCore_DP0 pid=566320)[0;0m INFO 12-04 14:22:05 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=566317)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=566317)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=566317)[0;0m 
[1;36m(EngineCore_DP0 pid=566317)[0;0m INFO 12-04 14:22:05 [default_loader.py:314] Loading weights took 1.69 seconds
[1;36m(EngineCore_DP0 pid=566320)[0;0m INFO 12-04 14:22:06 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.790737 seconds
[1;36m(EngineCore_DP0 pid=566317)[0;0m INFO 12-04 14:22:06 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.949983 seconds
[1;36m(EngineCore_DP0 pid=566320)[0;0m INFO 12-04 14:22:14 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=566320)[0;0m INFO 12-04 14:22:14 [backends.py:647] Dynamo bytecode transform time: 8.01 s
[1;36m(EngineCore_DP0 pid=566317)[0;0m INFO 12-04 14:22:14 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=566317)[0;0m INFO 12-04 14:22:14 [backends.py:647] Dynamo bytecode transform time: 7.93 s
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb418df2ab0>' raised:
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=566320)[0;0m ERROR 12-04 14:22:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=566320)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=566320)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=566320)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=566320)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=566320)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=566320)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=566320)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=566320)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=566320)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=566320)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566320)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=566320)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=566320)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=566320)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566320)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566320)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=566320)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=566320)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566320)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=566320)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=566320)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=566320)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=566320)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=566320)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=566320)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=566320)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=566320)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566320)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566320)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=566320)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=566320)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=566320)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=566320)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=566320)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=566320)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=566320)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=566320)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=566320)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=566320)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=566320)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=566320)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=566320)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=566320)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=566320)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=566320)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566320)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=566320)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=566320)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb418df2ab0>' raised:
[1;36m(EngineCore_DP0 pid=566320)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=566320)[0;0m 
[1;36m(EngineCore_DP0 pid=566320)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=566320)[0;0m 
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f0c8828ae70>' raised:
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=566317)[0;0m ERROR 12-04 14:22:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=566317)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=566317)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=566317)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=566317)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=566317)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=566317)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=566317)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=566317)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=566317)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=566317)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566317)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=566317)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=566317)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=566317)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566317)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566317)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=566317)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=566317)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566317)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=566317)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=566317)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=566317)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=566317)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=566317)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=566317)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=566317)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=566317)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566317)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566317)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=566317)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=566317)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=566317)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=566317)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=566317)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=566317)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=566317)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=566317)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=566317)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=566317)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=566317)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=566317)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=566317)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=566317)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=566317)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=566317)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566317)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=566317)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=566317)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f0c8828ae70>' raised:
[1;36m(EngineCore_DP0 pid=566317)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=566317)[0;0m 
[1;36m(EngineCore_DP0 pid=566317)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=566317)[0;0m 
[rank0]:[W1204 14:22:16.415519902 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:22:16.534275931 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:22:37 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:22:37 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:22:37 [model.py:1745] Using max model len 131072
INFO 12-04 14:22:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:22:37 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:22:37 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:22:37 [model.py:1745] Using max model len 131072
INFO 12-04 14:22:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=566479)[0;0m INFO 12-04 14:22:52 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=566476)[0;0m INFO 12-04 14:22:52 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=566479)[0;0m INFO 12-04 14:22:54 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:36105 backend=nccl
[1;36m(EngineCore_DP0 pid=566476)[0;0m INFO 12-04 14:22:54 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:43887 backend=nccl
[W1204 14:22:54.556347393 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:36105 (errno: 97 - Address family not supported by protocol).
[W1204 14:22:54.556347212 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:43887 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=566479)[0;0m INFO 12-04 14:22:54 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=566476)[0;0m INFO 12-04 14:22:54 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=566479)[0;0m INFO 12-04 14:22:54 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=566476)[0;0m INFO 12-04 14:22:54 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=566476)[0;0m INFO 12-04 14:22:55 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=566476)[0;0m INFO 12-04 14:22:55 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=566479)[0;0m INFO 12-04 14:22:55 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=566479)[0;0m INFO 12-04 14:22:55 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=566476)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=566479)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=566476)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=566479)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=566476)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=566476)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=566476)[0;0m 
[1;36m(EngineCore_DP0 pid=566476)[0;0m INFO 12-04 14:22:57 [default_loader.py:314] Loading weights took 1.69 seconds
[1;36m(EngineCore_DP0 pid=566479)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=566479)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=566479)[0;0m 
[1;36m(EngineCore_DP0 pid=566479)[0;0m INFO 12-04 14:22:57 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=566476)[0;0m INFO 12-04 14:22:58 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.801180 seconds
[1;36m(EngineCore_DP0 pid=566479)[0;0m INFO 12-04 14:22:58 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.960469 seconds
[1;36m(EngineCore_DP0 pid=566476)[0;0m INFO 12-04 14:23:07 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=566476)[0;0m INFO 12-04 14:23:07 [backends.py:647] Dynamo bytecode transform time: 8.40 s
[1;36m(EngineCore_DP0 pid=566479)[0;0m INFO 12-04 14:23:07 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=566479)[0;0m INFO 12-04 14:23:07 [backends.py:647] Dynamo bytecode transform time: 8.31 s
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f14311df7a0>' raised:
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=566476)[0;0m ERROR 12-04 14:23:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=566476)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=566476)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=566476)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=566476)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=566476)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=566476)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=566476)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=566476)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=566476)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=566476)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566476)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=566476)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=566476)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=566476)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566476)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566476)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=566476)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=566476)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566476)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=566476)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=566476)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=566476)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=566476)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=566476)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=566476)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=566476)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=566476)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566476)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566476)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=566476)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=566476)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=566476)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=566476)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=566476)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=566476)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=566476)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=566476)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=566476)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=566476)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=566476)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=566476)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=566476)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=566476)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=566476)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=566476)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566476)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=566476)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=566476)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f14311df7a0>' raised:
[1;36m(EngineCore_DP0 pid=566476)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=566476)[0;0m 
[1;36m(EngineCore_DP0 pid=566476)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=566476)[0;0m 
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f93d325f620>' raised:
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=566479)[0;0m ERROR 12-04 14:23:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=566479)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=566479)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=566479)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=566479)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=566479)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=566479)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=566479)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=566479)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=566479)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=566479)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566479)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=566479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=566479)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=566479)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566479)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=566479)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=566479)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=566479)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=566479)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=566479)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=566479)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=566479)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=566479)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=566479)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=566479)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=566479)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=566479)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566479)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=566479)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=566479)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=566479)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=566479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=566479)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=566479)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=566479)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=566479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=566479)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=566479)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=566479)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=566479)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=566479)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=566479)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=566479)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=566479)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=566479)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=566479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=566479)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=566479)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f93d325f620>' raised:
[1;36m(EngineCore_DP0 pid=566479)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=566479)[0;0m 
[1;36m(EngineCore_DP0 pid=566479)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=566479)[0;0m 
[rank0]:[W1204 14:23:08.694264546 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:23:08.752168062 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:23:29 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:23:29 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:23:29 [model.py:1745] Using max model len 131072
INFO 12-04 14:23:29 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:23:29 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:23:29 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:23:29 [model.py:1745] Using max model len 131072
INFO 12-04 14:23:29 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=567050)[0;0m INFO 12-04 14:23:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=567047)[0;0m INFO 12-04 14:23:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=567050)[0;0m INFO 12-04 14:23:44 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:53705 backend=nccl
[1;36m(EngineCore_DP0 pid=567047)[0;0m INFO 12-04 14:23:44 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:40609 backend=nccl
[W1204 14:23:44.041308887 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:53705 (errno: 97 - Address family not supported by protocol).
[W1204 14:23:44.041803982 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:40609 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=567050)[0;0m INFO 12-04 14:23:44 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=567047)[0;0m INFO 12-04 14:23:44 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=567050)[0;0m INFO 12-04 14:23:45 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=567047)[0;0m INFO 12-04 14:23:45 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=567050)[0;0m INFO 12-04 14:23:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=567050)[0;0m INFO 12-04 14:23:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=567047)[0;0m INFO 12-04 14:23:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=567047)[0;0m INFO 12-04 14:23:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=567050)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=567047)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=567050)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=567047)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=567050)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=567050)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=567050)[0;0m 
[1;36m(EngineCore_DP0 pid=567050)[0;0m INFO 12-04 14:23:48 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=567047)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=567047)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=567047)[0;0m 
[1;36m(EngineCore_DP0 pid=567047)[0;0m INFO 12-04 14:23:48 [default_loader.py:314] Loading weights took 1.72 seconds
[1;36m(EngineCore_DP0 pid=567050)[0;0m INFO 12-04 14:23:48 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.818565 seconds
[1;36m(EngineCore_DP0 pid=567047)[0;0m INFO 12-04 14:23:49 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.932113 seconds
[1;36m(EngineCore_DP0 pid=567050)[0;0m INFO 12-04 14:23:57 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=567050)[0;0m INFO 12-04 14:23:57 [backends.py:647] Dynamo bytecode transform time: 8.35 s
[1;36m(EngineCore_DP0 pid=567047)[0;0m INFO 12-04 14:23:57 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=567047)[0;0m INFO 12-04 14:23:57 [backends.py:647] Dynamo bytecode transform time: 8.26 s
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f82506ef8f0>' raised:
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567050)[0;0m ERROR 12-04 14:23:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567050)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=567050)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=567050)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=567050)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567050)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567050)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567050)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567050)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567050)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567050)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567050)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567050)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567050)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567050)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567050)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567050)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567050)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567050)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567050)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567050)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567050)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567050)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567050)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567050)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567050)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567050)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567050)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567050)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567050)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567050)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567050)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567050)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567050)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567050)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567050)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567050)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567050)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567050)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567050)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567050)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567050)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567050)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567050)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567050)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567050)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567050)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567050)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567050)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f82506ef8f0>' raised:
[1;36m(EngineCore_DP0 pid=567050)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567050)[0;0m 
[1;36m(EngineCore_DP0 pid=567050)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567050)[0;0m 
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f2b082897f0>' raised:
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567047)[0;0m ERROR 12-04 14:23:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567047)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=567047)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=567047)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=567047)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567047)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567047)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567047)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567047)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567047)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567047)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567047)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567047)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567047)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567047)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567047)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567047)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567047)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567047)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567047)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567047)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567047)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567047)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567047)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567047)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567047)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567047)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567047)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567047)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567047)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567047)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567047)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567047)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567047)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567047)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567047)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567047)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567047)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567047)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567047)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567047)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567047)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567047)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567047)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567047)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567047)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567047)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567047)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567047)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f2b082897f0>' raised:
[1;36m(EngineCore_DP0 pid=567047)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567047)[0;0m 
[1;36m(EngineCore_DP0 pid=567047)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567047)[0;0m 
[rank0]:[W1204 14:23:58.234369348 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:23:58.259357130 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:24:20 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:24:20 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:24:20 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:24:20 [model.py:1745] Using max model len 131072
INFO 12-04 14:24:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:24:20 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:24:20 [model.py:1745] Using max model len 131072
INFO 12-04 14:24:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=567356)[0;0m INFO 12-04 14:24:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=567353)[0;0m INFO 12-04 14:24:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=567353)[0;0m INFO 12-04 14:24:36 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:40095 backend=nccl
[1;36m(EngineCore_DP0 pid=567356)[0;0m INFO 12-04 14:24:36 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:48355 backend=nccl
[W1204 14:24:36.347007085 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:48355 (errno: 97 - Address family not supported by protocol).
[W1204 14:24:36.347101546 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:40095 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=567353)[0;0m INFO 12-04 14:24:36 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=567356)[0;0m INFO 12-04 14:24:36 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=567353)[0;0m INFO 12-04 14:24:37 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=567356)[0;0m INFO 12-04 14:24:37 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=567356)[0;0m INFO 12-04 14:24:38 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=567356)[0;0m INFO 12-04 14:24:38 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=567353)[0;0m INFO 12-04 14:24:38 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=567353)[0;0m INFO 12-04 14:24:38 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=567356)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=567353)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=567356)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=567353)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=567356)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=567356)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=567356)[0;0m 
[1;36m(EngineCore_DP0 pid=567356)[0;0m INFO 12-04 14:24:40 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=567353)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=567353)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=567353)[0;0m 
[1;36m(EngineCore_DP0 pid=567353)[0;0m INFO 12-04 14:24:40 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=567356)[0;0m INFO 12-04 14:24:41 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.903783 seconds
[1;36m(EngineCore_DP0 pid=567353)[0;0m INFO 12-04 14:24:41 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.009264 seconds
[1;36m(EngineCore_DP0 pid=567353)[0;0m INFO 12-04 14:24:50 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=567356)[0;0m INFO 12-04 14:24:50 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=567353)[0;0m INFO 12-04 14:24:50 [backends.py:647] Dynamo bytecode transform time: 8.40 s
[1;36m(EngineCore_DP0 pid=567356)[0;0m INFO 12-04 14:24:50 [backends.py:647] Dynamo bytecode transform time: 8.50 s
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f360c2d8d70>' raised:
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567353)[0;0m ERROR 12-04 14:24:50 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567353)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=567353)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=567353)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=567353)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567353)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567353)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567353)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567353)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567353)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567353)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567353)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567353)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567353)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567353)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567353)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567353)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567353)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567353)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567353)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567353)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567353)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567353)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567353)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567353)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567353)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567353)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567353)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567353)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567353)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567353)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567353)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567353)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567353)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567353)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567353)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567353)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567353)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567353)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567353)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567353)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567353)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567353)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567353)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567353)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567353)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567353)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567353)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567353)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f360c2d8d70>' raised:
[1;36m(EngineCore_DP0 pid=567353)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567353)[0;0m 
[1;36m(EngineCore_DP0 pid=567353)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567353)[0;0m 
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f31702e3ad0>' raised:
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567356)[0;0m ERROR 12-04 14:24:50 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567356)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=567356)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=567356)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=567356)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567356)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567356)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567356)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567356)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567356)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567356)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567356)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567356)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567356)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567356)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567356)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567356)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567356)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567356)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567356)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567356)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567356)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567356)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567356)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567356)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567356)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567356)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567356)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567356)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567356)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567356)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567356)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567356)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567356)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567356)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567356)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567356)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567356)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567356)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567356)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567356)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567356)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567356)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567356)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567356)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567356)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567356)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567356)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567356)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f31702e3ad0>' raised:
[1;36m(EngineCore_DP0 pid=567356)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567356)[0;0m 
[1;36m(EngineCore_DP0 pid=567356)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567356)[0;0m 
[rank0]:[W1204 14:24:51.700082922 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:24:51.700082765 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:25:12 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:25:12 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:25:12 [model.py:1745] Using max model len 131072
INFO 12-04 14:25:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:25:12 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:25:12 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:25:12 [model.py:1745] Using max model len 131072
INFO 12-04 14:25:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=567529)[0;0m INFO 12-04 14:25:25 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=567532)[0;0m INFO 12-04 14:25:25 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=567529)[0;0m INFO 12-04 14:25:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:50009 backend=nccl
[W1204 14:25:27.462648192 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:50009 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=567532)[0;0m INFO 12-04 14:25:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:48793 backend=nccl
[W1204 14:25:27.488458005 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:48793 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=567529)[0;0m INFO 12-04 14:25:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=567532)[0;0m INFO 12-04 14:25:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=567529)[0;0m INFO 12-04 14:25:27 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=567532)[0;0m INFO 12-04 14:25:27 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=567529)[0;0m INFO 12-04 14:25:28 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=567529)[0;0m INFO 12-04 14:25:28 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=567532)[0;0m INFO 12-04 14:25:28 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=567532)[0;0m INFO 12-04 14:25:28 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=567529)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=567532)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=567529)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.18s/it]
[1;36m(EngineCore_DP0 pid=567532)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=567529)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.26it/s]
[1;36m(EngineCore_DP0 pid=567529)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.17it/s]
[1;36m(EngineCore_DP0 pid=567529)[0;0m 
[1;36m(EngineCore_DP0 pid=567529)[0;0m INFO 12-04 14:25:30 [default_loader.py:314] Loading weights took 1.76 seconds
[1;36m(EngineCore_DP0 pid=567532)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
[1;36m(EngineCore_DP0 pid=567532)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.17it/s]
[1;36m(EngineCore_DP0 pid=567532)[0;0m 
[1;36m(EngineCore_DP0 pid=567532)[0;0m INFO 12-04 14:25:30 [default_loader.py:314] Loading weights took 1.77 seconds
[1;36m(EngineCore_DP0 pid=567529)[0;0m INFO 12-04 14:25:31 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.865584 seconds
[1;36m(EngineCore_DP0 pid=567532)[0;0m INFO 12-04 14:25:31 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.995483 seconds
[1;36m(EngineCore_DP0 pid=567529)[0;0m INFO 12-04 14:25:39 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=567529)[0;0m INFO 12-04 14:25:39 [backends.py:647] Dynamo bytecode transform time: 8.17 s
[1;36m(EngineCore_DP0 pid=567532)[0;0m INFO 12-04 14:25:39 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=567532)[0;0m INFO 12-04 14:25:39 [backends.py:647] Dynamo bytecode transform time: 8.08 s
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f58a8273500>' raised:
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567529)[0;0m ERROR 12-04 14:25:40 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567529)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=567529)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=567529)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=567529)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567529)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567529)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567529)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567529)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567529)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567529)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567529)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567529)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567529)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567529)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567529)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567529)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567529)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567529)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567529)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567529)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567529)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567529)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567529)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567529)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567529)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567529)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567529)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567529)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567529)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567529)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567529)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567529)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567529)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567529)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567529)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567529)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567529)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567529)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567529)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567529)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567529)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567529)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567529)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567529)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567529)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567529)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567529)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567529)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f58a8273500>' raised:
[1;36m(EngineCore_DP0 pid=567529)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567529)[0;0m 
[1;36m(EngineCore_DP0 pid=567529)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567529)[0;0m 
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f048412ab10>' raised:
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567532)[0;0m ERROR 12-04 14:25:40 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567532)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=567532)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=567532)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=567532)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567532)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567532)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567532)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567532)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567532)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567532)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567532)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567532)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567532)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567532)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567532)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567532)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567532)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567532)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567532)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567532)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567532)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567532)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567532)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567532)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567532)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567532)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567532)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567532)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567532)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567532)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567532)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567532)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567532)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567532)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567532)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567532)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567532)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567532)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567532)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567532)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567532)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567532)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567532)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567532)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567532)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567532)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567532)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567532)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f048412ab10>' raised:
[1;36m(EngineCore_DP0 pid=567532)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567532)[0;0m 
[1;36m(EngineCore_DP0 pid=567532)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567532)[0;0m 
[rank0]:[W1204 14:25:41.773878140 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:25:41.894598254 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:02 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:02 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:26:02 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:26:02 [model.py:1745] Using max model len 131072
INFO 12-04 14:26:02 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:26:03 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:26:03 [model.py:1745] Using max model len 131072
INFO 12-04 14:26:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=567730)[0;0m INFO 12-04 14:26:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=567733)[0;0m INFO 12-04 14:26:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=567733)[0;0m INFO 12-04 14:26:19 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:41297 backend=nccl
[1;36m(EngineCore_DP0 pid=567730)[0;0m INFO 12-04 14:26:19 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:50063 backend=nccl
[W1204 14:26:19.976468213 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:41297 (errno: 97 - Address family not supported by protocol).
[W1204 14:26:19.979092841 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:50063 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=567730)[0;0m INFO 12-04 14:26:19 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=567733)[0;0m INFO 12-04 14:26:19 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=567730)[0;0m INFO 12-04 14:26:20 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=567733)[0;0m INFO 12-04 14:26:20 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=567730)[0;0m INFO 12-04 14:26:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=567733)[0;0m INFO 12-04 14:26:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=567733)[0;0m INFO 12-04 14:26:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=567730)[0;0m INFO 12-04 14:26:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=567730)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=567733)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=567730)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=567733)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=567730)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.28it/s]
[1;36m(EngineCore_DP0 pid=567730)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.19it/s]
[1;36m(EngineCore_DP0 pid=567730)[0;0m 
[1;36m(EngineCore_DP0 pid=567730)[0;0m INFO 12-04 14:26:23 [default_loader.py:314] Loading weights took 1.73 seconds
[1;36m(EngineCore_DP0 pid=567733)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.28it/s]
[1;36m(EngineCore_DP0 pid=567733)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=567733)[0;0m 
[1;36m(EngineCore_DP0 pid=567733)[0;0m INFO 12-04 14:26:23 [default_loader.py:314] Loading weights took 1.73 seconds
[1;36m(EngineCore_DP0 pid=567730)[0;0m INFO 12-04 14:26:23 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.878085 seconds
[1;36m(EngineCore_DP0 pid=567733)[0;0m INFO 12-04 14:26:23 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.965253 seconds
[1;36m(EngineCore_DP0 pid=567730)[0;0m INFO 12-04 14:26:32 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=567730)[0;0m INFO 12-04 14:26:32 [backends.py:647] Dynamo bytecode transform time: 8.25 s
[1;36m(EngineCore_DP0 pid=567733)[0;0m INFO 12-04 14:26:32 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=567733)[0;0m INFO 12-04 14:26:32 [backends.py:647] Dynamo bytecode transform time: 8.18 s
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f6b701c7110>' raised:
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567730)[0;0m ERROR 12-04 14:26:33 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f2d5820e6f0>' raised:
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567733)[0;0m ERROR 12-04 14:26:33 [core.py:842] 
[1;36m(EngineCore_DP0 pid=567730)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=567730)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=567730)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=567730)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567730)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567730)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567730)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567730)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567730)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567730)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567730)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567730)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567730)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567730)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567730)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567730)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567730)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567730)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567730)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567730)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567730)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567730)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567730)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567730)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567730)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567730)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567730)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567730)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567730)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567730)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567730)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567730)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567730)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567730)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567730)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567730)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567730)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567730)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567730)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567730)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567730)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567730)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567730)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567730)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567730)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567730)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567730)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567730)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f6b701c7110>' raised:
[1;36m(EngineCore_DP0 pid=567730)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567730)[0;0m 
[1;36m(EngineCore_DP0 pid=567730)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567730)[0;0m 
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=567733)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=567733)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=567733)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=567733)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=567733)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=567733)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=567733)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=567733)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=567733)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567733)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=567733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=567733)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=567733)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567733)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=567733)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=567733)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=567733)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=567733)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=567733)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=567733)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=567733)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=567733)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=567733)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=567733)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=567733)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=567733)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567733)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=567733)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=567733)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=567733)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=567733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=567733)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=567733)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=567733)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=567733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=567733)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=567733)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=567733)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=567733)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=567733)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=567733)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=567733)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=567733)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=567733)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=567733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=567733)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=567733)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f2d5820e6f0>' raised:
[1;36m(EngineCore_DP0 pid=567733)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=567733)[0;0m 
[1;36m(EngineCore_DP0 pid=567733)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=567733)[0;0m 
[rank0]:[W1204 14:26:33.233213912 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:26:33.233188803 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:55 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:55 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:26:55 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:26:55 [model.py:1745] Using max model len 131072
INFO 12-04 14:26:55 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:26:55 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:26:55 [model.py:1745] Using max model len 131072
INFO 12-04 14:26:55 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=568112)[0;0m INFO 12-04 14:27:08 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=568109)[0;0m INFO 12-04 14:27:08 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=568109)[0;0m INFO 12-04 14:27:09 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:55643 backend=nccl
[1;36m(EngineCore_DP0 pid=568112)[0;0m INFO 12-04 14:27:09 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:47679 backend=nccl
[W1204 14:27:09.041887383 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:55643 (errno: 97 - Address family not supported by protocol).
[W1204 14:27:09.043845868 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:47679 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=568112)[0;0m INFO 12-04 14:27:09 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=568109)[0;0m INFO 12-04 14:27:09 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=568112)[0;0m INFO 12-04 14:27:10 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=568109)[0;0m INFO 12-04 14:27:10 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=568112)[0;0m INFO 12-04 14:27:11 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=568112)[0;0m INFO 12-04 14:27:11 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=568109)[0;0m INFO 12-04 14:27:11 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=568109)[0;0m INFO 12-04 14:27:11 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=568109)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=568112)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=568109)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.05s/it]
[1;36m(EngineCore_DP0 pid=568112)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.12s/it]
[1;36m(EngineCore_DP0 pid=568109)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.37it/s]
[1;36m(EngineCore_DP0 pid=568109)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=568109)[0;0m 
[1;36m(EngineCore_DP0 pid=568109)[0;0m INFO 12-04 14:27:13 [default_loader.py:314] Loading weights took 1.62 seconds
[1;36m(EngineCore_DP0 pid=568112)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=568112)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=568112)[0;0m 
[1;36m(EngineCore_DP0 pid=568112)[0;0m INFO 12-04 14:27:13 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=568109)[0;0m INFO 12-04 14:27:13 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.749847 seconds
[1;36m(EngineCore_DP0 pid=568112)[0;0m INFO 12-04 14:27:14 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.156549 seconds
[1;36m(EngineCore_DP0 pid=568109)[0;0m INFO 12-04 14:27:21 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=568109)[0;0m INFO 12-04 14:27:21 [backends.py:647] Dynamo bytecode transform time: 7.93 s
[1;36m(EngineCore_DP0 pid=568112)[0;0m INFO 12-04 14:27:22 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=568112)[0;0m INFO 12-04 14:27:22 [backends.py:647] Dynamo bytecode transform time: 7.75 s
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb81dd53680>' raised:
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568109)[0;0m ERROR 12-04 14:27:22 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568109)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=568109)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=568109)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=568109)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568109)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568109)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568109)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568109)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568109)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568109)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568109)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568109)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568109)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568109)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568109)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568109)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568109)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568109)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568109)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568109)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568109)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568109)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568109)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568109)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568109)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568109)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568109)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568109)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568109)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568109)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568109)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568109)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568109)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568109)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568109)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568109)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568109)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568109)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568109)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568109)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568109)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568109)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568109)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568109)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568109)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568109)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568109)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568109)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb81dd53680>' raised:
[1;36m(EngineCore_DP0 pid=568109)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568109)[0;0m 
[1;36m(EngineCore_DP0 pid=568109)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568109)[0;0m 
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f46314ceba0>' raised:
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568112)[0;0m ERROR 12-04 14:27:22 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568112)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=568112)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=568112)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=568112)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568112)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568112)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568112)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568112)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568112)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568112)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568112)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568112)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568112)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568112)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568112)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568112)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568112)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568112)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568112)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568112)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568112)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568112)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568112)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568112)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568112)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568112)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568112)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568112)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568112)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568112)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568112)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568112)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568112)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568112)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568112)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568112)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568112)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568112)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568112)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568112)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568112)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568112)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568112)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568112)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568112)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568112)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568112)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568112)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f46314ceba0>' raised:
[1;36m(EngineCore_DP0 pid=568112)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568112)[0;0m 
[1;36m(EngineCore_DP0 pid=568112)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568112)[0;0m 
[rank0]:[W1204 14:27:23.540997320 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:27:23.797952256 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:27:44 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:27:44 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:27:44 [model.py:1745] Using max model len 131072
INFO 12-04 14:27:44 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:27:44 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:27:44 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:27:44 [model.py:1745] Using max model len 131072
INFO 12-04 14:27:44 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=568269)[0;0m INFO 12-04 14:27:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=568272)[0;0m INFO 12-04 14:27:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=568269)[0;0m INFO 12-04 14:28:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:41293 backend=nccl
[1;36m(EngineCore_DP0 pid=568272)[0;0m INFO 12-04 14:28:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:46389 backend=nccl
[W1204 14:28:01.487188677 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:41293 (errno: 97 - Address family not supported by protocol).
[W1204 14:28:01.488684682 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:46389 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=568272)[0;0m INFO 12-04 14:28:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=568269)[0;0m INFO 12-04 14:28:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=568269)[0;0m INFO 12-04 14:28:01 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=568272)[0;0m INFO 12-04 14:28:01 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=568269)[0;0m INFO 12-04 14:28:02 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=568269)[0;0m INFO 12-04 14:28:02 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=568272)[0;0m INFO 12-04 14:28:02 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=568272)[0;0m INFO 12-04 14:28:02 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=568272)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=568269)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=568272)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=568269)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.12s/it]
[1;36m(EngineCore_DP0 pid=568272)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=568272)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=568272)[0;0m 
[1;36m(EngineCore_DP0 pid=568272)[0;0m INFO 12-04 14:28:04 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=568269)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=568269)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=568269)[0;0m 
[1;36m(EngineCore_DP0 pid=568269)[0;0m INFO 12-04 14:28:04 [default_loader.py:314] Loading weights took 1.69 seconds
[1;36m(EngineCore_DP0 pid=568272)[0;0m INFO 12-04 14:28:05 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.820475 seconds
[1;36m(EngineCore_DP0 pid=568269)[0;0m INFO 12-04 14:28:05 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.909543 seconds
[1;36m(EngineCore_DP0 pid=568272)[0;0m INFO 12-04 14:28:14 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=568269)[0;0m INFO 12-04 14:28:14 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=568272)[0;0m INFO 12-04 14:28:14 [backends.py:647] Dynamo bytecode transform time: 8.39 s
[1;36m(EngineCore_DP0 pid=568269)[0;0m INFO 12-04 14:28:14 [backends.py:647] Dynamo bytecode transform time: 8.32 s
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f06543d7800>' raised:
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568269)[0;0m ERROR 12-04 14:28:14 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc1401055b0>' raised:
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568272)[0;0m ERROR 12-04 14:28:14 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568269)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568272)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=568269)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=568269)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=568272)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=568272)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=568272)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568272)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=568269)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568269)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568269)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568269)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568269)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568269)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568269)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568269)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568269)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568272)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568272)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568272)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568272)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568272)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568272)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568272)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568272)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568272)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568272)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568272)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568272)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568272)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568272)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568272)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568269)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568269)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568269)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568269)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568269)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568269)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568269)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568269)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568269)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568269)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568269)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568269)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568272)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568272)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568272)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568272)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568272)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568272)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568272)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568272)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568272)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568272)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568269)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568269)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568269)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568269)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568269)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568269)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568269)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568269)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568269)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568269)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568269)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568269)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568269)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568269)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568269)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568272)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568272)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568272)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568272)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568272)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568272)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568272)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568272)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568272)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568272)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568272)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568272)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568272)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568272)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568272)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568272)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc1401055b0>' raised:
[1;36m(EngineCore_DP0 pid=568272)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568272)[0;0m 
[1;36m(EngineCore_DP0 pid=568272)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568272)[0;0m 
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568269)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568269)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568269)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568269)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f06543d7800>' raised:
[1;36m(EngineCore_DP0 pid=568269)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568269)[0;0m 
[1;36m(EngineCore_DP0 pid=568269)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568269)[0;0m 
[rank0]:[W1204 14:28:15.798598750 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:28:15.798736929 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:28:36 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:28:36 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:28:36 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:28:36 [model.py:1745] Using max model len 131072
INFO 12-04 14:28:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:28:36 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:28:36 [model.py:1745] Using max model len 131072
INFO 12-04 14:28:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=568808)[0;0m INFO 12-04 14:28:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=568819)[0;0m INFO 12-04 14:28:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=568819)[0;0m INFO 12-04 14:28:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:32903 backend=nccl
[1;36m(EngineCore_DP0 pid=568808)[0;0m INFO 12-04 14:28:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:44821 backend=nccl
[W1204 14:28:51.643413765 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:32903 (errno: 97 - Address family not supported by protocol).
[W1204 14:28:51.643832455 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:44821 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=568808)[0;0m INFO 12-04 14:28:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=568819)[0;0m INFO 12-04 14:28:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=568808)[0;0m INFO 12-04 14:28:51 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=568819)[0;0m INFO 12-04 14:28:51 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=568819)[0;0m INFO 12-04 14:28:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=568819)[0;0m INFO 12-04 14:28:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=568808)[0;0m INFO 12-04 14:28:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=568808)[0;0m INFO 12-04 14:28:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=568808)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=568819)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=568808)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=568819)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=568808)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=568808)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=568808)[0;0m 
[1;36m(EngineCore_DP0 pid=568808)[0;0m INFO 12-04 14:28:54 [default_loader.py:314] Loading weights took 1.72 seconds
[1;36m(EngineCore_DP0 pid=568819)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=568819)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=568819)[0;0m 
[1;36m(EngineCore_DP0 pid=568819)[0;0m INFO 12-04 14:28:54 [default_loader.py:314] Loading weights took 1.72 seconds
[1;36m(EngineCore_DP0 pid=568808)[0;0m INFO 12-04 14:28:55 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.810206 seconds
[1;36m(EngineCore_DP0 pid=568819)[0;0m INFO 12-04 14:28:55 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.900250 seconds
[1;36m(EngineCore_DP0 pid=568808)[0;0m INFO 12-04 14:29:04 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=568808)[0;0m INFO 12-04 14:29:04 [backends.py:647] Dynamo bytecode transform time: 8.29 s
[1;36m(EngineCore_DP0 pid=568819)[0;0m INFO 12-04 14:29:04 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=568819)[0;0m INFO 12-04 14:29:04 [backends.py:647] Dynamo bytecode transform time: 8.42 s
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fa1782bb590>' raised:
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568808)[0;0m ERROR 12-04 14:29:04 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568808)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=568808)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=568808)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=568808)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568808)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568808)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568808)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568808)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568808)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568808)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568808)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568808)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568808)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568808)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568808)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568808)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568808)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568808)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568808)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568808)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568808)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568808)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568808)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568808)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568808)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568808)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568808)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568808)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568808)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568808)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568808)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568808)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568808)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568808)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568808)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568808)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568808)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568808)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568808)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568808)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568808)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568808)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568808)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568808)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568808)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568808)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568808)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568808)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fa1782bb590>' raised:
[1;36m(EngineCore_DP0 pid=568808)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568808)[0;0m 
[1;36m(EngineCore_DP0 pid=568808)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568808)[0;0m 
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb79c2709b0>' raised:
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568819)[0;0m ERROR 12-04 14:29:04 [core.py:842] 
[1;36m(EngineCore_DP0 pid=568819)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=568819)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=568819)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=568819)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=568819)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=568819)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=568819)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=568819)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=568819)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=568819)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568819)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=568819)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=568819)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=568819)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568819)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=568819)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=568819)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=568819)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=568819)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=568819)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=568819)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=568819)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=568819)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=568819)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=568819)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=568819)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=568819)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568819)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=568819)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=568819)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=568819)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=568819)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=568819)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=568819)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=568819)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=568819)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=568819)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=568819)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=568819)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=568819)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=568819)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=568819)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=568819)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=568819)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=568819)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=568819)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=568819)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=568819)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb79c2709b0>' raised:
[1;36m(EngineCore_DP0 pid=568819)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=568819)[0;0m 
[1;36m(EngineCore_DP0 pid=568819)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=568819)[0;0m 
[rank0]:[W1204 14:29:05.586099081 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:29:05.907278685 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:29:26 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:29:26 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:29:26 [model.py:1745] Using max model len 131072
INFO 12-04 14:29:26 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:29:26 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:29:26 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:29:26 [model.py:1745] Using max model len 131072
INFO 12-04 14:29:26 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=569265)[0;0m INFO 12-04 14:29:41 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=569269)[0;0m INFO 12-04 14:29:41 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=569265)[0;0m INFO 12-04 14:29:43 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:38817 backend=nccl
[1;36m(EngineCore_DP0 pid=569269)[0;0m INFO 12-04 14:29:43 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:44179 backend=nccl
[W1204 14:29:43.535957215 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:38817 (errno: 97 - Address family not supported by protocol).
[W1204 14:29:43.538983353 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:44179 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=569269)[0;0m INFO 12-04 14:29:43 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=569265)[0;0m INFO 12-04 14:29:43 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=569269)[0;0m INFO 12-04 14:29:43 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=569265)[0;0m INFO 12-04 14:29:43 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=569265)[0;0m INFO 12-04 14:29:44 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=569269)[0;0m INFO 12-04 14:29:44 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=569269)[0;0m INFO 12-04 14:29:44 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=569265)[0;0m INFO 12-04 14:29:44 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=569265)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=569269)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=569265)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=569269)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=569265)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=569265)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=569265)[0;0m 
[1;36m(EngineCore_DP0 pid=569265)[0;0m INFO 12-04 14:29:46 [default_loader.py:314] Loading weights took 1.72 seconds
[1;36m(EngineCore_DP0 pid=569269)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=569269)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=569269)[0;0m 
[1;36m(EngineCore_DP0 pid=569269)[0;0m INFO 12-04 14:29:46 [default_loader.py:314] Loading weights took 1.72 seconds
[1;36m(EngineCore_DP0 pid=569265)[0;0m INFO 12-04 14:29:47 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.922320 seconds
[1;36m(EngineCore_DP0 pid=569269)[0;0m INFO 12-04 14:29:47 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.027667 seconds
[1;36m(EngineCore_DP0 pid=569265)[0;0m INFO 12-04 14:29:56 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=569265)[0;0m INFO 12-04 14:29:56 [backends.py:647] Dynamo bytecode transform time: 8.46 s
[1;36m(EngineCore_DP0 pid=569269)[0;0m INFO 12-04 14:29:56 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=569269)[0;0m INFO 12-04 14:29:56 [backends.py:647] Dynamo bytecode transform time: 8.42 s
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd4fc2bd730>' raised:
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569265)[0;0m ERROR 12-04 14:29:56 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569265)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=569265)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=569265)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=569265)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569265)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569265)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569265)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569265)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569265)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569265)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569265)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569265)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569265)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569265)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569265)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569265)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569265)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569265)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569265)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569265)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569265)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569265)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569265)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569265)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569265)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569265)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569265)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569265)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569265)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569265)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569265)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569265)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569265)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569265)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569265)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569265)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569265)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569265)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569265)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569265)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569265)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569265)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569265)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569265)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569265)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569265)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569265)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569265)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd4fc2bd730>' raised:
[1;36m(EngineCore_DP0 pid=569265)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569265)[0;0m 
[1;36m(EngineCore_DP0 pid=569265)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569265)[0;0m 
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f2975ca5be0>' raised:
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569269)[0;0m ERROR 12-04 14:29:56 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569269)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=569269)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=569269)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=569269)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569269)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569269)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569269)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569269)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569269)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569269)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569269)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569269)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569269)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569269)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569269)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569269)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569269)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569269)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569269)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569269)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569269)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569269)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569269)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569269)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569269)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569269)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569269)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569269)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569269)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569269)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569269)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569269)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569269)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569269)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569269)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569269)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569269)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569269)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569269)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569269)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569269)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569269)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569269)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569269)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569269)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569269)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f2975ca5be0>' raised:
[1;36m(EngineCore_DP0 pid=569269)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569269)[0;0m 
[1;36m(EngineCore_DP0 pid=569269)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569269)[0;0m 
[rank0]:[W1204 14:29:57.881199767 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:29:57.900457174 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:30:18 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:30:18 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:30:18 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:30:18 [model.py:1745] Using max model len 131072
INFO 12-04 14:30:18 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:30:18 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:30:18 [model.py:1745] Using max model len 131072
INFO 12-04 14:30:18 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=569605)[0;0m INFO 12-04 14:30:34 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=569608)[0;0m INFO 12-04 14:30:34 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=569605)[0;0m INFO 12-04 14:30:36 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:53713 backend=nccl
[1;36m(EngineCore_DP0 pid=569608)[0;0m INFO 12-04 14:30:36 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:35517 backend=nccl
[W1204 14:30:36.563917852 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:53713 (errno: 97 - Address family not supported by protocol).
[W1204 14:30:36.566030159 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:35517 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=569608)[0;0m INFO 12-04 14:30:36 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=569605)[0;0m INFO 12-04 14:30:36 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=569608)[0;0m INFO 12-04 14:30:36 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=569605)[0;0m INFO 12-04 14:30:36 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=569605)[0;0m INFO 12-04 14:30:37 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=569605)[0;0m INFO 12-04 14:30:37 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=569608)[0;0m INFO 12-04 14:30:37 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=569608)[0;0m INFO 12-04 14:30:37 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=569608)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=569605)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=569608)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.12s/it]
[1;36m(EngineCore_DP0 pid=569605)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=569608)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=569608)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=569608)[0;0m 
[1;36m(EngineCore_DP0 pid=569608)[0;0m INFO 12-04 14:30:39 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=569605)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=569605)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=569605)[0;0m 
[1;36m(EngineCore_DP0 pid=569605)[0;0m INFO 12-04 14:30:40 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=569608)[0;0m INFO 12-04 14:30:40 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.843044 seconds
[1;36m(EngineCore_DP0 pid=569605)[0;0m INFO 12-04 14:30:40 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.079651 seconds
[1;36m(EngineCore_DP0 pid=569608)[0;0m INFO 12-04 14:30:49 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=569608)[0;0m INFO 12-04 14:30:49 [backends.py:647] Dynamo bytecode transform time: 8.37 s
[1;36m(EngineCore_DP0 pid=569605)[0;0m INFO 12-04 14:30:49 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=569605)[0;0m INFO 12-04 14:30:49 [backends.py:647] Dynamo bytecode transform time: 8.29 s
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f60f02d66f0>' raised:
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569608)[0;0m ERROR 12-04 14:30:49 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569608)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=569608)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=569608)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=569608)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569608)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569608)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569608)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569608)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569608)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569608)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569608)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569608)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569608)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569608)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569608)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569608)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569608)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569608)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569608)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569608)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569608)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569608)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569608)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569608)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569608)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569608)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569608)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569608)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569608)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569608)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569608)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569608)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569608)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569608)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569608)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569608)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569608)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569608)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569608)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569608)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569608)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569608)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569608)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569608)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569608)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569608)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569608)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569608)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f60f02d66f0>' raised:
[1;36m(EngineCore_DP0 pid=569608)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569608)[0;0m 
[1;36m(EngineCore_DP0 pid=569608)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569608)[0;0m 
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f6b882977d0>' raised:
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569605)[0;0m ERROR 12-04 14:30:50 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569605)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=569605)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=569605)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=569605)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569605)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569605)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569605)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569605)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569605)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569605)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569605)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569605)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569605)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569605)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569605)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569605)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569605)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569605)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569605)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569605)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569605)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569605)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569605)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569605)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569605)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569605)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569605)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569605)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569605)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569605)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569605)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569605)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569605)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569605)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569605)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569605)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569605)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569605)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569605)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569605)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569605)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569605)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569605)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569605)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569605)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569605)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569605)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569605)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f6b882977d0>' raised:
[1;36m(EngineCore_DP0 pid=569605)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569605)[0;0m 
[1;36m(EngineCore_DP0 pid=569605)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569605)[0;0m 
[rank0]:[W1204 14:30:50.136477386 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:30:50.388285148 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:31:12 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:31:12 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:31:12 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:31:12 [model.py:1745] Using max model len 131072
INFO 12-04 14:31:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:31:12 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:31:12 [model.py:1745] Using max model len 131072
INFO 12-04 14:31:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=569896)[0;0m INFO 12-04 14:31:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=569899)[0;0m INFO 12-04 14:31:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=569899)[0;0m INFO 12-04 14:31:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:58427 backend=nccl
[1;36m(EngineCore_DP0 pid=569896)[0;0m INFO 12-04 14:31:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:53869 backend=nccl
[W1204 14:31:29.738354245 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:58427 (errno: 97 - Address family not supported by protocol).
[W1204 14:31:29.740966884 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:53869 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=569896)[0;0m INFO 12-04 14:31:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=569899)[0;0m INFO 12-04 14:31:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=569899)[0;0m INFO 12-04 14:31:29 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=569896)[0;0m INFO 12-04 14:31:29 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=569899)[0;0m INFO 12-04 14:31:30 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=569899)[0;0m INFO 12-04 14:31:30 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=569896)[0;0m INFO 12-04 14:31:30 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=569896)[0;0m INFO 12-04 14:31:30 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=569899)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=569896)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=569899)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.22s/it]
[1;36m(EngineCore_DP0 pid=569896)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.19s/it]
[1;36m(EngineCore_DP0 pid=569899)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=569899)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.15it/s]
[1;36m(EngineCore_DP0 pid=569899)[0;0m 
[1;36m(EngineCore_DP0 pid=569899)[0;0m INFO 12-04 14:31:33 [default_loader.py:314] Loading weights took 1.80 seconds
[1;36m(EngineCore_DP0 pid=569896)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=569896)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.16it/s]
[1;36m(EngineCore_DP0 pid=569896)[0;0m 
[1;36m(EngineCore_DP0 pid=569896)[0;0m INFO 12-04 14:31:33 [default_loader.py:314] Loading weights took 1.79 seconds
[1;36m(EngineCore_DP0 pid=569899)[0;0m INFO 12-04 14:31:33 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.947030 seconds
[1;36m(EngineCore_DP0 pid=569896)[0;0m INFO 12-04 14:31:33 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.033014 seconds
[1;36m(EngineCore_DP0 pid=569899)[0;0m INFO 12-04 14:31:42 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=569899)[0;0m INFO 12-04 14:31:42 [backends.py:647] Dynamo bytecode transform time: 8.37 s
[1;36m(EngineCore_DP0 pid=569896)[0;0m INFO 12-04 14:31:42 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=569896)[0;0m INFO 12-04 14:31:42 [backends.py:647] Dynamo bytecode transform time: 8.33 s
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fbcb40b3d40>' raised:
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569899)[0;0m ERROR 12-04 14:31:43 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569899)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=569899)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=569899)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=569899)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569899)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569899)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569899)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569899)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569899)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569899)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569899)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569899)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569899)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569899)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569899)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569899)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569899)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569899)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569899)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569899)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569899)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569899)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569899)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569899)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569899)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569899)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569899)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569899)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569899)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569899)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569899)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569899)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569899)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569899)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569899)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569899)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569899)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569899)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569899)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569899)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569899)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569899)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569899)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569899)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569899)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569899)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569899)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569899)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fbcb40b3d40>' raised:
[1;36m(EngineCore_DP0 pid=569899)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569899)[0;0m 
[1;36m(EngineCore_DP0 pid=569899)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569899)[0;0m 
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f595022a930>' raised:
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569896)[0;0m ERROR 12-04 14:31:43 [core.py:842] 
[1;36m(EngineCore_DP0 pid=569896)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=569896)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=569896)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=569896)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=569896)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=569896)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=569896)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=569896)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=569896)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=569896)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569896)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=569896)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=569896)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=569896)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569896)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=569896)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=569896)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=569896)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=569896)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=569896)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=569896)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=569896)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=569896)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=569896)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=569896)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=569896)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=569896)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569896)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=569896)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=569896)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=569896)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=569896)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=569896)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=569896)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=569896)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=569896)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=569896)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=569896)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=569896)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=569896)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=569896)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=569896)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=569896)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=569896)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=569896)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=569896)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=569896)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=569896)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f595022a930>' raised:
[1;36m(EngineCore_DP0 pid=569896)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=569896)[0;0m 
[1;36m(EngineCore_DP0 pid=569896)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=569896)[0;0m 
[rank0]:[W1204 14:31:43.244020032 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:31:43.262044654 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:05 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:32:05 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:32:05 [model.py:1745] Using max model len 131072
INFO 12-04 14:32:05 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:05 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:32:05 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:32:05 [model.py:1745] Using max model len 131072
INFO 12-04 14:32:05 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=570340)[0;0m INFO 12-04 14:32:19 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=570343)[0;0m INFO 12-04 14:32:19 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=570343)[0;0m INFO 12-04 14:32:21 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:50275 backend=nccl
[1;36m(EngineCore_DP0 pid=570340)[0;0m INFO 12-04 14:32:21 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:36263 backend=nccl
[W1204 14:32:21.629987519 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:50275 (errno: 97 - Address family not supported by protocol).
[W1204 14:32:21.630444574 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:36263 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=570343)[0;0m INFO 12-04 14:32:21 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=570340)[0;0m INFO 12-04 14:32:21 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=570340)[0;0m INFO 12-04 14:32:21 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=570343)[0;0m INFO 12-04 14:32:21 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=570343)[0;0m INFO 12-04 14:32:22 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=570343)[0;0m INFO 12-04 14:32:22 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=570340)[0;0m INFO 12-04 14:32:22 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=570340)[0;0m INFO 12-04 14:32:22 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=570343)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=570340)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=570343)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=570340)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=570343)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
[1;36m(EngineCore_DP0 pid=570343)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
[1;36m(EngineCore_DP0 pid=570343)[0;0m 
[1;36m(EngineCore_DP0 pid=570343)[0;0m INFO 12-04 14:32:24 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=570340)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=570340)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=570340)[0;0m 
[1;36m(EngineCore_DP0 pid=570340)[0;0m INFO 12-04 14:32:25 [default_loader.py:314] Loading weights took 1.70 seconds
[1;36m(EngineCore_DP0 pid=570343)[0;0m INFO 12-04 14:32:25 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.870327 seconds
[1;36m(EngineCore_DP0 pid=570340)[0;0m INFO 12-04 14:32:25 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.983054 seconds
[1;36m(EngineCore_DP0 pid=570343)[0;0m INFO 12-04 14:32:34 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=570343)[0;0m INFO 12-04 14:32:34 [backends.py:647] Dynamo bytecode transform time: 8.05 s
[1;36m(EngineCore_DP0 pid=570340)[0;0m INFO 12-04 14:32:34 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=570340)[0;0m INFO 12-04 14:32:34 [backends.py:647] Dynamo bytecode transform time: 8.06 s
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f89903bb7d0>' raised:
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842] 
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=570343)[0;0m ERROR 12-04 14:32:34 [core.py:842] 
[1;36m(EngineCore_DP0 pid=570343)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=570343)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=570343)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=570343)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=570343)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=570343)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=570343)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=570343)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=570343)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=570343)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570343)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=570343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=570343)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=570343)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570343)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570343)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=570343)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=570343)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570343)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=570343)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=570343)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=570343)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=570343)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=570343)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=570343)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=570343)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=570343)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570343)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570343)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=570343)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=570343)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=570343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=570343)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=570343)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=570343)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=570343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=570343)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=570343)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=570343)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=570343)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=570343)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=570343)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=570343)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=570343)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=570343)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=570343)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=570343)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f89903bb7d0>' raised:
[1;36m(EngineCore_DP0 pid=570343)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=570343)[0;0m 
[1;36m(EngineCore_DP0 pid=570343)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=570343)[0;0m 
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f1c5c239fa0>' raised:
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842] 
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=570340)[0;0m ERROR 12-04 14:32:34 [core.py:842] 
[1;36m(EngineCore_DP0 pid=570340)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=570340)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=570340)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=570340)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=570340)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=570340)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=570340)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=570340)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=570340)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=570340)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570340)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=570340)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=570340)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=570340)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570340)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570340)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=570340)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=570340)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570340)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=570340)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=570340)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=570340)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=570340)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=570340)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=570340)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=570340)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=570340)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570340)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570340)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=570340)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=570340)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=570340)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=570340)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=570340)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=570340)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=570340)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=570340)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=570340)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=570340)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=570340)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=570340)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=570340)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=570340)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=570340)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=570340)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570340)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=570340)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=570340)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f1c5c239fa0>' raised:
[1;36m(EngineCore_DP0 pid=570340)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=570340)[0;0m 
[1;36m(EngineCore_DP0 pid=570340)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=570340)[0;0m 
[rank0]:[W1204 14:32:35.992712485 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:32:35.137896380 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:56 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:32:57 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:32:57 [model.py:1745] Using max model len 131072
INFO 12-04 14:32:57 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:57 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:32:57 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:32:57 [model.py:1745] Using max model len 131072
INFO 12-04 14:32:57 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=570715)[0;0m INFO 12-04 14:33:13 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=570712)[0;0m INFO 12-04 14:33:13 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=570712)[0;0m INFO 12-04 14:33:15 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:33185 backend=nccl
[1;36m(EngineCore_DP0 pid=570715)[0;0m INFO 12-04 14:33:15 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:39587 backend=nccl
[W1204 14:33:15.500839059 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:33185 (errno: 97 - Address family not supported by protocol).
[W1204 14:33:15.504015380 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:39587 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=570715)[0;0m INFO 12-04 14:33:15 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=570712)[0;0m INFO 12-04 14:33:15 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=570715)[0;0m INFO 12-04 14:33:15 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=570712)[0;0m INFO 12-04 14:33:15 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=570715)[0;0m INFO 12-04 14:33:16 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=570715)[0;0m INFO 12-04 14:33:16 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=570712)[0;0m INFO 12-04 14:33:16 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=570712)[0;0m INFO 12-04 14:33:16 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=570715)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=570712)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=570715)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=570712)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=570715)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.27it/s]
[1;36m(EngineCore_DP0 pid=570715)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.19it/s]
[1;36m(EngineCore_DP0 pid=570715)[0;0m 
[1;36m(EngineCore_DP0 pid=570715)[0;0m INFO 12-04 14:33:18 [default_loader.py:314] Loading weights took 1.74 seconds
[1;36m(EngineCore_DP0 pid=570712)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.27it/s]
[1;36m(EngineCore_DP0 pid=570712)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.19it/s]
[1;36m(EngineCore_DP0 pid=570712)[0;0m 
[1;36m(EngineCore_DP0 pid=570712)[0;0m INFO 12-04 14:33:19 [default_loader.py:314] Loading weights took 1.74 seconds
[1;36m(EngineCore_DP0 pid=570715)[0;0m INFO 12-04 14:33:19 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.935260 seconds
[1;36m(EngineCore_DP0 pid=570712)[0;0m INFO 12-04 14:33:19 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.023370 seconds
[1;36m(EngineCore_DP0 pid=570715)[0;0m INFO 12-04 14:33:28 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=570715)[0;0m INFO 12-04 14:33:28 [backends.py:647] Dynamo bytecode transform time: 8.37 s
[1;36m(EngineCore_DP0 pid=570712)[0;0m INFO 12-04 14:33:28 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=570712)[0;0m INFO 12-04 14:33:28 [backends.py:647] Dynamo bytecode transform time: 8.30 s
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f4b54212540>' raised:
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=570715)[0;0m ERROR 12-04 14:33:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fbc703b27e0>' raised:
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=570712)[0;0m ERROR 12-04 14:33:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=570715)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=570712)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=570715)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=570712)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=570715)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=570715)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=570712)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=570712)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=570712)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=570715)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=570715)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=570712)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=570712)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=570712)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=570712)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=570715)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=570715)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=570715)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=570715)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=570712)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=570712)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570712)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=570712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570715)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=570715)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=570715)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=570715)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=570712)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=570712)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570712)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570712)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570715)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=570715)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=570715)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=570715)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570715)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=570715)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=570715)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=570712)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=570712)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=570712)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=570712)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=570712)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=570712)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=570712)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=570712)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=570712)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=570715)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=570715)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=570715)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=570715)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=570715)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570715)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570715)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=570715)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=570712)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=570712)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570712)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=570712)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=570712)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=570712)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=570712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=570712)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=570712)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=570712)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=570712)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=570712)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=570712)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=570712)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=570712)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=570712)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=570715)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=570715)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=570715)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=570715)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=570715)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=570715)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=570715)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=570715)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=570715)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=570715)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=570715)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=570715)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=570715)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=570715)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=570715)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570715)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=570715)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=570715)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f4b54212540>' raised:
[1;36m(EngineCore_DP0 pid=570715)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=570715)[0;0m 
[1;36m(EngineCore_DP0 pid=570715)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=570715)[0;0m 
[1;36m(EngineCore_DP0 pid=570712)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=570712)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=570712)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=570712)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=570712)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=570712)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=570712)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fbc703b27e0>' raised:
[1;36m(EngineCore_DP0 pid=570712)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=570712)[0;0m 
[1;36m(EngineCore_DP0 pid=570712)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=570712)[0;0m 
[rank0]:[W1204 14:33:30.412312103 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:33:30.415329107 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:33:51 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:33:51 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:33:51 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:33:51 [model.py:1745] Using max model len 131072
INFO 12-04 14:33:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:33:51 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:33:51 [model.py:1745] Using max model len 131072
INFO 12-04 14:33:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=571934)[0;0m INFO 12-04 14:34:07 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=571931)[0;0m INFO 12-04 14:34:07 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=571934)[0;0m INFO 12-04 14:34:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:49265 backend=nccl
[1;36m(EngineCore_DP0 pid=571931)[0;0m INFO 12-04 14:34:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:36501 backend=nccl
[W1204 14:34:08.106710534 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:49265 (errno: 97 - Address family not supported by protocol).
[W1204 14:34:08.106742968 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:36501 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=571934)[0;0m INFO 12-04 14:34:08 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=571931)[0;0m INFO 12-04 14:34:08 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=571934)[0;0m INFO 12-04 14:34:09 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=571931)[0;0m INFO 12-04 14:34:09 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=571931)[0;0m INFO 12-04 14:34:10 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=571931)[0;0m INFO 12-04 14:34:10 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=571934)[0;0m INFO 12-04 14:34:10 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=571934)[0;0m INFO 12-04 14:34:10 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=571931)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=571934)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=571934)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=571931)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.27s/it]
[1;36m(EngineCore_DP0 pid=571934)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.27it/s]
[1;36m(EngineCore_DP0 pid=571934)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.19it/s]
[1;36m(EngineCore_DP0 pid=571931)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=571931)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.11it/s]
[1;36m(EngineCore_DP0 pid=571931)[0;0m 
[1;36m(EngineCore_DP0 pid=571934)[0;0m 
[1;36m(EngineCore_DP0 pid=571934)[0;0m INFO 12-04 14:34:12 [default_loader.py:314] Loading weights took 1.73 seconds
[1;36m(EngineCore_DP0 pid=571931)[0;0m INFO 12-04 14:34:12 [default_loader.py:314] Loading weights took 1.85 seconds
[1;36m(EngineCore_DP0 pid=571931)[0;0m INFO 12-04 14:34:13 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.923777 seconds
[1;36m(EngineCore_DP0 pid=571934)[0;0m INFO 12-04 14:34:13 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.922870 seconds
[1;36m(EngineCore_DP0 pid=571931)[0;0m INFO 12-04 14:34:21 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=571934)[0;0m INFO 12-04 14:34:21 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=571931)[0;0m INFO 12-04 14:34:21 [backends.py:647] Dynamo bytecode transform time: 8.41 s
[1;36m(EngineCore_DP0 pid=571934)[0;0m INFO 12-04 14:34:21 [backends.py:647] Dynamo bytecode transform time: 8.41 s
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7faa7c2fb230>' raised:
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842] 
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=571934)[0;0m ERROR 12-04 14:34:22 [core.py:842] 
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd087375730>' raised:
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842] 
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=571931)[0;0m ERROR 12-04 14:34:22 [core.py:842] 
[1;36m(EngineCore_DP0 pid=571931)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=571934)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=571934)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=571934)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=571931)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=571931)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=571931)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=571931)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=571934)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=571934)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=571934)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=571934)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=571934)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=571934)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=571934)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=571934)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=571934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=571934)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=571931)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=571931)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=571931)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=571931)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=571931)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=571931)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=571931)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=571931)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=571931)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=571931)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=571931)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=571931)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=571931)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=571931)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=571931)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=571931)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=571934)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=571934)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=571934)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=571934)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=571934)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=571934)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=571934)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=571934)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=571934)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=571934)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=571934)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=571934)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=571931)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=571931)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=571931)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=571931)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=571931)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=571931)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=571931)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=571931)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=571931)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=571931)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=571931)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=571934)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=571934)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=571934)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=571934)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=571934)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=571934)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=571934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=571934)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=571934)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=571934)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=571934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=571934)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=571934)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=571934)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=571934)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=571934)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=571931)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=571931)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=571931)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=571931)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=571931)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=571931)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=571931)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=571931)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=571931)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=571931)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=571931)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=571931)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=571931)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571931)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=571931)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=571931)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd087375730>' raised:
[1;36m(EngineCore_DP0 pid=571931)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=571931)[0;0m 
[1;36m(EngineCore_DP0 pid=571931)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=571931)[0;0m 
[1;36m(EngineCore_DP0 pid=571934)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=571934)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=571934)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=571934)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=571934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=571934)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=571934)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7faa7c2fb230>' raised:
[1;36m(EngineCore_DP0 pid=571934)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=571934)[0;0m 
[1;36m(EngineCore_DP0 pid=571934)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=571934)[0;0m 
[rank0]:[W1204 14:34:22.372882180 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:34:22.374838047 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:34:44 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:34:44 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:34:44 [model.py:1745] Using max model len 131072
INFO 12-04 14:34:44 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:34:44 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:34:44 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:34:44 [model.py:1745] Using max model len 131072
INFO 12-04 14:34:44 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=572793)[0;0m INFO 12-04 14:34:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=572798)[0;0m INFO 12-04 14:34:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=572798)[0;0m INFO 12-04 14:35:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:36959 backend=nccl
[1;36m(EngineCore_DP0 pid=572793)[0;0m INFO 12-04 14:35:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:59819 backend=nccl
[W1204 14:35:01.959075986 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:36959 (errno: 97 - Address family not supported by protocol).
[W1204 14:35:01.960523425 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:59819 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=572793)[0;0m INFO 12-04 14:35:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=572798)[0;0m INFO 12-04 14:35:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=572793)[0;0m INFO 12-04 14:35:02 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=572798)[0;0m INFO 12-04 14:35:02 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=572793)[0;0m INFO 12-04 14:35:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=572793)[0;0m INFO 12-04 14:35:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=572798)[0;0m INFO 12-04 14:35:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=572798)[0;0m INFO 12-04 14:35:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=572793)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=572798)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=572793)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.19s/it]
[1;36m(EngineCore_DP0 pid=572798)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=572793)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.28it/s]
[1;36m(EngineCore_DP0 pid=572793)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.18it/s]
[1;36m(EngineCore_DP0 pid=572793)[0;0m 
[1;36m(EngineCore_DP0 pid=572793)[0;0m INFO 12-04 14:35:05 [default_loader.py:314] Loading weights took 1.75 seconds
[1;36m(EngineCore_DP0 pid=572798)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.27it/s]
[1;36m(EngineCore_DP0 pid=572798)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.19it/s]
[1;36m(EngineCore_DP0 pid=572798)[0;0m 
[1;36m(EngineCore_DP0 pid=572798)[0;0m INFO 12-04 14:35:05 [default_loader.py:314] Loading weights took 1.75 seconds
[1;36m(EngineCore_DP0 pid=572793)[0;0m INFO 12-04 14:35:05 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.834023 seconds
[1;36m(EngineCore_DP0 pid=572798)[0;0m INFO 12-04 14:35:05 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.958106 seconds
[1;36m(EngineCore_DP0 pid=572793)[0;0m INFO 12-04 14:35:14 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=572793)[0;0m INFO 12-04 14:35:14 [backends.py:647] Dynamo bytecode transform time: 8.52 s
[1;36m(EngineCore_DP0 pid=572798)[0;0m INFO 12-04 14:35:14 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=572798)[0;0m INFO 12-04 14:35:14 [backends.py:647] Dynamo bytecode transform time: 8.43 s
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc815f6b7a0>' raised:
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=572793)[0;0m ERROR 12-04 14:35:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=572793)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=572793)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=572793)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=572793)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=572793)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=572793)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=572793)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=572793)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=572793)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=572793)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=572793)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=572793)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=572793)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=572793)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=572793)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=572793)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=572793)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=572793)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=572793)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=572793)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=572793)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=572793)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=572793)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=572793)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=572793)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=572793)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=572793)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=572793)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=572793)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=572793)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=572793)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=572793)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=572793)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=572793)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=572793)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=572793)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=572793)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=572793)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=572793)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=572793)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=572793)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=572793)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=572793)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=572793)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=572793)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572793)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=572793)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=572793)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc815f6b7a0>' raised:
[1;36m(EngineCore_DP0 pid=572793)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=572793)[0;0m 
[1;36m(EngineCore_DP0 pid=572793)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=572793)[0;0m 
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=572798)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7ff97cfaf770>' raised:
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=572798)[0;0m ERROR 12-04 14:35:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=572798)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=572798)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=572798)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=572798)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=572798)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=572798)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=572798)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=572798)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=572798)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=572798)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=572798)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=572798)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=572798)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=572798)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=572798)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=572798)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=572798)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=572798)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=572798)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=572798)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=572798)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=572798)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=572798)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=572798)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=572798)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=572798)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=572798)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=572798)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=572798)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=572798)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=572798)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=572798)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=572798)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=572798)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=572798)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=572798)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=572798)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=572798)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=572798)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=572798)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=572798)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=572798)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=572798)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=572798)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=572798)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=572798)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=572798)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=572798)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7ff97cfaf770>' raised:
[1;36m(EngineCore_DP0 pid=572798)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=572798)[0;0m 
[1;36m(EngineCore_DP0 pid=572798)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=572798)[0;0m 
[rank0]:[W1204 14:35:15.310620935 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:35:15.334681822 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:35:37 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:35:37 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:35:37 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:35:37 [model.py:1745] Using max model len 131072
INFO 12-04 14:35:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:35:37 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:35:37 [model.py:1745] Using max model len 131072
INFO 12-04 14:35:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=573311)[0;0m INFO 12-04 14:35:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=573308)[0;0m INFO 12-04 14:35:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=573311)[0;0m INFO 12-04 14:35:52 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:44025 backend=nccl
[1;36m(EngineCore_DP0 pid=573308)[0;0m INFO 12-04 14:35:52 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:58059 backend=nccl
[W1204 14:35:52.334146385 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:44025 (errno: 97 - Address family not supported by protocol).
[W1204 14:35:52.334570337 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:58059 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=573308)[0;0m INFO 12-04 14:35:52 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=573311)[0;0m INFO 12-04 14:35:52 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=573311)[0;0m INFO 12-04 14:35:53 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=573308)[0;0m INFO 12-04 14:35:53 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=573311)[0;0m INFO 12-04 14:35:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=573311)[0;0m INFO 12-04 14:35:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=573308)[0;0m INFO 12-04 14:35:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=573308)[0;0m INFO 12-04 14:35:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=573308)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=573311)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=573311)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.48s/it]
[1;36m(EngineCore_DP0 pid=573308)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.60s/it]
[1;36m(EngineCore_DP0 pid=573308)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.02it/s]
[1;36m(EngineCore_DP0 pid=573311)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.07it/s]
[1;36m(EngineCore_DP0 pid=573311)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.02s/it]
[1;36m(EngineCore_DP0 pid=573311)[0;0m 
[1;36m(EngineCore_DP0 pid=573308)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.07s/it]
[1;36m(EngineCore_DP0 pid=573308)[0;0m 
[1;36m(EngineCore_DP0 pid=573311)[0;0m INFO 12-04 14:35:57 [default_loader.py:314] Loading weights took 2.08 seconds
[1;36m(EngineCore_DP0 pid=573308)[0;0m INFO 12-04 14:35:57 [default_loader.py:314] Loading weights took 2.20 seconds
[1;36m(EngineCore_DP0 pid=573311)[0;0m INFO 12-04 14:35:57 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.289617 seconds
[1;36m(EngineCore_DP0 pid=573308)[0;0m INFO 12-04 14:35:57 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.289054 seconds
[1;36m(EngineCore_DP0 pid=573311)[0;0m INFO 12-04 14:36:06 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=573308)[0;0m INFO 12-04 14:36:06 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=573311)[0;0m INFO 12-04 14:36:06 [backends.py:647] Dynamo bytecode transform time: 8.55 s
[1;36m(EngineCore_DP0 pid=573308)[0;0m INFO 12-04 14:36:06 [backends.py:647] Dynamo bytecode transform time: 8.55 s
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f34c8232900>' raised:
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=573308)[0;0m ERROR 12-04 14:36:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f77e41d7e90>' raised:
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=573311)[0;0m ERROR 12-04 14:36:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=573308)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=573308)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=573308)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=573308)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=573308)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=573308)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=573308)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=573308)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=573308)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=573308)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=573308)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=573308)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=573308)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=573308)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=573308)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=573308)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=573308)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=573308)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=573308)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=573308)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=573308)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=573308)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=573308)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=573308)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=573308)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=573308)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=573308)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=573308)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=573308)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=573308)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=573308)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=573308)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=573308)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=573308)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=573308)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=573308)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=573308)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=573308)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=573308)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=573308)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=573308)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=573308)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=573308)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=573308)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=573308)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573308)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=573308)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=573308)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f34c8232900>' raised:
[1;36m(EngineCore_DP0 pid=573308)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=573308)[0;0m 
[1;36m(EngineCore_DP0 pid=573308)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=573308)[0;0m 
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=573311)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=573311)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=573311)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=573311)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=573311)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=573311)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=573311)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=573311)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=573311)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=573311)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=573311)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=573311)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=573311)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=573311)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=573311)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=573311)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=573311)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=573311)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=573311)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=573311)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=573311)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=573311)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=573311)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=573311)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=573311)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=573311)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=573311)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=573311)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=573311)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=573311)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=573311)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=573311)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=573311)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=573311)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=573311)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=573311)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=573311)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=573311)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=573311)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=573311)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=573311)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=573311)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=573311)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=573311)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=573311)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=573311)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=573311)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f77e41d7e90>' raised:
[1;36m(EngineCore_DP0 pid=573311)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=573311)[0;0m 
[1;36m(EngineCore_DP0 pid=573311)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=573311)[0;0m 
[rank0]:[W1204 14:36:07.239894928 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:36:07.240471917 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:36:29 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:36:29 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:36:29 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:36:29 [model.py:1745] Using max model len 131072
INFO 12-04 14:36:29 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:36:29 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:36:29 [model.py:1745] Using max model len 131072
INFO 12-04 14:36:29 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=574667)[0;0m INFO 12-04 14:36:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=574674)[0;0m INFO 12-04 14:36:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=574674)[0;0m INFO 12-04 14:36:44 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:51355 backend=nccl
[1;36m(EngineCore_DP0 pid=574667)[0;0m INFO 12-04 14:36:44 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:49007 backend=nccl
[W1204 14:36:44.993036527 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:51355 (errno: 97 - Address family not supported by protocol).
[W1204 14:36:44.996483974 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:49007 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=574667)[0;0m INFO 12-04 14:36:44 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=574674)[0;0m INFO 12-04 14:36:44 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=574667)[0;0m INFO 12-04 14:36:45 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=574674)[0;0m INFO 12-04 14:36:45 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=574667)[0;0m INFO 12-04 14:36:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=574667)[0;0m INFO 12-04 14:36:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=574674)[0;0m INFO 12-04 14:36:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=574674)[0;0m INFO 12-04 14:36:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=574667)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=574674)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=574667)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.19s/it]
[1;36m(EngineCore_DP0 pid=574674)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=574667)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.26it/s]
[1;36m(EngineCore_DP0 pid=574667)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.17it/s]
[1;36m(EngineCore_DP0 pid=574667)[0;0m 
[1;36m(EngineCore_DP0 pid=574667)[0;0m INFO 12-04 14:36:48 [default_loader.py:314] Loading weights took 1.77 seconds
[1;36m(EngineCore_DP0 pid=574674)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.26it/s]
[1;36m(EngineCore_DP0 pid=574674)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.18it/s]
[1;36m(EngineCore_DP0 pid=574674)[0;0m 
[1;36m(EngineCore_DP0 pid=574674)[0;0m INFO 12-04 14:36:48 [default_loader.py:314] Loading weights took 1.76 seconds
[1;36m(EngineCore_DP0 pid=574667)[0;0m INFO 12-04 14:36:48 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.872444 seconds
[1;36m(EngineCore_DP0 pid=574674)[0;0m INFO 12-04 14:36:48 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.943274 seconds
[1;36m(EngineCore_DP0 pid=574674)[0;0m INFO 12-04 14:36:57 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=574667)[0;0m INFO 12-04 14:36:57 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=574674)[0;0m INFO 12-04 14:36:57 [backends.py:647] Dynamo bytecode transform time: 8.17 s
[1;36m(EngineCore_DP0 pid=574667)[0;0m INFO 12-04 14:36:57 [backends.py:647] Dynamo bytecode transform time: 8.26 s
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f10581b0140>' raised:
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=574674)[0;0m ERROR 12-04 14:36:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=574674)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5ee0230ec0>' raised:
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=574667)[0;0m ERROR 12-04 14:36:58 [core.py:842] 
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=574674)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=574674)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=574674)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=574674)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=574674)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=574674)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=574674)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=574674)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=574674)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574674)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=574674)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=574674)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=574674)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574674)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574674)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=574674)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=574674)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574674)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=574674)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=574674)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=574674)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=574674)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=574674)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=574674)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=574674)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=574674)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574674)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574674)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=574674)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=574674)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=574674)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=574674)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=574674)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=574674)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=574674)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=574674)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=574674)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=574674)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=574674)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=574674)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=574674)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=574674)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=574674)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=574674)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574674)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=574674)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=574674)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f10581b0140>' raised:
[1;36m(EngineCore_DP0 pid=574674)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=574674)[0;0m 
[1;36m(EngineCore_DP0 pid=574674)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=574674)[0;0m 
[1;36m(EngineCore_DP0 pid=574667)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=574667)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=574667)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=574667)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=574667)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=574667)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=574667)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=574667)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=574667)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=574667)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574667)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=574667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=574667)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=574667)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574667)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574667)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=574667)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=574667)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574667)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=574667)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=574667)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=574667)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=574667)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=574667)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=574667)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=574667)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=574667)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574667)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574667)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=574667)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=574667)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=574667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=574667)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=574667)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=574667)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=574667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=574667)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=574667)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=574667)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=574667)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=574667)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=574667)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=574667)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=574667)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=574667)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=574667)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=574667)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5ee0230ec0>' raised:
[1;36m(EngineCore_DP0 pid=574667)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=574667)[0;0m 
[1;36m(EngineCore_DP0 pid=574667)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=574667)[0;0m 
[rank0]:[W1204 14:36:58.254199220 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:36:58.254199204 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:20 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:20 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:37:20 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:37:20 [model.py:1745] Using max model len 131072
INFO 12-04 14:37:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:37:20 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:37:20 [model.py:1745] Using max model len 131072
INFO 12-04 14:37:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=574994)[0;0m INFO 12-04 14:37:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=574997)[0;0m INFO 12-04 14:37:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=574994)[0;0m INFO 12-04 14:37:37 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:33287 backend=nccl
[1;36m(EngineCore_DP0 pid=574997)[0;0m INFO 12-04 14:37:37 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.9:36217 backend=nccl
[W1204 14:37:37.381222076 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:33287 (errno: 97 - Address family not supported by protocol).
[W1204 14:37:37.381222266 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-2.rc.tch.harvard.edu]:36217 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=574994)[0;0m INFO 12-04 14:37:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=574997)[0;0m INFO 12-04 14:37:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=574994)[0;0m INFO 12-04 14:37:38 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=574997)[0;0m INFO 12-04 14:37:38 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=574997)[0;0m INFO 12-04 14:37:39 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=574997)[0;0m INFO 12-04 14:37:39 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=574994)[0;0m INFO 12-04 14:37:39 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=574994)[0;0m INFO 12-04 14:37:39 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=574997)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=574994)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=574997)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=574994)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=574997)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.28it/s]
[1;36m(EngineCore_DP0 pid=574997)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.19it/s]
[1;36m(EngineCore_DP0 pid=574997)[0;0m 
[1;36m(EngineCore_DP0 pid=574997)[0;0m INFO 12-04 14:37:41 [default_loader.py:314] Loading weights took 1.73 seconds
[1;36m(EngineCore_DP0 pid=574994)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.28it/s]
[1;36m(EngineCore_DP0 pid=574994)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=574994)[0;0m 
[1;36m(EngineCore_DP0 pid=574994)[0;0m INFO 12-04 14:37:41 [default_loader.py:314] Loading weights took 1.73 seconds
[1;36m(EngineCore_DP0 pid=574997)[0;0m INFO 12-04 14:37:42 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.870811 seconds
[1;36m(EngineCore_DP0 pid=574994)[0;0m INFO 12-04 14:37:42 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.975896 seconds
[1;36m(EngineCore_DP0 pid=574997)[0;0m INFO 12-04 14:37:50 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=574997)[0;0m INFO 12-04 14:37:50 [backends.py:647] Dynamo bytecode transform time: 8.14 s
[1;36m(EngineCore_DP0 pid=574994)[0;0m INFO 12-04 14:37:50 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=574994)[0;0m INFO 12-04 14:37:50 [backends.py:647] Dynamo bytecode transform time: 8.16 s
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5abc5d3680>' raised:
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=574997)[0;0m ERROR 12-04 14:37:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=574997)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=574997)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=574997)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=574997)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=574997)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=574997)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=574997)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=574997)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=574997)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=574997)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574997)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=574997)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=574997)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=574997)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574997)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574997)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=574997)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=574997)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574997)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=574997)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=574997)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=574997)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=574997)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=574997)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=574997)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=574997)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=574997)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574997)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574997)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=574997)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=574997)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=574997)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=574997)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=574997)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=574997)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=574997)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=574997)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=574997)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=574997)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=574997)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=574997)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=574997)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=574997)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=574997)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=574997)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574997)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=574997)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=574997)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5abc5d3680>' raised:
[1;36m(EngineCore_DP0 pid=574997)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=574997)[0;0m 
[1;36m(EngineCore_DP0 pid=574997)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=574997)[0;0m 
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd63c2cec60>' raised:
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=574994)[0;0m ERROR 12-04 14:37:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=574994)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=574994)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=574994)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=574994)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=574994)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=574994)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=574994)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=574994)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=574994)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=574994)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574994)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=574994)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=574994)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=574994)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574994)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=574994)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=574994)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=574994)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=574994)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=574994)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=574994)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=574994)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=574994)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=574994)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=574994)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=574994)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=574994)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574994)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=574994)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=574994)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=574994)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=574994)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=574994)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=574994)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=574994)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=574994)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=574994)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=574994)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=574994)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=574994)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=574994)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=574994)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=574994)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=574994)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=574994)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=574994)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=574994)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=574994)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd63c2cec60>' raised:
[1;36m(EngineCore_DP0 pid=574994)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=574994)[0;0m 
[1;36m(EngineCore_DP0 pid=574994)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=574994)[0;0m 
[rank0]:[W1204 14:37:52.457901100 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:37:52.647731801 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:38:13 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:38:13 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:38:13 [model.py:1745] Using max model len 131072
INFO 12-04 14:38:13 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:38:13 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:38:13 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:38:13 [model.py:1745] Using max model len 131072
INFO 12-04 14:38:13 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
