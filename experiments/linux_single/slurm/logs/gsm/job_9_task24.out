Using persona diversity with 7 different personas
============================================================
GSM Task - Multiagent Debate
============================================================
Model: meta-llama/Llama-3.2-3B-Instruct
Persona diversity mode:
  Agent 1: a radical anarchist who views all imposed structures and hie...
  Agent 2: a Kantian deontologist who judges all actions strictly by th...
  Agent 3: a Soviet-era bureaucrat who prioritizes documentation, adher...
  Agent 4: a Zen master who communicates only through non-sequiturs, ko...
  Agent 5: a deep-sea volcanologist focused on extremes of pressure, he...
  Agent 6: a cosmic horror narrator who frames the problem as an ancien...
  Agent 7: a Renaissance painter who values perspective, light, shadow,...
Agents: 7
Rounds: 3
Problems: 20
Dataset: /home/ch269957/projects/slm_multiagent_debate/data/gsm8k/test.jsonl
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================

--- Problem 1/20, Round 1, Agent 1/7 ---
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:03:11 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Using persona diversity with 7 different personas
============================================================
GSM Task - Multiagent Debate
============================================================
Model: meta-llama/Llama-3.2-3B-Instruct
Persona diversity mode:
  Agent 1: a radical anarchist who views all imposed structures and hie...
  Agent 2: a Kantian deontologist who judges all actions strictly by th...
  Agent 3: a Soviet-era bureaucrat who prioritizes documentation, adher...
  Agent 4: a Zen master who communicates only through non-sequiturs, ko...
  Agent 5: a deep-sea volcanologist focused on extremes of pressure, he...
  Agent 6: a cosmic horror narrator who frames the problem as an ancien...
  Agent 7: a Renaissance painter who values perspective, light, shadow,...
Agents: 7
Rounds: 3
Problems: 20
Dataset: /home/ch269957/projects/slm_multiagent_debate/data/gsm8k/test.jsonl
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================

--- Problem 1/20, Round 1, Agent 1/7 ---
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:03:11 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:03:12 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:03:12 [model.py:1745] Using max model len 131072
INFO 12-04 14:03:12 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:03:12 [model.py:1745] Using max model len 131072
INFO 12-04 14:03:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:03:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1564691)[0;0m INFO 12-04 14:03:45 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1564692)[0;0m INFO 12-04 14:03:45 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1564691)[0;0m INFO 12-04 14:03:50 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:54223 backend=nccl
[1;36m(EngineCore_DP0 pid=1564692)[0;0m INFO 12-04 14:03:50 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:47137 backend=nccl
[W1204 14:03:50.496198586 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:54223 (errno: 97 - Address family not supported by protocol).
[W1204 14:03:50.497169503 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:47137 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1564692)[0;0m INFO 12-04 14:03:50 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1564691)[0;0m INFO 12-04 14:03:50 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1564692)[0;0m INFO 12-04 14:03:50 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1564691)[0;0m INFO 12-04 14:03:50 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1564692)[0;0m INFO 12-04 14:03:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1564692)[0;0m INFO 12-04 14:03:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1564691)[0;0m INFO 12-04 14:03:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1564691)[0;0m INFO 12-04 14:03:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1564692)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1564691)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1564692)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:38<00:38, 38.92s/it]
[1;36m(EngineCore_DP0 pid=1564691)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:38<00:38, 38.79s/it]
[1;36m(EngineCore_DP0 pid=1564692)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:50<00:00, 23.05s/it]
[1;36m(EngineCore_DP0 pid=1564691)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:50<00:00, 23.00s/it]
[1;36m(EngineCore_DP0 pid=1564692)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:50<00:00, 25.43s/it]
[1;36m(EngineCore_DP0 pid=1564692)[0;0m 
[1;36m(EngineCore_DP0 pid=1564691)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:50<00:00, 25.36s/it]
[1;36m(EngineCore_DP0 pid=1564691)[0;0m 
[1;36m(EngineCore_DP0 pid=1564691)[0;0m INFO 12-04 14:04:43 [default_loader.py:314] Loading weights took 50.79 seconds
[1;36m(EngineCore_DP0 pid=1564692)[0;0m INFO 12-04 14:04:44 [default_loader.py:314] Loading weights took 51.01 seconds
[1;36m(EngineCore_DP0 pid=1564691)[0;0m INFO 12-04 14:04:44 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 52.935448 seconds
[1;36m(EngineCore_DP0 pid=1564692)[0;0m INFO 12-04 14:04:44 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 53.009493 seconds
[1;36m(EngineCore_DP0 pid=1564692)[0;0m INFO 12-04 14:05:00 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1564691)[0;0m INFO 12-04 14:05:00 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1564692)[0;0m INFO 12-04 14:05:00 [backends.py:647] Dynamo bytecode transform time: 15.40 s
[1;36m(EngineCore_DP0 pid=1564691)[0;0m INFO 12-04 14:05:00 [backends.py:647] Dynamo bytecode transform time: 15.46 s
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f891cc4b680>' raised:
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1564692)[0;0m ERROR 12-04 14:05:01 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fe48825f8f0>' raised:
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1564691)[0;0m ERROR 12-04 14:05:01 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1564692)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1564691)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1564691)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1564691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1564692)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1564692)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1564692)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1564692)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1564692)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f891cc4b680>' raised:
[1;36m(EngineCore_DP0 pid=1564692)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1564692)[0;0m 
[1;36m(EngineCore_DP0 pid=1564692)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1564692)[0;0m 
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1564691)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1564691)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1564691)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1564691)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fe48825f8f0>' raised:
[1;36m(EngineCore_DP0 pid=1564691)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1564691)[0;0m 
[1;36m(EngineCore_DP0 pid=1564691)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1564691)[0;0m 
[rank0]:[W1204 14:05:01.239638716 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:05:01.239985477 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:05:23 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:05:23 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:05:23 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:05:23 [model.py:1745] Using max model len 131072
INFO 12-04 14:05:23 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:05:23 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:05:23 [model.py:1745] Using max model len 131072
INFO 12-04 14:05:23 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1570002)[0;0m INFO 12-04 14:05:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1570052)[0;0m INFO 12-04 14:05:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1570002)[0;0m INFO 12-04 14:05:58 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:54873 backend=nccl
[1;36m(EngineCore_DP0 pid=1570052)[0;0m INFO 12-04 14:05:58 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:38687 backend=nccl
[W1204 14:05:58.465308931 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:38687 (errno: 97 - Address family not supported by protocol).
[W1204 14:05:58.465403302 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:54873 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1570002)[0;0m INFO 12-04 14:05:58 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1570052)[0;0m INFO 12-04 14:05:58 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1570052)[0;0m INFO 12-04 14:05:58 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1570002)[0;0m INFO 12-04 14:05:58 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1570052)[0;0m INFO 12-04 14:06:00 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1570052)[0;0m INFO 12-04 14:06:00 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1570002)[0;0m INFO 12-04 14:06:00 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1570002)[0;0m INFO 12-04 14:06:00 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1570002)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1570052)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1570002)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=1570052)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1570002)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=1570002)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1570002)[0;0m 
[1;36m(EngineCore_DP0 pid=1570002)[0;0m INFO 12-04 14:06:02 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=1570052)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=1570052)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1570052)[0;0m 
[1;36m(EngineCore_DP0 pid=1570052)[0;0m INFO 12-04 14:06:02 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=1570002)[0;0m INFO 12-04 14:06:03 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.593273 seconds
[1;36m(EngineCore_DP0 pid=1570052)[0;0m INFO 12-04 14:06:03 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.789717 seconds
[1;36m(EngineCore_DP0 pid=1570002)[0;0m INFO 12-04 14:06:20 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1570052)[0;0m INFO 12-04 14:06:20 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1570002)[0;0m INFO 12-04 14:06:20 [backends.py:647] Dynamo bytecode transform time: 16.96 s
[1;36m(EngineCore_DP0 pid=1570052)[0;0m INFO 12-04 14:06:20 [backends.py:647] Dynamo bytecode transform time: 16.78 s
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8820e1bbf0>' raised:
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1570002)[0;0m ERROR 12-04 14:06:21 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fdbfe08f8c0>' raised:
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1570052)[0;0m ERROR 12-04 14:06:21 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1570002)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1570052)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1570052)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1570052)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1570002)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1570002)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1570002)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1570002)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570002)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1570002)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1570002)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8820e1bbf0>' raised:
[1;36m(EngineCore_DP0 pid=1570002)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1570002)[0;0m 
[1;36m(EngineCore_DP0 pid=1570002)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1570002)[0;0m 
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1570052)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1570052)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1570052)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1570052)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fdbfe08f8c0>' raised:
[1;36m(EngineCore_DP0 pid=1570052)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1570052)[0;0m 
[1;36m(EngineCore_DP0 pid=1570052)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1570052)[0;0m 
[rank0]:[W1204 14:06:21.342392758 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:06:21.342373288 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:06:43 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:06:43 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:06:43 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:06:43 [model.py:1745] Using max model len 131072
INFO 12-04 14:06:43 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:06:43 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:06:43 [model.py:1745] Using max model len 131072
INFO 12-04 14:06:43 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1573467)[0;0m INFO 12-04 14:07:23 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1573470)[0;0m INFO 12-04 14:07:23 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1573467)[0;0m INFO 12-04 14:07:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:40215 backend=nccl
[1;36m(EngineCore_DP0 pid=1573470)[0;0m INFO 12-04 14:07:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:57543 backend=nccl
[W1204 14:07:27.180952092 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:40215 (errno: 97 - Address family not supported by protocol).
[W1204 14:07:27.182570885 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:57543 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1573467)[0;0m INFO 12-04 14:07:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1573470)[0;0m INFO 12-04 14:07:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1573467)[0;0m INFO 12-04 14:07:28 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1573470)[0;0m INFO 12-04 14:07:28 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1573467)[0;0m INFO 12-04 14:07:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1573467)[0;0m INFO 12-04 14:07:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1573470)[0;0m INFO 12-04 14:07:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1573470)[0;0m INFO 12-04 14:07:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1573470)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1573467)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1573470)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.18s/it]
[1;36m(EngineCore_DP0 pid=1573467)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1573470)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=1573470)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=1573470)[0;0m 
[1;36m(EngineCore_DP0 pid=1573470)[0;0m INFO 12-04 14:07:31 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=1573467)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=1573467)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=1573467)[0;0m 
[1;36m(EngineCore_DP0 pid=1573467)[0;0m INFO 12-04 14:07:31 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=1573470)[0;0m INFO 12-04 14:07:32 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.145061 seconds
[1;36m(EngineCore_DP0 pid=1573467)[0;0m INFO 12-04 14:07:32 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.228842 seconds
[1;36m(EngineCore_DP0 pid=1573467)[0;0m INFO 12-04 14:07:47 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1573470)[0;0m INFO 12-04 14:07:47 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1573467)[0;0m INFO 12-04 14:07:47 [backends.py:647] Dynamo bytecode transform time: 14.44 s
[1;36m(EngineCore_DP0 pid=1573470)[0;0m INFO 12-04 14:07:47 [backends.py:647] Dynamo bytecode transform time: 14.51 s
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8d14243380>' raised:
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1573467)[0;0m ERROR 12-04 14:07:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fbd84108d70>' raised:
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1573470)[0;0m ERROR 12-04 14:07:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1573467)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1573470)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1573467)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1573467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1573467)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573467)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1573467)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1573467)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8d14243380>' raised:
[1;36m(EngineCore_DP0 pid=1573467)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1573467)[0;0m 
[1;36m(EngineCore_DP0 pid=1573467)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1573467)[0;0m 
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1573470)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1573470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1573470)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1573470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1573470)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1573470)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fbd84108d70>' raised:
[1;36m(EngineCore_DP0 pid=1573470)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1573470)[0;0m 
[1;36m(EngineCore_DP0 pid=1573470)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1573470)[0;0m 
[rank0]:[W1204 14:07:48.143049918 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:07:48.144471409 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:08:10 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:08:10 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:08:10 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:08:10 [model.py:1745] Using max model len 131072
INFO 12-04 14:08:10 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:08:10 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:08:10 [model.py:1745] Using max model len 131072
INFO 12-04 14:08:10 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1577550)[0;0m INFO 12-04 14:08:47 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1577547)[0;0m INFO 12-04 14:08:47 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1577550)[0;0m INFO 12-04 14:08:50 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:42465 backend=nccl
[1;36m(EngineCore_DP0 pid=1577547)[0;0m INFO 12-04 14:08:50 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:46353 backend=nccl
[W1204 14:08:50.840437344 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:42465 (errno: 97 - Address family not supported by protocol).
[W1204 14:08:50.841549305 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:46353 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1577547)[0;0m INFO 12-04 14:08:50 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1577550)[0;0m INFO 12-04 14:08:50 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1577547)[0;0m INFO 12-04 14:08:50 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1577550)[0;0m INFO 12-04 14:08:50 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1577550)[0;0m INFO 12-04 14:08:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1577550)[0;0m INFO 12-04 14:08:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1577547)[0;0m INFO 12-04 14:08:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1577547)[0;0m INFO 12-04 14:08:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1577547)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1577550)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1577547)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1577550)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1577547)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.36it/s]
[1;36m(EngineCore_DP0 pid=1577547)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.26it/s]
[1;36m(EngineCore_DP0 pid=1577547)[0;0m 
[1;36m(EngineCore_DP0 pid=1577547)[0;0m INFO 12-04 14:08:54 [default_loader.py:314] Loading weights took 1.63 seconds
[1;36m(EngineCore_DP0 pid=1577550)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1577550)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1577550)[0;0m 
[1;36m(EngineCore_DP0 pid=1577550)[0;0m INFO 12-04 14:08:54 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1577547)[0;0m INFO 12-04 14:08:55 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.265840 seconds
[1;36m(EngineCore_DP0 pid=1577550)[0;0m INFO 12-04 14:08:55 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.434482 seconds
[1;36m(EngineCore_DP0 pid=1577550)[0;0m INFO 12-04 14:09:07 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1577547)[0;0m INFO 12-04 14:09:07 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1577550)[0;0m INFO 12-04 14:09:07 [backends.py:647] Dynamo bytecode transform time: 11.48 s
[1;36m(EngineCore_DP0 pid=1577547)[0;0m INFO 12-04 14:09:07 [backends.py:647] Dynamo bytecode transform time: 11.64 s
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7efae82866f0>' raised:
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1577550)[0;0m ERROR 12-04 14:09:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fcae0192c90>' raised:
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1577547)[0;0m ERROR 12-04 14:09:07 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1577550)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1577547)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1577547)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1577547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1577550)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1577550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1577550)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1577550)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1577550)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7efae82866f0>' raised:
[1;36m(EngineCore_DP0 pid=1577550)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1577550)[0;0m 
[1;36m(EngineCore_DP0 pid=1577550)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1577550)[0;0m 
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1577547)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1577547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1577547)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1577547)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fcae0192c90>' raised:
[1;36m(EngineCore_DP0 pid=1577547)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1577547)[0;0m 
[1;36m(EngineCore_DP0 pid=1577547)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1577547)[0;0m 
[rank0]:[W1204 14:09:08.969098740 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:09:08.969035992 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:09:29 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:09:30 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:09:30 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:09:30 [model.py:1745] Using max model len 131072
INFO 12-04 14:09:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:09:30 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:09:30 [model.py:1745] Using max model len 131072
INFO 12-04 14:09:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1580828)[0;0m INFO 12-04 14:10:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1580835)[0;0m INFO 12-04 14:10:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1580835)[0;0m INFO 12-04 14:10:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:39825 backend=nccl
[1;36m(EngineCore_DP0 pid=1580828)[0;0m INFO 12-04 14:10:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:60301 backend=nccl
[W1204 14:10:04.951611983 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:60301 (errno: 97 - Address family not supported by protocol).
[W1204 14:10:04.951612012 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:39825 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1580828)[0;0m INFO 12-04 14:10:04 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1580835)[0;0m INFO 12-04 14:10:04 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1580828)[0;0m INFO 12-04 14:10:05 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1580835)[0;0m INFO 12-04 14:10:05 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1580835)[0;0m INFO 12-04 14:10:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1580835)[0;0m INFO 12-04 14:10:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1580828)[0;0m INFO 12-04 14:10:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1580828)[0;0m INFO 12-04 14:10:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1580835)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1580828)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1580835)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=1580828)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1580835)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1580835)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1580835)[0;0m 
[1;36m(EngineCore_DP0 pid=1580835)[0;0m INFO 12-04 14:10:08 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1580828)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=1580828)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1580828)[0;0m 
[1;36m(EngineCore_DP0 pid=1580828)[0;0m INFO 12-04 14:10:09 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=1580835)[0;0m INFO 12-04 14:10:09 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.518690 seconds
[1;36m(EngineCore_DP0 pid=1580828)[0;0m INFO 12-04 14:10:09 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.647566 seconds
[1;36m(EngineCore_DP0 pid=1580828)[0;0m INFO 12-04 14:10:22 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1580835)[0;0m INFO 12-04 14:10:22 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1580828)[0;0m INFO 12-04 14:10:22 [backends.py:647] Dynamo bytecode transform time: 12.36 s
[1;36m(EngineCore_DP0 pid=1580835)[0;0m INFO 12-04 14:10:22 [backends.py:647] Dynamo bytecode transform time: 12.48 s
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fdea00a3410>' raised:
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1580835)[0;0m ERROR 12-04 14:10:23 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fe874346300>' raised:
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1580828)[0;0m ERROR 12-04 14:10:23 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1580835)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1580828)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1580835)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1580835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1580835)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1580835)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1580835)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fdea00a3410>' raised:
[1;36m(EngineCore_DP0 pid=1580835)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1580835)[0;0m 
[1;36m(EngineCore_DP0 pid=1580835)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1580835)[0;0m 
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1580828)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1580828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1580828)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1580828)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1580828)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1580828)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fe874346300>' raised:
[1;36m(EngineCore_DP0 pid=1580828)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1580828)[0;0m 
[1;36m(EngineCore_DP0 pid=1580828)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1580828)[0;0m 
[rank0]:[W1204 14:10:23.268346535 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:10:23.293348334 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:10:45 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:10:45 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:10:45 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:10:45 [model.py:1745] Using max model len 131072
INFO 12-04 14:10:45 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:10:45 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:10:45 [model.py:1745] Using max model len 131072
INFO 12-04 14:10:45 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1583760)[0;0m INFO 12-04 14:11:19 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1583763)[0;0m INFO 12-04 14:11:19 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1583760)[0;0m INFO 12-04 14:11:22 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:54909 backend=nccl
[1;36m(EngineCore_DP0 pid=1583763)[0;0m INFO 12-04 14:11:22 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:42001 backend=nccl
[W1204 14:11:22.496434224 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:42001 (errno: 97 - Address family not supported by protocol).
[W1204 14:11:22.496537692 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:54909 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1583760)[0;0m INFO 12-04 14:11:22 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1583763)[0;0m INFO 12-04 14:11:22 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1583760)[0;0m INFO 12-04 14:11:22 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1583763)[0;0m INFO 12-04 14:11:22 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1583760)[0;0m INFO 12-04 14:11:23 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1583760)[0;0m INFO 12-04 14:11:23 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1583763)[0;0m INFO 12-04 14:11:23 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1583763)[0;0m INFO 12-04 14:11:23 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1583760)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1583763)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1583760)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1583763)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1583760)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.36it/s]
[1;36m(EngineCore_DP0 pid=1583760)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.26it/s]
[1;36m(EngineCore_DP0 pid=1583760)[0;0m 
[1;36m(EngineCore_DP0 pid=1583760)[0;0m INFO 12-04 14:11:25 [default_loader.py:314] Loading weights took 1.63 seconds
[1;36m(EngineCore_DP0 pid=1583763)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1583763)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1583763)[0;0m 
[1;36m(EngineCore_DP0 pid=1583763)[0;0m INFO 12-04 14:11:26 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1583760)[0;0m INFO 12-04 14:11:26 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.925072 seconds
[1;36m(EngineCore_DP0 pid=1583763)[0;0m INFO 12-04 14:11:26 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.086991 seconds
[1;36m(EngineCore_DP0 pid=1583763)[0;0m INFO 12-04 14:11:43 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1583760)[0;0m INFO 12-04 14:11:43 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1583760)[0;0m INFO 12-04 14:11:43 [backends.py:647] Dynamo bytecode transform time: 16.79 s
[1;36m(EngineCore_DP0 pid=1583763)[0;0m INFO 12-04 14:11:43 [backends.py:647] Dynamo bytecode transform time: 16.64 s
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7effe417b860>' raised:
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1583760)[0;0m ERROR 12-04 14:11:44 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8f601578c0>' raised:
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1583763)[0;0m ERROR 12-04 14:11:44 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1583760)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1583763)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1583763)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1583763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1583760)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1583760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1583760)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1583760)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1583760)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7effe417b860>' raised:
[1;36m(EngineCore_DP0 pid=1583760)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1583760)[0;0m 
[1;36m(EngineCore_DP0 pid=1583760)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1583760)[0;0m 
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1583763)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1583763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1583763)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1583763)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8f601578c0>' raised:
[1;36m(EngineCore_DP0 pid=1583763)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1583763)[0;0m 
[1;36m(EngineCore_DP0 pid=1583763)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1583763)[0;0m 
[rank0]:[W1204 14:11:45.453401177 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:11:45.453401282 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:12:06 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:12:06 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:12:06 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:12:06 [model.py:1745] Using max model len 131072
INFO 12-04 14:12:06 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:12:06 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:12:06 [model.py:1745] Using max model len 131072
INFO 12-04 14:12:06 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1586990)[0;0m INFO 12-04 14:12:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1586993)[0;0m INFO 12-04 14:12:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1586993)[0;0m INFO 12-04 14:12:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:47899 backend=nccl
[1;36m(EngineCore_DP0 pid=1586990)[0;0m INFO 12-04 14:12:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:39831 backend=nccl
[W1204 14:12:53.257901996 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:47899 (errno: 97 - Address family not supported by protocol).
[W1204 14:12:53.257965455 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:39831 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1586990)[0;0m INFO 12-04 14:12:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1586993)[0;0m INFO 12-04 14:12:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1586990)[0;0m INFO 12-04 14:12:54 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1586993)[0;0m INFO 12-04 14:12:54 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1586990)[0;0m INFO 12-04 14:12:55 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1586990)[0;0m INFO 12-04 14:12:55 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1586993)[0;0m INFO 12-04 14:12:55 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1586993)[0;0m INFO 12-04 14:12:55 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1586990)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1586993)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1586990)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1586993)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1586990)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.36it/s]
[1;36m(EngineCore_DP0 pid=1586990)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
[1;36m(EngineCore_DP0 pid=1586990)[0;0m 
[1;36m(EngineCore_DP0 pid=1586990)[0;0m INFO 12-04 14:12:58 [default_loader.py:314] Loading weights took 1.63 seconds
[1;36m(EngineCore_DP0 pid=1586993)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1586993)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1586993)[0;0m 
[1;36m(EngineCore_DP0 pid=1586993)[0;0m INFO 12-04 14:12:58 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1586990)[0;0m INFO 12-04 14:12:58 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.447406 seconds
[1;36m(EngineCore_DP0 pid=1586993)[0;0m INFO 12-04 14:12:59 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.604829 seconds
[1;36m(EngineCore_DP0 pid=1586990)[0;0m INFO 12-04 14:13:14 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1586993)[0;0m INFO 12-04 14:13:14 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1586990)[0;0m INFO 12-04 14:13:14 [backends.py:647] Dynamo bytecode transform time: 15.60 s
[1;36m(EngineCore_DP0 pid=1586993)[0;0m INFO 12-04 14:13:14 [backends.py:647] Dynamo bytecode transform time: 15.45 s
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8ac82d85f0>' raised:
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1586990)[0;0m ERROR 12-04 14:13:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f45882f7680>' raised:
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1586993)[0;0m ERROR 12-04 14:13:15 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1586990)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1586993)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1586993)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1586993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1586990)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1586990)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1586990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1586990)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1586990)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1586990)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8ac82d85f0>' raised:
[1;36m(EngineCore_DP0 pid=1586990)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1586990)[0;0m 
[1;36m(EngineCore_DP0 pid=1586990)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1586990)[0;0m 
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1586993)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1586993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1586993)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1586993)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f45882f7680>' raised:
[1;36m(EngineCore_DP0 pid=1586993)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1586993)[0;0m 
[1;36m(EngineCore_DP0 pid=1586993)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1586993)[0;0m 
[rank0]:[W1204 14:13:16.725145178 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:13:16.727388933 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:13:37 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:13:37 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:13:37 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:13:37 [model.py:1745] Using max model len 131072
INFO 12-04 14:13:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:13:37 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:13:37 [model.py:1745] Using max model len 131072
INFO 12-04 14:13:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1590598)[0;0m INFO 12-04 14:14:11 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1590595)[0;0m INFO 12-04 14:14:11 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1590598)[0;0m INFO 12-04 14:14:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:43815 backend=nccl
[1;36m(EngineCore_DP0 pid=1590595)[0;0m INFO 12-04 14:14:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:45469 backend=nccl
[W1204 14:14:16.449544758 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:43815 (errno: 97 - Address family not supported by protocol).
[W1204 14:14:16.449544719 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:45469 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1590595)[0;0m INFO 12-04 14:14:16 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1590598)[0;0m INFO 12-04 14:14:16 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1590595)[0;0m INFO 12-04 14:14:16 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1590598)[0;0m INFO 12-04 14:14:16 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1590598)[0;0m INFO 12-04 14:14:18 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1590598)[0;0m INFO 12-04 14:14:18 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1590595)[0;0m INFO 12-04 14:14:18 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1590595)[0;0m INFO 12-04 14:14:18 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1590595)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1590598)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1590595)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=1590598)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1590595)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1590595)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1590595)[0;0m 
[1;36m(EngineCore_DP0 pid=1590595)[0;0m INFO 12-04 14:14:20 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1590598)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1590598)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1590598)[0;0m 
[1;36m(EngineCore_DP0 pid=1590598)[0;0m INFO 12-04 14:14:20 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1590595)[0;0m INFO 12-04 14:14:21 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.530925 seconds
[1;36m(EngineCore_DP0 pid=1590598)[0;0m INFO 12-04 14:14:21 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.615621 seconds
[1;36m(EngineCore_DP0 pid=1590598)[0;0m INFO 12-04 14:14:36 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1590595)[0;0m INFO 12-04 14:14:36 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1590598)[0;0m INFO 12-04 14:14:36 [backends.py:647] Dynamo bytecode transform time: 14.75 s
[1;36m(EngineCore_DP0 pid=1590595)[0;0m INFO 12-04 14:14:36 [backends.py:647] Dynamo bytecode transform time: 14.82 s
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f42ec12d6a0>' raised:
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1590598)[0;0m ERROR 12-04 14:14:36 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8a942e04a0>' raised:
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1590595)[0;0m ERROR 12-04 14:14:36 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1590598)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1590595)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1590595)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1590595)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1590598)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1590598)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1590598)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1590598)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590598)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1590598)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1590598)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f42ec12d6a0>' raised:
[1;36m(EngineCore_DP0 pid=1590598)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1590598)[0;0m 
[1;36m(EngineCore_DP0 pid=1590598)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1590598)[0;0m 
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1590595)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1590595)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1590595)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1590595)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8a942e04a0>' raised:
[1;36m(EngineCore_DP0 pid=1590595)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1590595)[0;0m 
[1;36m(EngineCore_DP0 pid=1590595)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1590595)[0;0m 
[rank0]:[W1204 14:14:37.174716958 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:14:37.175563055 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:14:59 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:14:59 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:14:59 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:14:59 [model.py:1745] Using max model len 131072
INFO 12-04 14:14:59 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:14:59 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:14:59 [model.py:1745] Using max model len 131072
INFO 12-04 14:14:59 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1593749)[0;0m INFO 12-04 14:15:31 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1593752)[0;0m INFO 12-04 14:15:31 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1593752)[0;0m INFO 12-04 14:15:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:53473 backend=nccl
[1;36m(EngineCore_DP0 pid=1593749)[0;0m INFO 12-04 14:15:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:59989 backend=nccl
[W1204 14:15:34.788567455 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:53473 (errno: 97 - Address family not supported by protocol).
[W1204 14:15:34.790525877 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:59989 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1593752)[0;0m INFO 12-04 14:15:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1593749)[0;0m INFO 12-04 14:15:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1593752)[0;0m INFO 12-04 14:15:35 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1593749)[0;0m INFO 12-04 14:15:35 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1593749)[0;0m INFO 12-04 14:15:36 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1593752)[0;0m INFO 12-04 14:15:36 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1593749)[0;0m INFO 12-04 14:15:36 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1593752)[0;0m INFO 12-04 14:15:36 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1593752)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1593749)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1593752)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=1593749)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=1593752)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1593752)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1593752)[0;0m 
[1;36m(EngineCore_DP0 pid=1593752)[0;0m INFO 12-04 14:15:38 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1593749)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=1593749)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=1593749)[0;0m 
[1;36m(EngineCore_DP0 pid=1593749)[0;0m INFO 12-04 14:15:38 [default_loader.py:314] Loading weights took 1.68 seconds
[1;36m(EngineCore_DP0 pid=1593752)[0;0m INFO 12-04 14:15:39 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.066560 seconds
[1;36m(EngineCore_DP0 pid=1593749)[0;0m INFO 12-04 14:15:39 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.225520 seconds
[1;36m(EngineCore_DP0 pid=1593752)[0;0m INFO 12-04 14:15:51 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1593749)[0;0m INFO 12-04 14:15:51 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1593752)[0;0m INFO 12-04 14:15:51 [backends.py:647] Dynamo bytecode transform time: 11.71 s
[1;36m(EngineCore_DP0 pid=1593749)[0;0m INFO 12-04 14:15:51 [backends.py:647] Dynamo bytecode transform time: 11.56 s
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fac6b3bba70>' raised:
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1593752)[0;0m ERROR 12-04 14:15:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7ff7cc1c65a0>' raised:
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1593749)[0;0m ERROR 12-04 14:15:51 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1593752)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1593749)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1593752)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1593752)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1593749)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1593749)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1593749)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593749)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1593749)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1593749)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7ff7cc1c65a0>' raised:
[1;36m(EngineCore_DP0 pid=1593749)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1593749)[0;0m 
[1;36m(EngineCore_DP0 pid=1593749)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1593749)[0;0m 
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1593752)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1593752)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1593752)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1593752)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fac6b3bba70>' raised:
[1;36m(EngineCore_DP0 pid=1593752)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1593752)[0;0m 
[1;36m(EngineCore_DP0 pid=1593752)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1593752)[0;0m 
[rank0]:[W1204 14:15:52.027420111 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:15:52.031279313 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:16:13 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:16:14 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:16:14 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:16:14 [model.py:1745] Using max model len 131072
INFO 12-04 14:16:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:16:14 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:16:14 [model.py:1745] Using max model len 131072
INFO 12-04 14:16:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1597684)[0;0m INFO 12-04 14:16:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1597683)[0;0m INFO 12-04 14:16:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1597684)[0;0m INFO 12-04 14:17:03 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:34877 backend=nccl
[1;36m(EngineCore_DP0 pid=1597683)[0;0m INFO 12-04 14:17:03 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:40101 backend=nccl
[W1204 14:17:03.576115456 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:34877 (errno: 97 - Address family not supported by protocol).
[W1204 14:17:03.577627443 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:40101 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1597684)[0;0m INFO 12-04 14:17:03 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1597683)[0;0m INFO 12-04 14:17:03 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1597683)[0;0m INFO 12-04 14:17:03 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1597684)[0;0m INFO 12-04 14:17:03 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1597683)[0;0m INFO 12-04 14:17:05 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1597683)[0;0m INFO 12-04 14:17:05 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1597684)[0;0m INFO 12-04 14:17:05 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1597684)[0;0m INFO 12-04 14:17:05 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1597683)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1597684)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1597683)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1597684)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1597683)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.36it/s]
[1;36m(EngineCore_DP0 pid=1597683)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
[1;36m(EngineCore_DP0 pid=1597683)[0;0m 
[1;36m(EngineCore_DP0 pid=1597683)[0;0m INFO 12-04 14:17:07 [default_loader.py:314] Loading weights took 1.63 seconds
[1;36m(EngineCore_DP0 pid=1597684)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1597684)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1597684)[0;0m 
[1;36m(EngineCore_DP0 pid=1597684)[0;0m INFO 12-04 14:17:07 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1597683)[0;0m INFO 12-04 14:17:08 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.441313 seconds
[1;36m(EngineCore_DP0 pid=1597684)[0;0m INFO 12-04 14:17:08 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.583688 seconds
[1;36m(EngineCore_DP0 pid=1597684)[0;0m INFO 12-04 14:17:20 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1597683)[0;0m INFO 12-04 14:17:20 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1597684)[0;0m INFO 12-04 14:17:20 [backends.py:647] Dynamo bytecode transform time: 11.65 s
[1;36m(EngineCore_DP0 pid=1597683)[0;0m INFO 12-04 14:17:20 [backends.py:647] Dynamo bytecode transform time: 11.80 s
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f44fdcb3620>' raised:
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1597683)[0;0m ERROR 12-04 14:17:20 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f77001792e0>' raised:
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1597684)[0;0m ERROR 12-04 14:17:20 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1597684)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1597683)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1597683)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1597684)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1597684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1597683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1597684)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1597684)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1597684)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f77001792e0>' raised:
[1;36m(EngineCore_DP0 pid=1597684)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1597684)[0;0m 
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1597683)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1597683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1597683)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1597683)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f44fdcb3620>' raised:
[1;36m(EngineCore_DP0 pid=1597683)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1597683)[0;0m 
[1;36m(EngineCore_DP0 pid=1597683)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1597683)[0;0m 
[1;36m(EngineCore_DP0 pid=1597684)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1597684)[0;0m 
[rank0]:[W1204 14:17:21.129579444 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:17:21.130338672 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:17:43 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:17:43 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:17:43 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:17:43 [model.py:1745] Using max model len 131072
INFO 12-04 14:17:43 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:17:43 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:17:43 [model.py:1745] Using max model len 131072
INFO 12-04 14:17:43 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1601298)[0;0m INFO 12-04 14:18:08 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1601301)[0;0m INFO 12-04 14:18:08 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1601301)[0;0m INFO 12-04 14:18:10 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:32875 backend=nccl
[1;36m(EngineCore_DP0 pid=1601298)[0;0m INFO 12-04 14:18:10 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:35515 backend=nccl
[W1204 14:18:10.093105186 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:32875 (errno: 97 - Address family not supported by protocol).
[W1204 14:18:10.095690122 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:35515 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1601298)[0;0m INFO 12-04 14:18:10 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1601301)[0;0m INFO 12-04 14:18:10 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1601298)[0;0m INFO 12-04 14:18:11 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1601301)[0;0m INFO 12-04 14:18:11 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1601298)[0;0m INFO 12-04 14:18:12 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1601298)[0;0m INFO 12-04 14:18:12 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1601301)[0;0m INFO 12-04 14:18:12 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1601301)[0;0m INFO 12-04 14:18:12 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1601298)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1601301)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1601298)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.11s/it]
[1;36m(EngineCore_DP0 pid=1601301)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=1601298)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.39it/s]
[1;36m(EngineCore_DP0 pid=1601298)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=1601298)[0;0m 
[1;36m(EngineCore_DP0 pid=1601298)[0;0m INFO 12-04 14:18:14 [default_loader.py:314] Loading weights took 1.59 seconds
[1;36m(EngineCore_DP0 pid=1601301)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.37it/s]
[1;36m(EngineCore_DP0 pid=1601301)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.26it/s]
[1;36m(EngineCore_DP0 pid=1601301)[0;0m 
[1;36m(EngineCore_DP0 pid=1601301)[0;0m INFO 12-04 14:18:14 [default_loader.py:314] Loading weights took 1.62 seconds
[1;36m(EngineCore_DP0 pid=1601298)[0;0m INFO 12-04 14:18:14 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.868334 seconds
[1;36m(EngineCore_DP0 pid=1601301)[0;0m INFO 12-04 14:18:15 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.065276 seconds
[1;36m(EngineCore_DP0 pid=1601298)[0;0m INFO 12-04 14:18:28 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1601301)[0;0m INFO 12-04 14:18:28 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1601298)[0;0m INFO 12-04 14:18:28 [backends.py:647] Dynamo bytecode transform time: 13.28 s
[1;36m(EngineCore_DP0 pid=1601301)[0;0m INFO 12-04 14:18:28 [backends.py:647] Dynamo bytecode transform time: 13.08 s
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc5d552b6b0>' raised:
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1601298)[0;0m ERROR 12-04 14:18:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb06b03f890>' raised:
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1601301)[0;0m ERROR 12-04 14:18:29 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1601298)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1601301)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1601301)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1601301)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1601298)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1601298)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1601301)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1601298)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1601298)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1601298)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1601298)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fc5d552b6b0>' raised:
[1;36m(EngineCore_DP0 pid=1601298)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1601298)[0;0m 
[1;36m(EngineCore_DP0 pid=1601298)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1601298)[0;0m 
[1;36m(EngineCore_DP0 pid=1601301)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1601301)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1601301)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb06b03f890>' raised:
[1;36m(EngineCore_DP0 pid=1601301)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1601301)[0;0m 
[1;36m(EngineCore_DP0 pid=1601301)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1601301)[0;0m 
[rank0]:[W1204 14:18:29.288546711 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:18:29.288546792 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:18:51 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:18:51 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:18:51 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:18:51 [model.py:1745] Using max model len 131072
INFO 12-04 14:18:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:18:51 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:18:51 [model.py:1745] Using max model len 131072
INFO 12-04 14:18:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1603776)[0;0m INFO 12-04 14:19:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1603773)[0;0m INFO 12-04 14:19:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1603776)[0;0m INFO 12-04 14:19:20 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:33567 backend=nccl
[1;36m(EngineCore_DP0 pid=1603773)[0;0m INFO 12-04 14:19:20 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:52289 backend=nccl
[W1204 14:19:20.855135550 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:33567 (errno: 97 - Address family not supported by protocol).
[W1204 14:19:20.856156829 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:52289 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1603773)[0;0m INFO 12-04 14:19:20 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1603776)[0;0m INFO 12-04 14:19:20 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1603773)[0;0m INFO 12-04 14:19:20 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1603776)[0;0m INFO 12-04 14:19:20 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1603776)[0;0m INFO 12-04 14:19:22 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1603776)[0;0m INFO 12-04 14:19:22 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1603773)[0;0m INFO 12-04 14:19:22 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1603773)[0;0m INFO 12-04 14:19:22 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1603773)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1603776)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1603773)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=1603776)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
[1;36m(EngineCore_DP0 pid=1603773)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.38it/s]
[1;36m(EngineCore_DP0 pid=1603773)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.27it/s]
[1;36m(EngineCore_DP0 pid=1603773)[0;0m 
[1;36m(EngineCore_DP0 pid=1603773)[0;0m INFO 12-04 14:19:24 [default_loader.py:314] Loading weights took 1.61 seconds
[1;36m(EngineCore_DP0 pid=1603776)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.36it/s]
[1;36m(EngineCore_DP0 pid=1603776)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.26it/s]
[1;36m(EngineCore_DP0 pid=1603776)[0;0m 
[1;36m(EngineCore_DP0 pid=1603776)[0;0m INFO 12-04 14:19:24 [default_loader.py:314] Loading weights took 1.63 seconds
[1;36m(EngineCore_DP0 pid=1603773)[0;0m INFO 12-04 14:19:24 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.916749 seconds
[1;36m(EngineCore_DP0 pid=1603776)[0;0m INFO 12-04 14:19:24 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.054079 seconds
[1;36m(EngineCore_DP0 pid=1603773)[0;0m INFO 12-04 14:19:34 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1603776)[0;0m INFO 12-04 14:19:34 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1603776)[0;0m INFO 12-04 14:19:34 [backends.py:647] Dynamo bytecode transform time: 9.69 s
[1;36m(EngineCore_DP0 pid=1603773)[0;0m INFO 12-04 14:19:34 [backends.py:647] Dynamo bytecode transform time: 9.84 s
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd16417e180>' raised:
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1603773)[0;0m ERROR 12-04 14:19:35 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f19780a76b0>' raised:
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1603776)[0;0m ERROR 12-04 14:19:35 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1603773)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1603773)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1603773)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1603773)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1603773)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603773)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1603773)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1603773)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd16417e180>' raised:
[1;36m(EngineCore_DP0 pid=1603773)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1603773)[0;0m 
[1;36m(EngineCore_DP0 pid=1603773)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1603773)[0;0m 
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1603776)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1603776)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1603776)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1603776)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1603776)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1603776)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f19780a76b0>' raised:
[1;36m(EngineCore_DP0 pid=1603776)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1603776)[0;0m 
[1;36m(EngineCore_DP0 pid=1603776)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1603776)[0;0m 
[rank0]:[W1204 14:19:36.739720036 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:19:36.739772367 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:19:57 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:19:57 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:19:57 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:19:57 [model.py:1745] Using max model len 131072
INFO 12-04 14:19:57 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:19:57 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:19:57 [model.py:1745] Using max model len 131072
INFO 12-04 14:19:57 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1607448)[0;0m INFO 12-04 14:20:20 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1607445)[0;0m INFO 12-04 14:20:20 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1607445)[0;0m INFO 12-04 14:20:22 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:54041 backend=nccl
[1;36m(EngineCore_DP0 pid=1607448)[0;0m INFO 12-04 14:20:22 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:42457 backend=nccl
[W1204 14:20:22.293943228 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:42457 (errno: 97 - Address family not supported by protocol).
[W1204 14:20:22.294049904 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:54041 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1607448)[0;0m INFO 12-04 14:20:22 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1607445)[0;0m INFO 12-04 14:20:22 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1607448)[0;0m INFO 12-04 14:20:23 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1607445)[0;0m INFO 12-04 14:20:23 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1607445)[0;0m INFO 12-04 14:20:24 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1607445)[0;0m INFO 12-04 14:20:24 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1607448)[0;0m INFO 12-04 14:20:24 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1607448)[0;0m INFO 12-04 14:20:24 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1607445)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1607448)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1607445)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.21s/it]
[1;36m(EngineCore_DP0 pid=1607448)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.19s/it]
[1;36m(EngineCore_DP0 pid=1607445)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=1607445)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=1607445)[0;0m 
[1;36m(EngineCore_DP0 pid=1607445)[0;0m INFO 12-04 14:20:26 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=1607448)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=1607448)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.20it/s]
[1;36m(EngineCore_DP0 pid=1607448)[0;0m 
[1;36m(EngineCore_DP0 pid=1607448)[0;0m INFO 12-04 14:20:26 [default_loader.py:314] Loading weights took 1.71 seconds
[1;36m(EngineCore_DP0 pid=1607445)[0;0m INFO 12-04 14:20:27 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.994487 seconds
[1;36m(EngineCore_DP0 pid=1607448)[0;0m INFO 12-04 14:20:27 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.103225 seconds
[1;36m(EngineCore_DP0 pid=1607445)[0;0m INFO 12-04 14:20:38 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1607448)[0;0m INFO 12-04 14:20:38 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1607445)[0;0m INFO 12-04 14:20:38 [backends.py:647] Dynamo bytecode transform time: 10.92 s
[1;36m(EngineCore_DP0 pid=1607448)[0;0m INFO 12-04 14:20:38 [backends.py:647] Dynamo bytecode transform time: 10.82 s
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8b7cbd3500>' raised:
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1607445)[0;0m ERROR 12-04 14:20:39 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb06c133d40>' raised:
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1607448)[0;0m ERROR 12-04 14:20:39 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1607445)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1607448)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1607448)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1607448)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1607445)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1607445)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1607445)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1607445)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607445)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1607445)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1607445)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f8b7cbd3500>' raised:
[1;36m(EngineCore_DP0 pid=1607445)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1607445)[0;0m 
[1;36m(EngineCore_DP0 pid=1607445)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1607445)[0;0m 
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1607448)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1607448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1607448)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1607448)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb06c133d40>' raised:
[1;36m(EngineCore_DP0 pid=1607448)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1607448)[0;0m 
[1;36m(EngineCore_DP0 pid=1607448)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1607448)[0;0m 
[rank0]:[W1204 14:20:40.476193832 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:20:40.476161238 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:21:01 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:21:01 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:21:01 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:21:01 [model.py:1745] Using max model len 131072
INFO 12-04 14:21:01 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:21:01 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:21:01 [model.py:1745] Using max model len 131072
INFO 12-04 14:21:01 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1608794)[0;0m INFO 12-04 14:21:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1608791)[0;0m INFO 12-04 14:21:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1608794)[0;0m INFO 12-04 14:21:28 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:53409 backend=nccl
[1;36m(EngineCore_DP0 pid=1608791)[0;0m INFO 12-04 14:21:28 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:37913 backend=nccl
[W1204 14:21:28.248768450 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:53409 (errno: 97 - Address family not supported by protocol).
[W1204 14:21:28.250339920 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:37913 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1608794)[0;0m INFO 12-04 14:21:28 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1608791)[0;0m INFO 12-04 14:21:28 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1608794)[0;0m INFO 12-04 14:21:29 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1608791)[0;0m INFO 12-04 14:21:29 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1608791)[0;0m INFO 12-04 14:21:30 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1608791)[0;0m INFO 12-04 14:21:30 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1608794)[0;0m INFO 12-04 14:21:30 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1608794)[0;0m INFO 12-04 14:21:30 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1608794)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1608791)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1608794)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1608791)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1608794)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.35it/s]
[1;36m(EngineCore_DP0 pid=1608794)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
[1;36m(EngineCore_DP0 pid=1608794)[0;0m 
[1;36m(EngineCore_DP0 pid=1608794)[0;0m INFO 12-04 14:21:32 [default_loader.py:314] Loading weights took 1.64 seconds
[1;36m(EngineCore_DP0 pid=1608791)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1608791)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1608791)[0;0m 
[1;36m(EngineCore_DP0 pid=1608791)[0;0m INFO 12-04 14:21:33 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1608794)[0;0m INFO 12-04 14:21:33 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.200144 seconds
[1;36m(EngineCore_DP0 pid=1608791)[0;0m INFO 12-04 14:21:33 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.358351 seconds
[1;36m(EngineCore_DP0 pid=1608791)[0;0m INFO 12-04 14:21:46 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1608794)[0;0m INFO 12-04 14:21:46 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1608791)[0;0m INFO 12-04 14:21:46 [backends.py:647] Dynamo bytecode transform time: 12.39 s
[1;36m(EngineCore_DP0 pid=1608794)[0;0m INFO 12-04 14:21:46 [backends.py:647] Dynamo bytecode transform time: 12.55 s
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f77d82088c0>' raised:
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1608794)[0;0m ERROR 12-04 14:21:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7efe002b8440>' raised:
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1608791)[0;0m ERROR 12-04 14:21:47 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1608794)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1608794)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1608794)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608794)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1608794)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1608794)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f77d82088c0>' raised:
[1;36m(EngineCore_DP0 pid=1608794)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1608794)[0;0m 
[1;36m(EngineCore_DP0 pid=1608794)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1608794)[0;0m 
[1;36m(EngineCore_DP0 pid=1608791)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1608791)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1608791)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1608791)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1608791)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1608791)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1608791)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7efe002b8440>' raised:
[1;36m(EngineCore_DP0 pid=1608791)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1608791)[0;0m 
[1;36m(EngineCore_DP0 pid=1608791)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1608791)[0;0m 
[rank0]:[W1204 14:21:47.236961833 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:21:47.237488764 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:22:09 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:22:09 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:22:09 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:22:09 [model.py:1745] Using max model len 131072
INFO 12-04 14:22:09 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:22:09 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:22:09 [model.py:1745] Using max model len 131072
INFO 12-04 14:22:09 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1610103)[0;0m INFO 12-04 14:22:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1610120)[0;0m INFO 12-04 14:22:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1610103)[0;0m INFO 12-04 14:22:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:41359 backend=nccl
[1;36m(EngineCore_DP0 pid=1610120)[0;0m INFO 12-04 14:22:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:53819 backend=nccl
[W1204 14:22:38.950041739 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:41359 (errno: 97 - Address family not supported by protocol).
[W1204 14:22:38.950028774 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:53819 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1610103)[0;0m INFO 12-04 14:22:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1610120)[0;0m INFO 12-04 14:22:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1610120)[0;0m INFO 12-04 14:22:39 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1610103)[0;0m INFO 12-04 14:22:39 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1610120)[0;0m INFO 12-04 14:22:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1610103)[0;0m INFO 12-04 14:22:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1610120)[0;0m INFO 12-04 14:22:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1610103)[0;0m INFO 12-04 14:22:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1610103)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1610120)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1610103)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=1610120)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1610103)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1610103)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1610103)[0;0m 
[1;36m(EngineCore_DP0 pid=1610103)[0;0m INFO 12-04 14:22:42 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1610120)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=1610120)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1610120)[0;0m 
[1;36m(EngineCore_DP0 pid=1610120)[0;0m INFO 12-04 14:22:42 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=1610103)[0;0m INFO 12-04 14:22:43 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.979230 seconds
[1;36m(EngineCore_DP0 pid=1610120)[0;0m INFO 12-04 14:22:43 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.108689 seconds
[1;36m(EngineCore_DP0 pid=1610120)[0;0m INFO 12-04 14:22:54 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1610103)[0;0m INFO 12-04 14:22:54 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1610120)[0;0m INFO 12-04 14:22:54 [backends.py:647] Dynamo bytecode transform time: 11.15 s
[1;36m(EngineCore_DP0 pid=1610103)[0;0m INFO 12-04 14:22:54 [backends.py:647] Dynamo bytecode transform time: 11.28 s
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f54b1e776b0>' raised:
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1610103)[0;0m ERROR 12-04 14:22:55 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7eff802d3ef0>' raised:
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1610120)[0;0m ERROR 12-04 14:22:55 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1610103)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1610120)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1610103)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1610103)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1610103)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610103)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1610103)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1610103)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f54b1e776b0>' raised:
[1;36m(EngineCore_DP0 pid=1610103)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1610103)[0;0m 
[1;36m(EngineCore_DP0 pid=1610103)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1610103)[0;0m 
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1610120)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1610120)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1610120)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1610120)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1610120)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1610120)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7eff802d3ef0>' raised:
[1;36m(EngineCore_DP0 pid=1610120)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1610120)[0;0m 
[1;36m(EngineCore_DP0 pid=1610120)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1610120)[0;0m 
[rank0]:[W1204 14:22:56.432094926 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:22:56.432221331 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:23:17 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:23:17 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:23:17 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:23:17 [model.py:1745] Using max model len 131072
INFO 12-04 14:23:17 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:23:17 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:23:17 [model.py:1745] Using max model len 131072
INFO 12-04 14:23:17 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1611488)[0;0m INFO 12-04 14:23:50 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1611485)[0;0m INFO 12-04 14:23:50 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1611488)[0;0m INFO 12-04 14:23:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:54523 backend=nccl
[1;36m(EngineCore_DP0 pid=1611485)[0;0m INFO 12-04 14:23:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:52599 backend=nccl
[W1204 14:23:53.415260009 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:54523 (errno: 97 - Address family not supported by protocol).
[W1204 14:23:53.416147983 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:52599 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1611488)[0;0m INFO 12-04 14:23:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1611485)[0;0m INFO 12-04 14:23:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1611485)[0;0m INFO 12-04 14:23:53 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1611488)[0;0m INFO 12-04 14:23:53 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1611488)[0;0m INFO 12-04 14:23:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1611488)[0;0m INFO 12-04 14:23:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1611485)[0;0m INFO 12-04 14:23:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1611485)[0;0m INFO 12-04 14:23:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1611488)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1611485)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1611488)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1611485)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=1611488)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.37it/s]
[1;36m(EngineCore_DP0 pid=1611488)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.26it/s]
[1;36m(EngineCore_DP0 pid=1611488)[0;0m 
[1;36m(EngineCore_DP0 pid=1611488)[0;0m INFO 12-04 14:23:57 [default_loader.py:314] Loading weights took 1.62 seconds
[1;36m(EngineCore_DP0 pid=1611485)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1611485)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1611485)[0;0m 
[1;36m(EngineCore_DP0 pid=1611485)[0;0m INFO 12-04 14:23:57 [default_loader.py:314] Loading weights took 1.64 seconds
[1;36m(EngineCore_DP0 pid=1611488)[0;0m INFO 12-04 14:23:57 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.182525 seconds
[1;36m(EngineCore_DP0 pid=1611485)[0;0m INFO 12-04 14:23:57 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.336551 seconds
[1;36m(EngineCore_DP0 pid=1611488)[0;0m INFO 12-04 14:24:09 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1611485)[0;0m INFO 12-04 14:24:09 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1611488)[0;0m INFO 12-04 14:24:09 [backends.py:647] Dynamo bytecode transform time: 11.18 s
[1;36m(EngineCore_DP0 pid=1611485)[0;0m INFO 12-04 14:24:09 [backends.py:647] Dynamo bytecode transform time: 11.04 s
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f36043a4c20>' raised:
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1611485)[0;0m ERROR 12-04 14:24:09 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fa809487740>' raised:
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1611488)[0;0m ERROR 12-04 14:24:09 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1611485)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1611488)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1611485)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1611485)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1611485)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1611485)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1611485)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f36043a4c20>' raised:
[1;36m(EngineCore_DP0 pid=1611485)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1611485)[0;0m 
[1;36m(EngineCore_DP0 pid=1611485)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1611485)[0;0m 
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1611488)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1611488)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1611488)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1611488)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1611488)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1611488)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fa809487740>' raised:
[1;36m(EngineCore_DP0 pid=1611488)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1611488)[0;0m 
[1;36m(EngineCore_DP0 pid=1611488)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1611488)[0;0m 
[rank0]:[W1204 14:24:10.967101330 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:24:10.967101391 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:24:31 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:24:31 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:24:32 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:24:32 [model.py:1745] Using max model len 131072
INFO 12-04 14:24:32 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:24:32 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:24:32 [model.py:1745] Using max model len 131072
INFO 12-04 14:24:32 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1612967)[0;0m INFO 12-04 14:24:55 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1612964)[0;0m INFO 12-04 14:24:55 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1612967)[0;0m INFO 12-04 14:24:57 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:58501 backend=nccl
[1;36m(EngineCore_DP0 pid=1612964)[0;0m INFO 12-04 14:24:57 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:34161 backend=nccl
[W1204 14:24:57.979286956 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:58501 (errno: 97 - Address family not supported by protocol).
[W1204 14:24:57.979334434 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:34161 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1612967)[0;0m INFO 12-04 14:24:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1612964)[0;0m INFO 12-04 14:24:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1612967)[0;0m INFO 12-04 14:24:58 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1612964)[0;0m INFO 12-04 14:24:58 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1612967)[0;0m INFO 12-04 14:24:59 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1612967)[0;0m INFO 12-04 14:24:59 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1612964)[0;0m INFO 12-04 14:24:59 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1612964)[0;0m INFO 12-04 14:24:59 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1612967)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1612964)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1612967)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1612964)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1612967)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.35it/s]
[1;36m(EngineCore_DP0 pid=1612967)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
[1;36m(EngineCore_DP0 pid=1612967)[0;0m 
[1;36m(EngineCore_DP0 pid=1612967)[0;0m INFO 12-04 14:25:01 [default_loader.py:314] Loading weights took 1.64 seconds
[1;36m(EngineCore_DP0 pid=1612964)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1612964)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1612964)[0;0m 
[1;36m(EngineCore_DP0 pid=1612964)[0;0m INFO 12-04 14:25:01 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1612967)[0;0m INFO 12-04 14:25:01 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.886237 seconds
[1;36m(EngineCore_DP0 pid=1612964)[0;0m INFO 12-04 14:25:02 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.034256 seconds
[1;36m(EngineCore_DP0 pid=1612967)[0;0m INFO 12-04 14:25:12 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1612964)[0;0m INFO 12-04 14:25:12 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1612967)[0;0m INFO 12-04 14:25:12 [backends.py:647] Dynamo bytecode transform time: 10.31 s
[1;36m(EngineCore_DP0 pid=1612964)[0;0m INFO 12-04 14:25:12 [backends.py:647] Dynamo bytecode transform time: 10.15 s
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f9cb1def8f0>' raised:
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1612964)[0;0m ERROR 12-04 14:25:13 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fef90213d40>' raised:
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1612967)[0;0m ERROR 12-04 14:25:13 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1612964)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1612967)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1612964)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1612967)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1612967)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1612964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1612964)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1612964)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1612964)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f9cb1def8f0>' raised:
[1;36m(EngineCore_DP0 pid=1612964)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1612964)[0;0m 
[1;36m(EngineCore_DP0 pid=1612964)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1612964)[0;0m 
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1612967)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1612967)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1612967)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1612967)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fef90213d40>' raised:
[1;36m(EngineCore_DP0 pid=1612967)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1612967)[0;0m 
[1;36m(EngineCore_DP0 pid=1612967)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1612967)[0;0m 
[rank0]:[W1204 14:25:14.392531854 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:25:14.392653880 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:25:35 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:25:35 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:25:35 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:25:35 [model.py:1745] Using max model len 131072
INFO 12-04 14:25:35 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:25:35 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:25:35 [model.py:1745] Using max model len 131072
INFO 12-04 14:25:35 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1614020)[0;0m INFO 12-04 14:26:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1614021)[0;0m INFO 12-04 14:26:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1614020)[0;0m INFO 12-04 14:26:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:44189 backend=nccl
[1;36m(EngineCore_DP0 pid=1614021)[0;0m INFO 12-04 14:26:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:46681 backend=nccl
[W1204 14:26:04.845099640 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:44189 (errno: 97 - Address family not supported by protocol).
[W1204 14:26:04.845658009 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:46681 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1614020)[0;0m INFO 12-04 14:26:04 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1614021)[0;0m INFO 12-04 14:26:04 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1614021)[0;0m INFO 12-04 14:26:04 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1614020)[0;0m INFO 12-04 14:26:04 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1614020)[0;0m INFO 12-04 14:26:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1614020)[0;0m INFO 12-04 14:26:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1614021)[0;0m INFO 12-04 14:26:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1614021)[0;0m INFO 12-04 14:26:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1614021)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1614020)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1614021)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1614020)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1614021)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.36it/s]
[1;36m(EngineCore_DP0 pid=1614021)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
[1;36m(EngineCore_DP0 pid=1614021)[0;0m 
[1;36m(EngineCore_DP0 pid=1614021)[0;0m INFO 12-04 14:26:08 [default_loader.py:314] Loading weights took 1.63 seconds
[1;36m(EngineCore_DP0 pid=1614020)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1614020)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1614020)[0;0m 
[1;36m(EngineCore_DP0 pid=1614020)[0;0m INFO 12-04 14:26:08 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1614021)[0;0m INFO 12-04 14:26:08 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.875898 seconds
[1;36m(EngineCore_DP0 pid=1614020)[0;0m INFO 12-04 14:26:08 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.035811 seconds
[1;36m(EngineCore_DP0 pid=1614020)[0;0m INFO 12-04 14:26:19 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1614021)[0;0m INFO 12-04 14:26:19 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1614020)[0;0m INFO 12-04 14:26:19 [backends.py:647] Dynamo bytecode transform time: 10.24 s
[1;36m(EngineCore_DP0 pid=1614021)[0;0m INFO 12-04 14:26:19 [backends.py:647] Dynamo bytecode transform time: 10.40 s
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fa4a82daea0>' raised:
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1614020)[0;0m ERROR 12-04 14:26:20 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f468c267470>' raised:
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1614021)[0;0m ERROR 12-04 14:26:20 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1614020)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1614021)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1614021)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1614021)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1614020)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1614020)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1614020)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614020)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1614020)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1614020)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fa4a82daea0>' raised:
[1;36m(EngineCore_DP0 pid=1614020)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1614020)[0;0m 
[1;36m(EngineCore_DP0 pid=1614020)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1614020)[0;0m 
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1614021)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1614021)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1614021)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1614021)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f468c267470>' raised:
[1;36m(EngineCore_DP0 pid=1614021)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1614021)[0;0m 
[1;36m(EngineCore_DP0 pid=1614021)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1614021)[0;0m 
[rank0]:[W1204 14:26:20.290234835 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:26:20.299923488 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:42 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:42 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:26:42 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:26:42 [model.py:1745] Using max model len 131072
INFO 12-04 14:26:42 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:26:42 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:26:42 [model.py:1745] Using max model len 131072
INFO 12-04 14:26:42 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1615498)[0;0m INFO 12-04 14:27:07 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1615501)[0;0m INFO 12-04 14:27:07 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1615498)[0;0m INFO 12-04 14:27:10 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:55653 backend=nccl
[1;36m(EngineCore_DP0 pid=1615501)[0;0m INFO 12-04 14:27:10 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:57313 backend=nccl
[W1204 14:27:10.839563627 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:55653 (errno: 97 - Address family not supported by protocol).
[W1204 14:27:10.842462104 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:57313 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1615498)[0;0m INFO 12-04 14:27:10 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1615501)[0;0m INFO 12-04 14:27:10 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1615498)[0;0m INFO 12-04 14:27:10 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1615501)[0;0m INFO 12-04 14:27:10 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1615501)[0;0m INFO 12-04 14:27:12 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1615501)[0;0m INFO 12-04 14:27:12 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1615498)[0;0m INFO 12-04 14:27:12 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1615498)[0;0m INFO 12-04 14:27:12 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1615501)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1615498)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1615501)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=1615498)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1615501)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1615501)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1615501)[0;0m 
[1;36m(EngineCore_DP0 pid=1615501)[0;0m INFO 12-04 14:27:14 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1615498)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=1615498)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1615498)[0;0m 
[1;36m(EngineCore_DP0 pid=1615498)[0;0m INFO 12-04 14:27:14 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=1615501)[0;0m INFO 12-04 14:27:14 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.868572 seconds
[1;36m(EngineCore_DP0 pid=1615498)[0;0m INFO 12-04 14:27:14 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.007168 seconds
[1;36m(EngineCore_DP0 pid=1615501)[0;0m INFO 12-04 14:27:25 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1615498)[0;0m INFO 12-04 14:27:25 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1615501)[0;0m INFO 12-04 14:27:25 [backends.py:647] Dynamo bytecode transform time: 10.63 s
[1;36m(EngineCore_DP0 pid=1615498)[0;0m INFO 12-04 14:27:25 [backends.py:647] Dynamo bytecode transform time: 10.51 s
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fcbf01004a0>' raised:
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1615498)[0;0m ERROR 12-04 14:27:26 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fade0116900>' raised:
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1615501)[0;0m ERROR 12-04 14:27:26 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1615501)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1615498)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1615498)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1615501)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1615501)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1615501)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615501)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1615501)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1615501)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fade0116900>' raised:
[1;36m(EngineCore_DP0 pid=1615501)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1615501)[0;0m 
[1;36m(EngineCore_DP0 pid=1615501)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1615501)[0;0m 
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1615498)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1615498)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1615498)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1615498)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fcbf01004a0>' raised:
[1;36m(EngineCore_DP0 pid=1615498)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1615498)[0;0m 
[1;36m(EngineCore_DP0 pid=1615498)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1615498)[0;0m 
[rank0]:[W1204 14:27:27.541445980 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:27:27.541445778 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:27:48 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:27:48 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:27:48 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:27:48 [model.py:1745] Using max model len 131072
INFO 12-04 14:27:48 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:27:48 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:27:48 [model.py:1745] Using max model len 131072
INFO 12-04 14:27:48 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1617022)[0;0m INFO 12-04 14:28:21 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1616889)[0;0m INFO 12-04 14:28:21 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1617022)[0;0m INFO 12-04 14:28:24 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:34455 backend=nccl
[1;36m(EngineCore_DP0 pid=1616889)[0;0m INFO 12-04 14:28:24 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:42231 backend=nccl
[W1204 14:28:24.728733700 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:34455 (errno: 97 - Address family not supported by protocol).
[W1204 14:28:24.728733704 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:42231 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1617022)[0;0m INFO 12-04 14:28:24 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1616889)[0;0m INFO 12-04 14:28:24 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1617022)[0;0m INFO 12-04 14:28:24 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1616889)[0;0m INFO 12-04 14:28:24 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1617022)[0;0m INFO 12-04 14:28:26 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1617022)[0;0m INFO 12-04 14:28:26 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1616889)[0;0m INFO 12-04 14:28:26 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1616889)[0;0m INFO 12-04 14:28:26 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1617022)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1616889)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1617022)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1616889)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=1617022)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.35it/s]
[1;36m(EngineCore_DP0 pid=1617022)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1617022)[0;0m 
[1;36m(EngineCore_DP0 pid=1617022)[0;0m INFO 12-04 14:28:28 [default_loader.py:314] Loading weights took 1.64 seconds
[1;36m(EngineCore_DP0 pid=1616889)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1616889)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1616889)[0;0m 
[1;36m(EngineCore_DP0 pid=1616889)[0;0m INFO 12-04 14:28:28 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1617022)[0;0m INFO 12-04 14:28:28 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.168519 seconds
[1;36m(EngineCore_DP0 pid=1616889)[0;0m INFO 12-04 14:28:29 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.297086 seconds
[1;36m(EngineCore_DP0 pid=1616889)[0;0m INFO 12-04 14:28:39 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1617022)[0;0m INFO 12-04 14:28:39 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1616889)[0;0m INFO 12-04 14:28:39 [backends.py:647] Dynamo bytecode transform time: 10.30 s
[1;36m(EngineCore_DP0 pid=1617022)[0;0m INFO 12-04 14:28:39 [backends.py:647] Dynamo bytecode transform time: 10.43 s
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f66643d0470>' raised:
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1617022)[0;0m ERROR 12-04 14:28:40 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7efc2c281d30>' raised:
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1616889)[0;0m ERROR 12-04 14:28:40 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1617022)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1616889)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1616889)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1616889)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1617022)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1617022)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1617022)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1617022)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1617022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1617022)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1617022)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f66643d0470>' raised:
[1;36m(EngineCore_DP0 pid=1617022)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1617022)[0;0m 
[1;36m(EngineCore_DP0 pid=1617022)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1617022)[0;0m 
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1616889)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1616889)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1616889)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1616889)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7efc2c281d30>' raised:
[1;36m(EngineCore_DP0 pid=1616889)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1616889)[0;0m 
[1;36m(EngineCore_DP0 pid=1616889)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1616889)[0;0m 
[rank0]:[W1204 14:28:41.484949813 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:28:41.484949853 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:29:02 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:29:02 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:29:02 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:29:02 [model.py:1745] Using max model len 131072
INFO 12-04 14:29:02 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:29:02 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:29:02 [model.py:1745] Using max model len 131072
INFO 12-04 14:29:02 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1618373)[0;0m INFO 12-04 14:29:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1618376)[0;0m INFO 12-04 14:29:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1618376)[0;0m INFO 12-04 14:29:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:40675 backend=nccl
[1;36m(EngineCore_DP0 pid=1618373)[0;0m INFO 12-04 14:29:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:34995 backend=nccl
[W1204 14:29:29.012305255 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:40675 (errno: 97 - Address family not supported by protocol).
[W1204 14:29:29.013152184 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:34995 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1618376)[0;0m INFO 12-04 14:29:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1618373)[0;0m INFO 12-04 14:29:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1618373)[0;0m INFO 12-04 14:29:30 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1618376)[0;0m INFO 12-04 14:29:30 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1618373)[0;0m INFO 12-04 14:29:31 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1618376)[0;0m INFO 12-04 14:29:31 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1618373)[0;0m INFO 12-04 14:29:31 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1618376)[0;0m INFO 12-04 14:29:31 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1618376)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1618373)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1618376)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1618373)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1618376)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.36it/s]
[1;36m(EngineCore_DP0 pid=1618376)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
[1;36m(EngineCore_DP0 pid=1618376)[0;0m 
[1;36m(EngineCore_DP0 pid=1618376)[0;0m INFO 12-04 14:29:33 [default_loader.py:314] Loading weights took 1.63 seconds
[1;36m(EngineCore_DP0 pid=1618373)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1618373)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1618373)[0;0m 
[1;36m(EngineCore_DP0 pid=1618373)[0;0m INFO 12-04 14:29:33 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1618376)[0;0m INFO 12-04 14:29:34 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.028015 seconds
[1;36m(EngineCore_DP0 pid=1618373)[0;0m INFO 12-04 14:29:34 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.171495 seconds
[1;36m(EngineCore_DP0 pid=1618373)[0;0m INFO 12-04 14:29:45 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1618376)[0;0m INFO 12-04 14:29:45 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1618373)[0;0m INFO 12-04 14:29:45 [backends.py:647] Dynamo bytecode transform time: 11.34 s
[1;36m(EngineCore_DP0 pid=1618376)[0;0m INFO 12-04 14:29:45 [backends.py:647] Dynamo bytecode transform time: 11.48 s
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1618373)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fe1c40df950>' raised:
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1618376)[0;0m ERROR 12-04 14:29:46 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd0ce0838f0>' raised:
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1618373)[0;0m ERROR 12-04 14:29:46 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1618376)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1618373)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1618376)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1618376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1618376)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1618373)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1618373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1618376)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1618376)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fe1c40df950>' raised:
[1;36m(EngineCore_DP0 pid=1618376)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1618376)[0;0m 
[1;36m(EngineCore_DP0 pid=1618376)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1618376)[0;0m 
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1618373)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1618373)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1618373)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1618373)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fd0ce0838f0>' raised:
[1;36m(EngineCore_DP0 pid=1618373)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1618373)[0;0m 
[1;36m(EngineCore_DP0 pid=1618373)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1618373)[0;0m 
[rank0]:[W1204 14:29:47.665973019 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:29:47.665972936 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:30:08 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:30:08 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:30:08 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:30:08 [model.py:1745] Using max model len 131072
INFO 12-04 14:30:08 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:30:08 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:30:08 [model.py:1745] Using max model len 131072
INFO 12-04 14:30:08 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1619861)[0;0m INFO 12-04 14:30:34 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1619864)[0;0m INFO 12-04 14:30:34 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1619864)[0;0m INFO 12-04 14:30:36 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:45753 backend=nccl
[1;36m(EngineCore_DP0 pid=1619861)[0;0m INFO 12-04 14:30:36 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:33121 backend=nccl
[W1204 14:30:36.356045494 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:45753 (errno: 97 - Address family not supported by protocol).
[W1204 14:30:36.358219758 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:33121 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1619861)[0;0m INFO 12-04 14:30:37 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1619864)[0;0m INFO 12-04 14:30:37 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1619861)[0;0m INFO 12-04 14:30:37 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1619864)[0;0m INFO 12-04 14:30:37 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1619861)[0;0m INFO 12-04 14:30:38 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1619861)[0;0m INFO 12-04 14:30:38 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1619864)[0;0m INFO 12-04 14:30:38 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1619864)[0;0m INFO 12-04 14:30:38 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1619861)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1619864)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1619861)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.08s/it]
[1;36m(EngineCore_DP0 pid=1619864)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1619861)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
[1;36m(EngineCore_DP0 pid=1619861)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=1619861)[0;0m 
[1;36m(EngineCore_DP0 pid=1619861)[0;0m INFO 12-04 14:30:40 [default_loader.py:314] Loading weights took 1.58 seconds
[1;36m(EngineCore_DP0 pid=1619864)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=1619864)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1619864)[0;0m 
[1;36m(EngineCore_DP0 pid=1619864)[0;0m INFO 12-04 14:30:41 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=1619861)[0;0m INFO 12-04 14:30:41 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.853989 seconds
[1;36m(EngineCore_DP0 pid=1619864)[0;0m INFO 12-04 14:30:41 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.250561 seconds
[1;36m(EngineCore_DP0 pid=1619861)[0;0m INFO 12-04 14:30:52 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1619864)[0;0m INFO 12-04 14:30:52 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1619861)[0;0m INFO 12-04 14:30:52 [backends.py:647] Dynamo bytecode transform time: 11.00 s
[1;36m(EngineCore_DP0 pid=1619864)[0;0m INFO 12-04 14:30:52 [backends.py:647] Dynamo bytecode transform time: 10.63 s
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7ff7ec249bb0>' raised:
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1619861)[0;0m ERROR 12-04 14:30:53 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f9b6023f170>' raised:
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1619864)[0;0m ERROR 12-04 14:30:53 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1619861)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1619864)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1619861)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1619861)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1619861)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619861)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1619861)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1619861)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7ff7ec249bb0>' raised:
[1;36m(EngineCore_DP0 pid=1619861)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1619861)[0;0m 
[1;36m(EngineCore_DP0 pid=1619861)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1619861)[0;0m 
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1619864)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1619864)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1619864)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1619864)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1619864)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1619864)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f9b6023f170>' raised:
[1;36m(EngineCore_DP0 pid=1619864)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1619864)[0;0m 
[1;36m(EngineCore_DP0 pid=1619864)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1619864)[0;0m 
[rank0]:[W1204 14:30:53.352672240 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:30:53.352672312 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:31:15 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:31:15 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:31:15 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:31:15 [model.py:1745] Using max model len 131072
INFO 12-04 14:31:15 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:31:15 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:31:15 [model.py:1745] Using max model len 131072
INFO 12-04 14:31:15 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1621177)[0;0m INFO 12-04 14:31:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1621180)[0;0m INFO 12-04 14:31:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1621177)[0;0m INFO 12-04 14:31:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:38059 backend=nccl
[1;36m(EngineCore_DP0 pid=1621180)[0;0m INFO 12-04 14:31:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:59929 backend=nccl
[W1204 14:31:45.259535326 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:59929 (errno: 97 - Address family not supported by protocol).
[W1204 14:31:45.259901510 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:38059 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1621180)[0;0m INFO 12-04 14:31:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1621177)[0;0m INFO 12-04 14:31:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1621180)[0;0m INFO 12-04 14:31:46 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1621177)[0;0m INFO 12-04 14:31:46 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1621177)[0;0m INFO 12-04 14:31:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1621177)[0;0m INFO 12-04 14:31:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1621180)[0;0m INFO 12-04 14:31:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1621180)[0;0m INFO 12-04 14:31:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1621177)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1621180)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1621177)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=1621180)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1621177)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=1621177)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1621177)[0;0m 
[1;36m(EngineCore_DP0 pid=1621177)[0;0m INFO 12-04 14:31:49 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=1621180)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=1621180)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1621180)[0;0m 
[1;36m(EngineCore_DP0 pid=1621180)[0;0m INFO 12-04 14:31:49 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=1621177)[0;0m INFO 12-04 14:31:50 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.983397 seconds
[1;36m(EngineCore_DP0 pid=1621180)[0;0m INFO 12-04 14:31:50 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.087307 seconds
[1;36m(EngineCore_DP0 pid=1621177)[0;0m INFO 12-04 14:32:01 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1621180)[0;0m INFO 12-04 14:32:01 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1621177)[0;0m INFO 12-04 14:32:01 [backends.py:647] Dynamo bytecode transform time: 11.38 s
[1;36m(EngineCore_DP0 pid=1621180)[0;0m INFO 12-04 14:32:01 [backends.py:647] Dynamo bytecode transform time: 11.29 s
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f6564e175f0>' raised:
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1621180)[0;0m ERROR 12-04 14:32:02 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f7a0c201910>' raised:
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1621177)[0;0m ERROR 12-04 14:32:02 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1621180)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1621177)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1621180)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1621180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1621180)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1621180)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1621180)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f6564e175f0>' raised:
[1;36m(EngineCore_DP0 pid=1621180)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1621180)[0;0m 
[1;36m(EngineCore_DP0 pid=1621180)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1621180)[0;0m 
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1621177)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1621177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1621177)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1621177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1621177)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1621177)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f7a0c201910>' raised:
[1;36m(EngineCore_DP0 pid=1621177)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1621177)[0;0m 
[1;36m(EngineCore_DP0 pid=1621177)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1621177)[0;0m 
[rank0]:[W1204 14:32:03.790356389 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:32:03.790388030 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:24 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:24 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:32:24 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:32:24 [model.py:1745] Using max model len 131072
INFO 12-04 14:32:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:32:25 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:32:25 [model.py:1745] Using max model len 131072
INFO 12-04 14:32:25 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1623062)[0;0m INFO 12-04 14:32:50 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1623061)[0;0m INFO 12-04 14:32:50 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1623062)[0;0m INFO 12-04 14:32:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:54139 backend=nccl
[1;36m(EngineCore_DP0 pid=1623061)[0;0m INFO 12-04 14:32:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:59499 backend=nccl
[W1204 14:32:53.691569724 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:54139 (errno: 97 - Address family not supported by protocol).
[W1204 14:32:53.692069318 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:59499 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1623061)[0;0m INFO 12-04 14:32:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1623062)[0;0m INFO 12-04 14:32:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1623062)[0;0m INFO 12-04 14:32:53 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1623061)[0;0m INFO 12-04 14:32:53 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1623062)[0;0m INFO 12-04 14:32:55 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1623061)[0;0m INFO 12-04 14:32:55 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1623061)[0;0m INFO 12-04 14:32:55 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1623062)[0;0m INFO 12-04 14:32:55 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1623061)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1623062)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1623061)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1623062)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1623061)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1623061)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1623061)[0;0m 
[1;36m(EngineCore_DP0 pid=1623061)[0;0m INFO 12-04 14:32:57 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1623062)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=1623062)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1623062)[0;0m 
[1;36m(EngineCore_DP0 pid=1623062)[0;0m INFO 12-04 14:32:57 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=1623061)[0;0m INFO 12-04 14:32:57 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.100895 seconds
[1;36m(EngineCore_DP0 pid=1623062)[0;0m INFO 12-04 14:32:57 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.217341 seconds
[1;36m(EngineCore_DP0 pid=1623061)[0;0m INFO 12-04 14:33:10 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1623062)[0;0m INFO 12-04 14:33:10 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1623062)[0;0m INFO 12-04 14:33:10 [backends.py:647] Dynamo bytecode transform time: 12.43 s
[1;36m(EngineCore_DP0 pid=1623061)[0;0m INFO 12-04 14:33:10 [backends.py:647] Dynamo bytecode transform time: 12.55 s
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f4b3815d190>' raised:
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1623062)[0;0m ERROR 12-04 14:33:11 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1623061)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f34902bb230>' raised:
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1623061)[0;0m ERROR 12-04 14:33:11 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1623062)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1623061)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1623062)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1623062)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1623061)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1623061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1623062)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623062)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1623062)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1623062)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f4b3815d190>' raised:
[1;36m(EngineCore_DP0 pid=1623062)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1623062)[0;0m 
[1;36m(EngineCore_DP0 pid=1623062)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1623062)[0;0m 
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1623061)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1623061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1623061)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1623061)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f34902bb230>' raised:
[1;36m(EngineCore_DP0 pid=1623061)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1623061)[0;0m 
[1;36m(EngineCore_DP0 pid=1623061)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1623061)[0;0m 
[rank0]:[W1204 14:33:12.522024927 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:33:12.522037878 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:33:33 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:33:33 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:33:33 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:33:33 [model.py:1745] Using max model len 131072
INFO 12-04 14:33:33 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:33:33 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:33:33 [model.py:1745] Using max model len 131072
INFO 12-04 14:33:33 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1624522)[0;0m INFO 12-04 14:33:57 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1624525)[0;0m INFO 12-04 14:33:57 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1624522)[0;0m INFO 12-04 14:34:00 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:58425 backend=nccl
[1;36m(EngineCore_DP0 pid=1624525)[0;0m INFO 12-04 14:34:00 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:58891 backend=nccl
[W1204 14:34:00.860945271 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:58891 (errno: 97 - Address family not supported by protocol).
[W1204 14:34:00.861117454 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:58425 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1624525)[0;0m INFO 12-04 14:34:00 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1624522)[0;0m INFO 12-04 14:34:00 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1624522)[0;0m INFO 12-04 14:34:00 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1624525)[0;0m INFO 12-04 14:34:00 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1624522)[0;0m INFO 12-04 14:34:02 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1624522)[0;0m INFO 12-04 14:34:02 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1624525)[0;0m INFO 12-04 14:34:02 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1624525)[0;0m INFO 12-04 14:34:02 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1624525)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1624522)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1624525)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1624522)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=1624525)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.35it/s]
[1;36m(EngineCore_DP0 pid=1624525)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
[1;36m(EngineCore_DP0 pid=1624525)[0;0m 
[1;36m(EngineCore_DP0 pid=1624525)[0;0m INFO 12-04 14:34:04 [default_loader.py:314] Loading weights took 1.64 seconds
[1;36m(EngineCore_DP0 pid=1624522)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1624522)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1624522)[0;0m 
[1;36m(EngineCore_DP0 pid=1624522)[0;0m INFO 12-04 14:34:04 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1624525)[0;0m INFO 12-04 14:34:04 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.950286 seconds
[1;36m(EngineCore_DP0 pid=1624522)[0;0m INFO 12-04 14:34:05 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.089900 seconds
[1;36m(EngineCore_DP0 pid=1624522)[0;0m INFO 12-04 14:34:16 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1624525)[0;0m INFO 12-04 14:34:16 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1624522)[0;0m INFO 12-04 14:34:16 [backends.py:647] Dynamo bytecode transform time: 10.91 s
[1;36m(EngineCore_DP0 pid=1624525)[0;0m INFO 12-04 14:34:16 [backends.py:647] Dynamo bytecode transform time: 11.05 s
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb6982f6a50>' raised:
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1624522)[0;0m ERROR 12-04 14:34:16 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fbfb80faf90>' raised:
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1624525)[0;0m ERROR 12-04 14:34:16 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1624522)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1624525)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1624525)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1624525)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1624522)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1624522)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1624522)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624522)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1624522)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1624522)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fb6982f6a50>' raised:
[1;36m(EngineCore_DP0 pid=1624522)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1624522)[0;0m 
[1;36m(EngineCore_DP0 pid=1624522)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1624522)[0;0m 
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1624525)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1624525)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1624525)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1624525)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fbfb80faf90>' raised:
[1;36m(EngineCore_DP0 pid=1624525)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1624525)[0;0m 
[1;36m(EngineCore_DP0 pid=1624525)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1624525)[0;0m 
[rank0]:[W1204 14:34:17.018413011 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:34:17.018412918 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:34:38 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:34:38 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:34:39 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:34:39 [model.py:1745] Using max model len 131072
INFO 12-04 14:34:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:34:39 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:34:39 [model.py:1745] Using max model len 131072
INFO 12-04 14:34:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1626385)[0;0m INFO 12-04 14:35:05 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1626382)[0;0m INFO 12-04 14:35:05 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1626382)[0;0m INFO 12-04 14:35:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:54761 backend=nccl
[1;36m(EngineCore_DP0 pid=1626385)[0;0m INFO 12-04 14:35:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:60661 backend=nccl
[W1204 14:35:08.692115395 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:54761 (errno: 97 - Address family not supported by protocol).
[W1204 14:35:08.692572040 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:60661 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1626385)[0;0m INFO 12-04 14:35:08 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1626382)[0;0m INFO 12-04 14:35:08 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1626385)[0;0m INFO 12-04 14:35:08 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1626382)[0;0m INFO 12-04 14:35:08 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1626382)[0;0m INFO 12-04 14:35:09 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1626382)[0;0m INFO 12-04 14:35:09 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1626385)[0;0m INFO 12-04 14:35:09 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1626385)[0;0m INFO 12-04 14:35:09 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1626382)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1626385)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1626382)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.18s/it]
[1;36m(EngineCore_DP0 pid=1626385)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
[1;36m(EngineCore_DP0 pid=1626382)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1626382)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1626382)[0;0m 
[1;36m(EngineCore_DP0 pid=1626382)[0;0m INFO 12-04 14:35:12 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=1626385)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
[1;36m(EngineCore_DP0 pid=1626385)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=1626385)[0;0m 
[1;36m(EngineCore_DP0 pid=1626385)[0;0m INFO 12-04 14:35:12 [default_loader.py:314] Loading weights took 1.67 seconds
[1;36m(EngineCore_DP0 pid=1626382)[0;0m INFO 12-04 14:35:12 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.937242 seconds
[1;36m(EngineCore_DP0 pid=1626385)[0;0m INFO 12-04 14:35:12 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.090088 seconds
[1;36m(EngineCore_DP0 pid=1626385)[0;0m INFO 12-04 14:35:23 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1626382)[0;0m INFO 12-04 14:35:23 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1626385)[0;0m INFO 12-04 14:35:23 [backends.py:647] Dynamo bytecode transform time: 10.38 s
[1;36m(EngineCore_DP0 pid=1626382)[0;0m INFO 12-04 14:35:23 [backends.py:647] Dynamo bytecode transform time: 10.53 s
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f09d42884a0>' raised:
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1626385)[0;0m ERROR 12-04 14:35:24 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f980c81b980>' raised:
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1626382)[0;0m ERROR 12-04 14:35:24 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1626385)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1626382)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1626382)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1626382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1626385)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1626385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1626385)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1626385)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1626385)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f09d42884a0>' raised:
[1;36m(EngineCore_DP0 pid=1626385)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1626385)[0;0m 
[1;36m(EngineCore_DP0 pid=1626385)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1626385)[0;0m 
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1626382)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1626382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1626382)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1626382)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f980c81b980>' raised:
[1;36m(EngineCore_DP0 pid=1626382)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1626382)[0;0m 
[1;36m(EngineCore_DP0 pid=1626382)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1626382)[0;0m 
[rank0]:[W1204 14:35:24.361995504 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:35:24.361995531 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:35:46 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:35:46 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:35:46 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:35:46 [model.py:1745] Using max model len 131072
INFO 12-04 14:35:46 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:35:46 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:35:46 [model.py:1745] Using max model len 131072
INFO 12-04 14:35:46 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1628814)[0;0m INFO 12-04 14:36:09 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1628817)[0;0m INFO 12-04 14:36:09 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1628814)[0;0m INFO 12-04 14:36:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:39807 backend=nccl
[1;36m(EngineCore_DP0 pid=1628817)[0;0m INFO 12-04 14:36:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:56675 backend=nccl
[W1204 14:36:11.031277131 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:39807 (errno: 97 - Address family not supported by protocol).
[W1204 14:36:11.032774042 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:56675 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1628814)[0;0m INFO 12-04 14:36:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1628817)[0;0m INFO 12-04 14:36:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1628814)[0;0m INFO 12-04 14:36:12 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1628817)[0;0m INFO 12-04 14:36:12 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1628817)[0;0m INFO 12-04 14:36:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1628817)[0;0m INFO 12-04 14:36:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1628814)[0;0m INFO 12-04 14:36:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1628814)[0;0m INFO 12-04 14:36:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1628814)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1628817)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1628814)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.16s/it]
[1;36m(EngineCore_DP0 pid=1628817)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.15s/it]
[1;36m(EngineCore_DP0 pid=1628814)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=1628814)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
[1;36m(EngineCore_DP0 pid=1628814)[0;0m 
[1;36m(EngineCore_DP0 pid=1628814)[0;0m INFO 12-04 14:36:15 [default_loader.py:314] Loading weights took 1.65 seconds
[1;36m(EngineCore_DP0 pid=1628817)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
[1;36m(EngineCore_DP0 pid=1628817)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=1628817)[0;0m 
[1;36m(EngineCore_DP0 pid=1628817)[0;0m INFO 12-04 14:36:15 [default_loader.py:314] Loading weights took 1.66 seconds
[1;36m(EngineCore_DP0 pid=1628814)[0;0m INFO 12-04 14:36:15 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.848899 seconds
[1;36m(EngineCore_DP0 pid=1628817)[0;0m INFO 12-04 14:36:16 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.970736 seconds
[1;36m(EngineCore_DP0 pid=1628814)[0;0m INFO 12-04 14:36:26 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1628817)[0;0m INFO 12-04 14:36:26 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1628814)[0;0m INFO 12-04 14:36:26 [backends.py:647] Dynamo bytecode transform time: 10.54 s
[1;36m(EngineCore_DP0 pid=1628817)[0;0m INFO 12-04 14:36:26 [backends.py:647] Dynamo bytecode transform time: 10.42 s
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5fa8132c90>' raised:
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1628814)[0;0m ERROR 12-04 14:36:27 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fe2a8228cb0>' raised:
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1628817)[0;0m ERROR 12-04 14:36:27 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1628814)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1628817)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1628817)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1628817)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1628814)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1628814)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1628817)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1628814)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628814)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1628814)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1628814)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f5fa8132c90>' raised:
[1;36m(EngineCore_DP0 pid=1628814)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1628814)[0;0m 
[1;36m(EngineCore_DP0 pid=1628814)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1628814)[0;0m 
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1628817)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1628817)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1628817)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1628817)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7fe2a8228cb0>' raised:
[1;36m(EngineCore_DP0 pid=1628817)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1628817)[0;0m 
[1;36m(EngineCore_DP0 pid=1628817)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1628817)[0;0m 
[rank0]:[W1204 14:36:28.591813144 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:36:28.598738317 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:36:49 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:36:49 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:36:49 [model.py:1745] Using max model len 131072
INFO 12-04 14:36:49 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:36:49 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:36:49 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:36:49 [model.py:1745] Using max model len 131072
INFO 12-04 14:36:49 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=1630459)[0;0m INFO 12-04 14:37:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1630456)[0;0m INFO 12-04 14:37:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=1630459)[0;0m INFO 12-04 14:37:15 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:49063 backend=nccl
[1;36m(EngineCore_DP0 pid=1630456)[0;0m INFO 12-04 14:37:15 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.6:52815 backend=nccl
[W1204 14:37:15.598992940 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:49063 (errno: 97 - Address family not supported by protocol).
[W1204 14:37:15.599506727 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-21-1.rc.tch.harvard.edu]:52815 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1630456)[0;0m INFO 12-04 14:37:15 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1630459)[0;0m INFO 12-04 14:37:15 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1630459)[0;0m INFO 12-04 14:37:15 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1630456)[0;0m INFO 12-04 14:37:15 [gpu_model_runner.py:3259] Starting to load model meta-llama/Llama-3.2-3B-Instruct...
[1;36m(EngineCore_DP0 pid=1630459)[0;0m INFO 12-04 14:37:16 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1630459)[0;0m INFO 12-04 14:37:16 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1630456)[0;0m INFO 12-04 14:37:16 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=1630456)[0;0m INFO 12-04 14:37:16 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=1630459)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1630456)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1630459)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.10s/it]
[1;36m(EngineCore_DP0 pid=1630456)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.14s/it]
[1;36m(EngineCore_DP0 pid=1630459)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.41it/s]
[1;36m(EngineCore_DP0 pid=1630459)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
[1;36m(EngineCore_DP0 pid=1630459)[0;0m 
[1;36m(EngineCore_DP0 pid=1630459)[0;0m INFO 12-04 14:37:18 [default_loader.py:314] Loading weights took 1.57 seconds
[1;36m(EngineCore_DP0 pid=1630456)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.38it/s]
[1;36m(EngineCore_DP0 pid=1630456)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.27it/s]
[1;36m(EngineCore_DP0 pid=1630456)[0;0m 
[1;36m(EngineCore_DP0 pid=1630456)[0;0m INFO 12-04 14:37:19 [default_loader.py:314] Loading weights took 1.62 seconds
[1;36m(EngineCore_DP0 pid=1630459)[0;0m INFO 12-04 14:37:19 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 2.853654 seconds
[1;36m(EngineCore_DP0 pid=1630456)[0;0m INFO 12-04 14:37:19 [gpu_model_runner.py:3338] Model loading took 6.0160 GiB memory and 3.148285 seconds
[1;36m(EngineCore_DP0 pid=1630456)[0;0m INFO 12-04 14:37:30 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1630459)[0;0m INFO 12-04 14:37:30 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/f2c2b73eff/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1630456)[0;0m INFO 12-04 14:37:30 [backends.py:647] Dynamo bytecode transform time: 10.56 s
[1;36m(EngineCore_DP0 pid=1630459)[0;0m INFO 12-04 14:37:30 [backends.py:647] Dynamo bytecode transform time: 10.84 s
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f9510183020>' raised:
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1630459)[0;0m ERROR 12-04 14:37:31 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842]     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842] torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f7f9c2e2c60>' raised:
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842] RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1630456)[0;0m ERROR 12-04 14:37:31 [core.py:842] 
[1;36m(EngineCore_DP0 pid=1630459)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1630456)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1630459)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1630459)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 231, in _initialize_kv_caches
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[1;36m(EngineCore_DP0 pid=1630456)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     return self.collective_rpc("determine_available_memory")
[1;36m(EngineCore_DP0 pid=1630456)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/serial_utils.py", line 479, in run_method
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 324, in determine_available_memory
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     self.model_runner.profile_run()
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 4135, in profile_run
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m                                         ^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3855, in _dummy_run
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     outputs = self.model(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m               ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/cuda_graph.py", line 126, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     return self.runnable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     return self._call_impl(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     return forward_call(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 655, in forward
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     model_output = self.model(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m                    ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 471, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/wrapper.py", line 149, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     return self._compiled_callable(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2196, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     raise BackendCompilerFailed(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/output_graph.py", line 2171, in _call_user_compiler
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     compiled_fn = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py", line 156, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     compiled_gm = compiler_fn(gm, example_inputs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/__init__.py", line 2437, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     return self.compiler_fn(model_, inputs_, **self.kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 683, in __call__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     PiecewiseCompileInterpreter(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 404, in run
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     return super().run(*fake_args)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 174, in run
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     self.env[node] = self.run_node(node)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/fx/interpreter.py", line 256, in run_node
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     return getattr(self, n.op)(n.target, args, kwargs)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1630459)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630459)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1630459)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1630459)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f9510183020>' raised:
[1;36m(EngineCore_DP0 pid=1630459)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1630459)[0;0m 
[1;36m(EngineCore_DP0 pid=1630459)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1630459)[0;0m 
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 424, in call_module
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     self.vllm_backend.compiler_manager.compile(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 201, in compile
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     compiled_graph = self.load(graph, example_inputs, graph_index, runtime_shape)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/backends.py", line 161, in load
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     compiled_graph = self.compiler.load(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m                      ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/compiler_interface.py", line 260, in load
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     inductor_compiled_graph = torch._inductor.CompiledArtifact.load(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/_inductor/standalone_compile.py", line 131, in load
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     reader = BytesReader(artifacts)
[1;36m(EngineCore_DP0 pid=1630456)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1630456)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_appending_byte_serializer.py", line 55, in __init__
[1;36m(EngineCore_DP0 pid=1630456)[0;0m     raise RuntimeError(
[1;36m(EngineCore_DP0 pid=1630456)[0;0m torch._dynamo.exc.BackendCompilerFailed: backend='<vllm.compilation.backends.VllmBackend object at 0x7f7f9c2e2c60>' raised:
[1;36m(EngineCore_DP0 pid=1630456)[0;0m RuntimeError: Bytes object is corrupted, checksum does not match. Expected: b'\xf4<.\x1e', Got: b'\xf4/\xe3\x0f'
[1;36m(EngineCore_DP0 pid=1630456)[0;0m 
[1;36m(EngineCore_DP0 pid=1630456)[0;0m Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
[1;36m(EngineCore_DP0 pid=1630456)[0;0m 
[rank0]:[W1204 14:37:32.432530695 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:37:32.433248901 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:53 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: meta-llama/Llama-3.2-3B-Instruct (backend=vllm)
[ModelCache] Using max_model_len=131072 for meta-llama/Llama-3.2-3B-Instruct
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:53 [utils.py:253] non-default args: {'max_model_len': 131072, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'meta-llama/Llama-3.2-3B-Instruct'}
INFO 12-04 14:37:53 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:37:53 [model.py:1745] Using max model len 131072
INFO 12-04 14:37:53 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:37:53 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 12-04 14:37:53 [model.py:1745] Using max model len 131072
INFO 12-04 14:37:53 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
slurmstepd-gpu-21-1: error: *** STEP 12735859.0 ON gpu-21-1 CANCELLED AT 2025-12-04T14:38:17 ***
