Using persona diversity with 3 different personas
============================================================
Math Task - Multiagent Debate (NO COMPRESSION)
============================================================
Model: Qwen/Qwen3-14B
Persona diversity mode:
  Agent 1: an enigma machine operator whose primary filter is signal-to...
  Agent 2: a Zen master who communicates only through non-sequiturs, ko...
  Agent 3: a deep-sea volcanologist focused on extremes of pressure, he...
Agents: 3
Rounds: 3
Problems: 20
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================
Using persona diversity with 3 different personas
============================================================
Math Task - Multiagent Debate (NO COMPRESSION)
============================================================
Model: Qwen/Qwen3-14B
Persona diversity mode:
  Agent 1: an enigma machine operator whose primary filter is signal-to...
  Agent 2: a Zen master who communicates only through non-sequiturs, ko...
  Agent 3: a deep-sea volcanologist focused on extremes of pressure, he...
Agents: 3
Rounds: 3
Problems: 20
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================

--- Problem 1/20, Round 1, Agent 1/3 ---
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:29:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}

--- Problem 1/20, Round 1, Agent 1/3 ---
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:29:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:29:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:29:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:29:38 [model.py:1745] Using max model len 40960
INFO 12-04 09:29:38 [model.py:1745] Using max model len 40960
INFO 12-04 09:29:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:29:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2876504)[0;0m INFO 12-04 09:29:53 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2876508)[0;0m INFO 12-04 09:29:53 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2876504)[0;0m INFO 12-04 09:29:56 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55629 backend=nccl
[1;36m(EngineCore_DP0 pid=2876508)[0;0m INFO 12-04 09:29:56 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38571 backend=nccl
  0%|          | 0/20 [00:00<?, ?it/s][W1204 09:29:56.455758651 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55629 (errno: 97 - Address family not supported by protocol).
  0%|          | 0/20 [00:00<?, ?it/s][W1204 09:29:56.455758602 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38571 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2876508)[0;0m INFO 12-04 09:29:56 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2876504)[0;0m INFO 12-04 09:29:56 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2876504)[0;0m INFO 12-04 09:29:56 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2876508)[0;0m INFO 12-04 09:29:56 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2876508)[0;0m INFO 12-04 09:29:57 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2876508)[0;0m INFO 12-04 09:29:57 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2876504)[0;0m INFO 12-04 09:29:57 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2876504)[0;0m INFO 12-04 09:29:57 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m ERROR 12-04 09:29:58 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2876508 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m ERROR 12-04 09:29:58 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2876504 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876508)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876504)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876504)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876504)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876504)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876508)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876508)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876508)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876508)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876508)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2876504 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876504)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2876508 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:29:59.904498496 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:29:59.922061301 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:30:20 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:30:20 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:30:21 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:30:21 [model.py:1745] Using max model len 40960
INFO 12-04 09:30:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:30:21 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:30:21 [model.py:1745] Using max model len 40960
INFO 12-04 09:30:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2876717)[0;0m INFO 12-04 09:30:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2876716)[0;0m INFO 12-04 09:30:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2876716)[0;0m INFO 12-04 09:30:42 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42271 backend=nccl
[1;36m(EngineCore_DP0 pid=2876717)[0;0m INFO 12-04 09:30:42 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47007 backend=nccl
[W1204 09:30:42.754013689 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42271 (errno: 97 - Address family not supported by protocol).
[W1204 09:30:42.757861397 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47007 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2876716)[0;0m INFO 12-04 09:30:42 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2876717)[0;0m INFO 12-04 09:30:42 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2876716)[0;0m INFO 12-04 09:30:42 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2876717)[0;0m INFO 12-04 09:30:42 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2876716)[0;0m INFO 12-04 09:30:43 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2876716)[0;0m INFO 12-04 09:30:43 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2876717)[0;0m INFO 12-04 09:30:44 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2876717)[0;0m INFO 12-04 09:30:44 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m ERROR 12-04 09:30:44 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Process 2876717 has 20.02 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876716)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876716)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876716)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876716)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876716)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Process 2876717 has 20.02 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m ERROR 12-04 09:30:44 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2876716 has 24.33 GiB memory in use. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876717)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876717)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876717)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876717)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876717)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2876716 has 24.33 GiB memory in use. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:30:45.045976040 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:30:45.064847774 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:31:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:31:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:31:07 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:31:07 [model.py:1745] Using max model len 40960
INFO 12-04 09:31:07 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:31:07 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:31:07 [model.py:1745] Using max model len 40960
INFO 12-04 09:31:07 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2876846)[0;0m INFO 12-04 09:31:22 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2876849)[0;0m INFO 12-04 09:31:22 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2876846)[0;0m INFO 12-04 09:31:24 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:56925 backend=nccl
[1;36m(EngineCore_DP0 pid=2876849)[0;0m INFO 12-04 09:31:24 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:48047 backend=nccl
[W1204 09:31:24.019859173 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:56925 (errno: 97 - Address family not supported by protocol).
[W1204 09:31:24.019859177 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:48047 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2876849)[0;0m INFO 12-04 09:31:24 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2876846)[0;0m INFO 12-04 09:31:24 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2876846)[0;0m INFO 12-04 09:31:25 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2876849)[0;0m INFO 12-04 09:31:25 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2876846)[0;0m INFO 12-04 09:31:26 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2876846)[0;0m INFO 12-04 09:31:26 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2876849)[0;0m INFO 12-04 09:31:26 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2876849)[0;0m INFO 12-04 09:31:26 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m ERROR 12-04 09:31:27 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2876846 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m ERROR 12-04 09:31:27 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2876849 has 21.89 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876846)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876849)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876849)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876849)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876849)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876849)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2876846 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876846)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876846)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876846)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876846)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876846)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2876849 has 21.89 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:31:28.356027216 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:31:28.356027221 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:31:49 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:31:49 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:31:49 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:31:49 [model.py:1745] Using max model len 40960
INFO 12-04 09:31:49 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:31:49 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:31:49 [model.py:1745] Using max model len 40960
INFO 12-04 09:31:49 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2876979)[0;0m INFO 12-04 09:32:08 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2876982)[0;0m INFO 12-04 09:32:08 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2876979)[0;0m INFO 12-04 09:32:09 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34979 backend=nccl
[1;36m(EngineCore_DP0 pid=2876982)[0;0m INFO 12-04 09:32:09 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:57697 backend=nccl
[W1204 09:32:09.941466125 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:57697 (errno: 97 - Address family not supported by protocol).
[W1204 09:32:09.941589300 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34979 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2876979)[0;0m INFO 12-04 09:32:09 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2876982)[0;0m INFO 12-04 09:32:09 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2876979)[0;0m INFO 12-04 09:32:10 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2876982)[0;0m INFO 12-04 09:32:10 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2876979)[0;0m INFO 12-04 09:32:11 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2876979)[0;0m INFO 12-04 09:32:11 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2876982)[0;0m INFO 12-04 09:32:11 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2876982)[0;0m INFO 12-04 09:32:11 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m ERROR 12-04 09:32:12 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 2876979 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876982)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876982)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876982)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876982)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876982)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 2876979 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m ERROR 12-04 09:32:12 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2876982 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2876979)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2876979)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2876979)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2876979)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2876979)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2876982 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:32:12.277429215 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:32:12.298070414 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:32:34 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:32:34 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:32:34 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:32:34 [model.py:1745] Using max model len 40960
INFO 12-04 09:32:34 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:32:34 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:32:34 [model.py:1745] Using max model len 40960
INFO 12-04 09:32:34 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2877250)[0;0m INFO 12-04 09:32:50 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2877253)[0;0m INFO 12-04 09:32:50 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2877253)[0;0m INFO 12-04 09:32:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44905 backend=nccl
[1;36m(EngineCore_DP0 pid=2877250)[0;0m INFO 12-04 09:32:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:49703 backend=nccl
[W1204 09:32:51.106742379 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44905 (errno: 97 - Address family not supported by protocol).
[W1204 09:32:51.109907875 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:49703 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2877253)[0;0m INFO 12-04 09:32:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2877250)[0;0m INFO 12-04 09:32:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2877253)[0;0m INFO 12-04 09:32:52 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2877250)[0;0m INFO 12-04 09:32:52 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2877253)[0;0m INFO 12-04 09:32:53 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2877253)[0;0m INFO 12-04 09:32:53 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2877250)[0;0m INFO 12-04 09:32:53 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2877250)[0;0m INFO 12-04 09:32:53 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m ERROR 12-04 09:32:54 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2877253 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877250)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877250)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877250)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877250)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877250)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2877253 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m ERROR 12-04 09:32:54 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2877250 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877253)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877253)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877253)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877253)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877253)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2877250 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:32:55.373561487 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:32:55.374154213 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:33:16 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:33:16 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:33:16 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:33:16 [model.py:1745] Using max model len 40960
INFO 12-04 09:33:16 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:33:16 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:33:16 [model.py:1745] Using max model len 40960
INFO 12-04 09:33:16 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2877385)[0;0m INFO 12-04 09:33:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2877382)[0;0m INFO 12-04 09:33:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2877382)[0;0m INFO 12-04 09:33:37 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:35593 backend=nccl
[1;36m(EngineCore_DP0 pid=2877385)[0;0m INFO 12-04 09:33:37 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:48353 backend=nccl
[W1204 09:33:37.639252376 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:35593 (errno: 97 - Address family not supported by protocol).
[W1204 09:33:37.642713236 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:48353 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2877382)[0;0m INFO 12-04 09:33:37 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2877385)[0;0m INFO 12-04 09:33:37 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2877382)[0;0m INFO 12-04 09:33:37 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2877385)[0;0m INFO 12-04 09:33:37 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2877385)[0;0m INFO 12-04 09:33:38 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2877385)[0;0m INFO 12-04 09:33:38 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2877382)[0;0m INFO 12-04 09:33:38 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2877382)[0;0m INFO 12-04 09:33:38 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m ERROR 12-04 09:33:39 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2877385 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877382)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877382)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877382)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877382)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877382)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2877385 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m ERROR 12-04 09:33:39 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 2877382 has 20.63 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877385)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877385)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877385)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877385)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877385)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 2877382 has 20.63 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:33:40.915015894 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:33:40.937221893 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:34:01 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:34:01 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:34:02 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:34:02 [model.py:1745] Using max model len 40960
INFO 12-04 09:34:02 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:34:02 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:34:02 [model.py:1745] Using max model len 40960
INFO 12-04 09:34:02 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2877531)[0;0m INFO 12-04 09:34:16 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2877534)[0;0m INFO 12-04 09:34:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2877531)[0;0m INFO 12-04 09:34:18 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:39367 backend=nccl
[1;36m(EngineCore_DP0 pid=2877534)[0;0m INFO 12-04 09:34:18 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47005 backend=nccl
[W1204 09:34:18.149272601 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:39367 (errno: 97 - Address family not supported by protocol).
[W1204 09:34:18.150679994 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47005 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2877534)[0;0m INFO 12-04 09:34:18 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2877531)[0;0m INFO 12-04 09:34:18 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2877531)[0;0m INFO 12-04 09:34:19 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2877534)[0;0m INFO 12-04 09:34:19 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2877531)[0;0m INFO 12-04 09:34:20 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2877531)[0;0m INFO 12-04 09:34:20 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2877534)[0;0m INFO 12-04 09:34:20 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2877534)[0;0m INFO 12-04 09:34:20 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m ERROR 12-04 09:34:21 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2877531 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877534)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877534)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877534)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877534)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877534)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2877531 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m ERROR 12-04 09:34:21 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2877534 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877531)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877531)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877531)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877531)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877531)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2877534 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:34:22.467340746 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:34:22.481794927 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:34:43 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:34:43 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:34:43 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:34:43 [model.py:1745] Using max model len 40960
INFO 12-04 09:34:43 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:34:43 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:34:43 [model.py:1745] Using max model len 40960
INFO 12-04 09:34:43 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2877662)[0;0m INFO 12-04 09:35:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2877659)[0;0m INFO 12-04 09:35:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2877659)[0;0m INFO 12-04 09:35:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:36063 backend=nccl
[1;36m(EngineCore_DP0 pid=2877662)[0;0m INFO 12-04 09:35:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:46175 backend=nccl
[W1204 09:35:04.557739853 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:36063 (errno: 97 - Address family not supported by protocol).
[W1204 09:35:04.558608285 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:46175 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2877659)[0;0m INFO 12-04 09:35:04 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2877662)[0;0m INFO 12-04 09:35:04 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2877659)[0;0m INFO 12-04 09:35:04 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2877662)[0;0m INFO 12-04 09:35:04 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2877662)[0;0m INFO 12-04 09:35:05 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2877662)[0;0m INFO 12-04 09:35:05 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2877659)[0;0m INFO 12-04 09:35:05 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2877659)[0;0m INFO 12-04 09:35:05 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m ERROR 12-04 09:35:06 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2877659 has 21.89 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m ERROR 12-04 09:35:06 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2877662 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877662)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877662)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877662)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877662)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877662)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2877659 has 21.89 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877659)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877659)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877659)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877659)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877659)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2877662 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:35:07.842591175 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:35:07.843869406 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:35:28 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:35:28 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:35:29 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:35:29 [model.py:1745] Using max model len 40960
INFO 12-04 09:35:29 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:35:29 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:35:29 [model.py:1745] Using max model len 40960
INFO 12-04 09:35:29 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2877872)[0;0m INFO 12-04 09:35:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2877875)[0;0m INFO 12-04 09:35:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2877872)[0;0m INFO 12-04 09:35:46 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:49999 backend=nccl
[1;36m(EngineCore_DP0 pid=2877875)[0;0m INFO 12-04 09:35:46 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50225 backend=nccl
[W1204 09:35:46.626517632 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:49999 (errno: 97 - Address family not supported by protocol).
[W1204 09:35:46.626927884 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50225 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2877875)[0;0m INFO 12-04 09:35:46 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2877872)[0;0m INFO 12-04 09:35:46 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2877875)[0;0m INFO 12-04 09:35:46 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2877872)[0;0m INFO 12-04 09:35:46 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2877872)[0;0m INFO 12-04 09:35:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2877872)[0;0m INFO 12-04 09:35:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2877875)[0;0m INFO 12-04 09:35:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2877875)[0;0m INFO 12-04 09:35:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m ERROR 12-04 09:35:48 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2877875 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877872)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877872)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877872)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877872)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877872)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2877875 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m ERROR 12-04 09:35:48 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2877872 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2877875)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2877875)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2877875)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2877875)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2877875)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2877872 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:35:49.059372483 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:35:49.066911244 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:36:10 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:36:11 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:36:11 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:36:11 [model.py:1745] Using max model len 40960
INFO 12-04 09:36:11 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:36:11 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:36:11 [model.py:1745] Using max model len 40960
INFO 12-04 09:36:11 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2878004)[0;0m INFO 12-04 09:36:30 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878001)[0;0m INFO 12-04 09:36:30 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878001)[0;0m INFO 12-04 09:36:32 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:48899 backend=nccl
[1;36m(EngineCore_DP0 pid=2878004)[0;0m INFO 12-04 09:36:32 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45347 backend=nccl
[W1204 09:36:32.326957554 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:48899 (errno: 97 - Address family not supported by protocol).
[W1204 09:36:32.329841025 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45347 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878004)[0;0m INFO 12-04 09:36:32 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878001)[0;0m INFO 12-04 09:36:32 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2878004)[0;0m INFO 12-04 09:36:32 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878001)[0;0m INFO 12-04 09:36:32 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878004)[0;0m INFO 12-04 09:36:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878004)[0;0m INFO 12-04 09:36:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878001)[0;0m INFO 12-04 09:36:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878001)[0;0m INFO 12-04 09:36:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m ERROR 12-04 09:36:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 2878004 has 23.74 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878001)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878001)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878001)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878001)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878001)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 2878004 has 23.74 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m ERROR 12-04 09:36:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2878001 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878004)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878004)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878004)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878004)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2878001 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:36:35.504302730 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:36:35.532697793 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:36:56 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:36:56 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:36:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:36:56 [model.py:1745] Using max model len 40960
INFO 12-04 09:36:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:36:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:36:56 [model.py:1745] Using max model len 40960
INFO 12-04 09:36:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2878138)[0;0m INFO 12-04 09:37:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878141)[0;0m INFO 12-04 09:37:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878141)[0;0m INFO 12-04 09:37:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50735 backend=nccl
[1;36m(EngineCore_DP0 pid=2878138)[0;0m INFO 12-04 09:37:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34387 backend=nccl
[W1204 09:37:14.485945964 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34387 (errno: 97 - Address family not supported by protocol).
[W1204 09:37:14.485912686 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50735 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878138)[0;0m INFO 12-04 09:37:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2878141)[0;0m INFO 12-04 09:37:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2878141)[0;0m INFO 12-04 09:37:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878138)[0;0m INFO 12-04 09:37:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878138)[0;0m INFO 12-04 09:37:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878138)[0;0m INFO 12-04 09:37:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878141)[0;0m INFO 12-04 09:37:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878141)[0;0m INFO 12-04 09:37:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m ERROR 12-04 09:37:16 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 2878141 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878138)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878138)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878138)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878138)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878138)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 2878141 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m ERROR 12-04 09:37:16 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2878138 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878141)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878141)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878141)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878141)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878141)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2878138 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:37:17.736843324 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:37:17.736870579 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:37:38 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:37:38 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:37:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:37:38 [model.py:1745] Using max model len 40960
INFO 12-04 09:37:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:37:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:37:38 [model.py:1745] Using max model len 40960
INFO 12-04 09:37:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2878266)[0;0m INFO 12-04 09:37:55 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878263)[0;0m INFO 12-04 09:37:55 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878263)[0;0m INFO 12-04 09:37:57 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37961 backend=nccl
[1;36m(EngineCore_DP0 pid=2878266)[0;0m INFO 12-04 09:37:57 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44985 backend=nccl
[W1204 09:37:57.395752522 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37961 (errno: 97 - Address family not supported by protocol).
[W1204 09:37:57.400800694 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44985 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878263)[0;0m INFO 12-04 09:37:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878266)[0;0m INFO 12-04 09:37:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2878266)[0;0m INFO 12-04 09:37:57 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878263)[0;0m INFO 12-04 09:37:57 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878263)[0;0m INFO 12-04 09:37:58 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878263)[0;0m INFO 12-04 09:37:58 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878266)[0;0m INFO 12-04 09:37:58 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878266)[0;0m INFO 12-04 09:37:58 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m ERROR 12-04 09:37:59 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 2878266 has 20.65 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878263)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878263)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878263)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878263)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878263)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 2878266 has 20.65 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m ERROR 12-04 09:37:59 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2878263 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878266)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878266)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878266)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878266)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878266)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2878263 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:38:00.661473490 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:38:00.707356474 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:38:21 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:38:21 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:38:21 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:38:21 [model.py:1745] Using max model len 40960
INFO 12-04 09:38:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:38:21 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:38:21 [model.py:1745] Using max model len 40960
INFO 12-04 09:38:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2878410)[0;0m INFO 12-04 09:38:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878413)[0;0m INFO 12-04 09:38:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878410)[0;0m INFO 12-04 09:38:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:49993 backend=nccl
[1;36m(EngineCore_DP0 pid=2878413)[0;0m INFO 12-04 09:38:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44107 backend=nccl
[W1204 09:38:38.997935582 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:49993 (errno: 97 - Address family not supported by protocol).
[W1204 09:38:38.001816958 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44107 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878410)[0;0m INFO 12-04 09:38:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878413)[0;0m INFO 12-04 09:38:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2878410)[0;0m INFO 12-04 09:38:39 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878413)[0;0m INFO 12-04 09:38:39 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878410)[0;0m INFO 12-04 09:38:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878410)[0;0m INFO 12-04 09:38:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878413)[0;0m INFO 12-04 09:38:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878413)[0;0m INFO 12-04 09:38:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m ERROR 12-04 09:38:41 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2878410 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878413)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878413)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878413)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878413)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878413)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2878410 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m ERROR 12-04 09:38:41 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2878413 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878410)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878410)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878410)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878410)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878410)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2878413 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:38:41.253361168 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:38:41.261500119 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:39:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:39:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:39:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:39:03 [model.py:1745] Using max model len 40960
INFO 12-04 09:39:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:39:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:39:03 [model.py:1745] Using max model len 40960
INFO 12-04 09:39:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2878545)[0;0m INFO 12-04 09:39:22 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878542)[0;0m INFO 12-04 09:39:22 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878542)[0;0m INFO 12-04 09:39:24 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:52825 backend=nccl
[1;36m(EngineCore_DP0 pid=2878545)[0;0m INFO 12-04 09:39:24 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51311 backend=nccl
[W1204 09:39:24.597709996 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:52825 (errno: 97 - Address family not supported by protocol).
[W1204 09:39:24.598299727 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51311 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878542)[0;0m INFO 12-04 09:39:24 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878545)[0;0m INFO 12-04 09:39:24 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2878545)[0;0m INFO 12-04 09:39:24 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878542)[0;0m INFO 12-04 09:39:24 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878542)[0;0m INFO 12-04 09:39:25 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878542)[0;0m INFO 12-04 09:39:25 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878545)[0;0m INFO 12-04 09:39:25 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878545)[0;0m INFO 12-04 09:39:25 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m ERROR 12-04 09:39:26 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2878545 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878542)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878542)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878542)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878542)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878542)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2878545 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m ERROR 12-04 09:39:26 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2878542 has 21.27 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878545)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878545)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878545)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878545)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878545)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2878542 has 21.27 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:39:27.877455767 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:39:27.890999487 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:39:48 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:39:48 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:39:49 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:39:49 [model.py:1745] Using max model len 40960
INFO 12-04 09:39:49 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:39:49 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:39:49 [model.py:1745] Using max model len 40960
INFO 12-04 09:39:49 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2878677)[0;0m INFO 12-04 09:40:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878680)[0;0m INFO 12-04 09:40:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878680)[0;0m INFO 12-04 09:40:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37047 backend=nccl
[1;36m(EngineCore_DP0 pid=2878677)[0;0m INFO 12-04 09:40:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34849 backend=nccl
[W1204 09:40:06.529911145 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37047 (errno: 97 - Address family not supported by protocol).
[W1204 09:40:06.532548172 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34849 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878680)[0;0m INFO 12-04 09:40:06 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878677)[0;0m INFO 12-04 09:40:06 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2878677)[0;0m INFO 12-04 09:40:06 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878680)[0;0m INFO 12-04 09:40:06 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878677)[0;0m INFO 12-04 09:40:07 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878677)[0;0m INFO 12-04 09:40:07 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878680)[0;0m INFO 12-04 09:40:07 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878680)[0;0m INFO 12-04 09:40:07 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m ERROR 12-04 09:40:08 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2878680 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878677)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878677)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878677)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878677)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878677)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2878680 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m ERROR 12-04 09:40:08 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2878677 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878680)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878680)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878680)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878680)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878680)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2878677 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:40:09.896326080 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:40:09.905424656 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:40:30 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:40:30 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:40:31 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:40:31 [model.py:1745] Using max model len 40960
INFO 12-04 09:40:31 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:40:31 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:40:31 [model.py:1745] Using max model len 40960
INFO 12-04 09:40:31 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2878883)[0;0m INFO 12-04 09:40:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878886)[0;0m INFO 12-04 09:40:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2878883)[0;0m INFO 12-04 09:40:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:48899 backend=nccl
[1;36m(EngineCore_DP0 pid=2878886)[0;0m INFO 12-04 09:40:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:58103 backend=nccl
[W1204 09:40:51.634786543 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:48899 (errno: 97 - Address family not supported by protocol).
[W1204 09:40:51.636621670 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:58103 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878883)[0;0m INFO 12-04 09:40:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2878886)[0;0m INFO 12-04 09:40:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2878883)[0;0m INFO 12-04 09:40:51 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878886)[0;0m INFO 12-04 09:40:51 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2878886)[0;0m INFO 12-04 09:40:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878886)[0;0m INFO 12-04 09:40:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878883)[0;0m INFO 12-04 09:40:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2878883)[0;0m INFO 12-04 09:40:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m ERROR 12-04 09:40:53 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2878886 has 23.12 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878883)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878883)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878883)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878883)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878883)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2878886 has 23.12 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m ERROR 12-04 09:40:53 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2878883 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2878886)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2878886)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2878886)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2878886)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2878886)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2878883 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:40:54.883471676 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:40:54.894022641 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:41:15 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:41:15 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:41:16 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:41:16 [model.py:1745] Using max model len 40960
INFO 12-04 09:41:16 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:41:16 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:41:16 [model.py:1745] Using max model len 40960
INFO 12-04 09:41:16 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2879017)[0;0m INFO 12-04 09:41:32 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879014)[0;0m INFO 12-04 09:41:32 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879017)[0;0m INFO 12-04 09:41:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:53817 backend=nccl
[1;36m(EngineCore_DP0 pid=2879014)[0;0m INFO 12-04 09:41:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37827 backend=nccl
[W1204 09:41:34.466854805 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:53817 (errno: 97 - Address family not supported by protocol).
[W1204 09:41:34.468583660 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37827 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879017)[0;0m INFO 12-04 09:41:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879014)[0;0m INFO 12-04 09:41:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2879017)[0;0m INFO 12-04 09:41:34 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879014)[0;0m INFO 12-04 09:41:34 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879014)[0;0m INFO 12-04 09:41:35 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879014)[0;0m INFO 12-04 09:41:35 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879017)[0;0m INFO 12-04 09:41:35 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879017)[0;0m INFO 12-04 09:41:35 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m ERROR 12-04 09:41:36 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2879014 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879017)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879017)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879017)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879017)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879017)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2879014 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m ERROR 12-04 09:41:36 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2879017 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879014)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879014)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879014)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879014)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879014)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2879017 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:41:37.854213372 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:41:37.861945657 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:41:58 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:41:58 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:41:58 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:41:58 [model.py:1745] Using max model len 40960
INFO 12-04 09:41:58 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:41:59 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:41:59 [model.py:1745] Using max model len 40960
INFO 12-04 09:41:59 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2879151)[0;0m INFO 12-04 09:42:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879154)[0;0m INFO 12-04 09:42:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879151)[0;0m INFO 12-04 09:42:20 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38411 backend=nccl
[1;36m(EngineCore_DP0 pid=2879154)[0;0m INFO 12-04 09:42:20 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44547 backend=nccl
[W1204 09:42:20.623337311 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38411 (errno: 97 - Address family not supported by protocol).
[W1204 09:42:20.626606441 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44547 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879154)[0;0m INFO 12-04 09:42:20 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879151)[0;0m INFO 12-04 09:42:20 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2879151)[0;0m INFO 12-04 09:42:20 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879154)[0;0m INFO 12-04 09:42:20 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879151)[0;0m INFO 12-04 09:42:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879151)[0;0m INFO 12-04 09:42:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879154)[0;0m INFO 12-04 09:42:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879154)[0;0m INFO 12-04 09:42:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m ERROR 12-04 09:42:22 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2879154 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879151)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879151)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879151)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879151)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879151)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2879154 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m ERROR 12-04 09:42:22 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2879151 has 21.89 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879154)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879154)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879154)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879154)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879154)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2879151 has 21.89 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:42:23.934900003 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:42:23.991050433 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:42:44 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:42:44 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:42:45 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:42:45 [model.py:1745] Using max model len 40960
INFO 12-04 09:42:45 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:42:45 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:42:45 [model.py:1745] Using max model len 40960
INFO 12-04 09:42:45 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2879279)[0;0m INFO 12-04 09:43:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879276)[0;0m INFO 12-04 09:43:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879279)[0;0m INFO 12-04 09:43:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:46385 backend=nccl
[1;36m(EngineCore_DP0 pid=2879276)[0;0m INFO 12-04 09:43:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44797 backend=nccl
[W1204 09:43:02.467853796 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:46385 (errno: 97 - Address family not supported by protocol).
[W1204 09:43:02.467789652 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44797 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879279)[0;0m INFO 12-04 09:43:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879276)[0;0m INFO 12-04 09:43:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2879279)[0;0m INFO 12-04 09:43:02 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879276)[0;0m INFO 12-04 09:43:02 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879279)[0;0m INFO 12-04 09:43:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879279)[0;0m INFO 12-04 09:43:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879276)[0;0m INFO 12-04 09:43:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879276)[0;0m INFO 12-04 09:43:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m ERROR 12-04 09:43:04 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2879279 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879276)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879276)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879276)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879276)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879276)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2879279 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m ERROR 12-04 09:43:04 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2879276 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879279)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879279)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879279)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879279)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879279)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2879276 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:43:05.779418126 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:43:05.786493999 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:43:26 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:43:26 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:43:26 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:43:26 [model.py:1745] Using max model len 40960
INFO 12-04 09:43:26 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:43:26 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:43:26 [model.py:1745] Using max model len 40960
INFO 12-04 09:43:26 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2879424)[0;0m INFO 12-04 09:43:46 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879427)[0;0m INFO 12-04 09:43:46 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879427)[0;0m INFO 12-04 09:43:48 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:49647 backend=nccl
[1;36m(EngineCore_DP0 pid=2879424)[0;0m INFO 12-04 09:43:48 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55955 backend=nccl
[W1204 09:43:48.404558975 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:49647 (errno: 97 - Address family not supported by protocol).
[W1204 09:43:48.407490258 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55955 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879427)[0;0m INFO 12-04 09:43:48 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879424)[0;0m INFO 12-04 09:43:48 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2879424)[0;0m INFO 12-04 09:43:48 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879427)[0;0m INFO 12-04 09:43:48 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879427)[0;0m INFO 12-04 09:43:49 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879427)[0;0m INFO 12-04 09:43:49 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879424)[0;0m INFO 12-04 09:43:49 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879424)[0;0m INFO 12-04 09:43:49 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m ERROR 12-04 09:43:50 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2879427 has 23.12 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879424)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879424)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879424)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879424)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879424)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2879427 has 23.12 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m ERROR 12-04 09:43:50 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2879424 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879427)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879427)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879427)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879427)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879427)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2879424 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:43:51.619874419 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:43:51.633325701 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:44:12 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:44:12 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:44:12 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:44:12 [model.py:1745] Using max model len 40960
INFO 12-04 09:44:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:44:12 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:44:12 [model.py:1745] Using max model len 40960
INFO 12-04 09:44:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2879566)[0;0m INFO 12-04 09:44:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879569)[0;0m INFO 12-04 09:44:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879569)[0;0m INFO 12-04 09:44:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45533 backend=nccl
[1;36m(EngineCore_DP0 pid=2879566)[0;0m INFO 12-04 09:44:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:59545 backend=nccl
[W1204 09:44:30.666565038 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45533 (errno: 97 - Address family not supported by protocol).
[W1204 09:44:30.667642415 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:59545 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879566)[0;0m INFO 12-04 09:44:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879569)[0;0m INFO 12-04 09:44:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2879566)[0;0m INFO 12-04 09:44:30 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879569)[0;0m INFO 12-04 09:44:30 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879569)[0;0m INFO 12-04 09:44:31 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879569)[0;0m INFO 12-04 09:44:31 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879566)[0;0m INFO 12-04 09:44:31 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879566)[0;0m INFO 12-04 09:44:31 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m ERROR 12-04 09:44:32 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2879566 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879569)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879569)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879569)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879569)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879569)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2879566 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m ERROR 12-04 09:44:32 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2879569 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879566)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879566)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879566)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879566)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879566)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2879569 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:44:33.031387201 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:44:33.038686622 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:44:54 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:44:55 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:44:55 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:44:55 [model.py:1745] Using max model len 40960
INFO 12-04 09:44:55 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:44:55 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:44:55 [model.py:1745] Using max model len 40960
INFO 12-04 09:44:55 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2879716)[0;0m INFO 12-04 09:45:13 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879719)[0;0m INFO 12-04 09:45:13 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879719)[0;0m INFO 12-04 09:45:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:43689 backend=nccl
[1;36m(EngineCore_DP0 pid=2879716)[0;0m INFO 12-04 09:45:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:39013 backend=nccl
[W1204 09:45:14.090641417 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:43689 (errno: 97 - Address family not supported by protocol).
[W1204 09:45:14.093700553 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:39013 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879719)[0;0m INFO 12-04 09:45:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879716)[0;0m INFO 12-04 09:45:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2879716)[0;0m INFO 12-04 09:45:15 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879719)[0;0m INFO 12-04 09:45:15 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879716)[0;0m INFO 12-04 09:45:16 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879716)[0;0m INFO 12-04 09:45:16 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879719)[0;0m INFO 12-04 09:45:16 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879719)[0;0m INFO 12-04 09:45:16 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m ERROR 12-04 09:45:17 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2879716 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879719)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879719)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879719)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879719)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879719)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2879716 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m ERROR 12-04 09:45:17 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 2879719 has 20.66 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879716)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879716)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879716)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879716)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879716)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 2879719 has 20.66 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:45:18.332622110 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:45:18.356634755 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:45:39 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:45:39 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:45:39 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:45:39 [model.py:1745] Using max model len 40960
INFO 12-04 09:45:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:45:39 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:45:39 [model.py:1745] Using max model len 40960
INFO 12-04 09:45:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2879974)[0;0m INFO 12-04 09:45:55 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879977)[0;0m INFO 12-04 09:45:55 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2879977)[0;0m INFO 12-04 09:45:56 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55639 backend=nccl
[1;36m(EngineCore_DP0 pid=2879974)[0;0m INFO 12-04 09:45:56 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:41601 backend=nccl
[W1204 09:45:56.274026935 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55639 (errno: 97 - Address family not supported by protocol).
[W1204 09:45:56.277627089 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:41601 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879977)[0;0m INFO 12-04 09:45:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2879974)[0;0m INFO 12-04 09:45:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2879974)[0;0m INFO 12-04 09:45:57 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879977)[0;0m INFO 12-04 09:45:57 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2879974)[0;0m INFO 12-04 09:45:58 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879974)[0;0m INFO 12-04 09:45:58 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879977)[0;0m INFO 12-04 09:45:58 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2879977)[0;0m INFO 12-04 09:45:58 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m ERROR 12-04 09:45:59 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2879977 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879974)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879974)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879974)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879974)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879974)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2879977 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m ERROR 12-04 09:45:59 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 2879974 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2879977)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2879977)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2879977)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2879977)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2879977)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 2879974 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 09:46:00.502261009 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 09:46:00.540074607 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:46:21 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:46:21 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:46:21 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:46:21 [model.py:1745] Using max model len 40960
INFO 12-04 09:46:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 09:46:21 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:46:21 [model.py:1745] Using max model len 40960
INFO 12-04 09:46:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:46:37 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:46:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:59663 backend=nccl
[W1204 09:46:38.796202837 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:59663 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:46:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:46:38 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:46:39 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:46:39 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/8 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=2880151)[0;0m INFO 12-04 09:46:46 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Loading safetensors checkpoint shards:  12% Completed | 1/8 [00:07<00:51,  7.34s/it]
[1;36m(EngineCore_DP0 pid=2880151)[0;0m INFO 12-04 09:46:48 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:54665 backend=nccl
[W1204 09:46:48.579490963 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:54665 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880151)[0;0m INFO 12-04 09:46:48 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ERROR 12-04 09:46:48 [core.py:842] ValueError: Free memory on device (15.75/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880151)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880151)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880151)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880151)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880151)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880151)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880151)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880151)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880151)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880151)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880151)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880151)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880151)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880151)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880151)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880151)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880151)[0;0m ValueError: Free memory on device (15.75/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:46:49.496434178 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Loading safetensors checkpoint shards:  25% Completed | 2/8 [00:14<00:44,  7.34s/it]
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Loading safetensors checkpoint shards:  38% Completed | 3/8 [00:22<00:37,  7.42s/it]
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:47:10 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:47:10 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:47:10 [model.py:1745] Using max model len 40960
INFO 12-04 09:47:10 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Loading safetensors checkpoint shards:  50% Completed | 4/8 [00:30<00:30,  7.71s/it]
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Loading safetensors checkpoint shards:  62% Completed | 5/8 [00:38<00:23,  7.87s/it]
[1;36m(EngineCore_DP0 pid=2880271)[0;0m INFO 12-04 09:47:23 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880271)[0;0m INFO 12-04 09:47:25 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:53899 backend=nccl
[W1204 09:47:25.545740950 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:53899 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880271)[0;0m INFO 12-04 09:47:25 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ERROR 12-04 09:47:25 [core.py:842] ValueError: Free memory on device (15.75/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880271)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880271)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880271)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880271)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880271)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880271)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880271)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880271)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880271)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880271)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880271)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880271)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880271)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880271)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880271)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880271)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880271)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880271)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880271)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880271)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880271)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880271)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880271)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880271)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880271)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880271)[0;0m ValueError: Free memory on device (15.75/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:47:26.517859693 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Loading safetensors checkpoint shards:  75% Completed | 6/8 [00:46<00:15,  7.81s/it]
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Loading safetensors checkpoint shards:  88% Completed | 7/8 [00:54<00:07,  7.93s/it]
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Loading safetensors checkpoint shards: 100% Completed | 8/8 [00:58<00:00,  6.71s/it]
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Loading safetensors checkpoint shards: 100% Completed | 8/8 [00:58<00:00,  7.31s/it]
[1;36m(EngineCore_DP0 pid=2880143)[0;0m 
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:47:39 [default_loader.py:314] Loading weights took 58.53 seconds
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:47:39 [gpu_model_runner.py:3338] Model loading took 27.5185 GiB memory and 60.131666 seconds
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:47:47 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:47:47 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:47:47 [model.py:1745] Using max model len 40960
INFO 12-04 09:47:47 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:47:53 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/d7ea762554/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:47:53 [backends.py:647] Dynamo bytecode transform time: 12.96 s
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:48:02 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.034 s
[1;36m(EngineCore_DP0 pid=2880334)[0;0m INFO 12-04 09:48:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:48:05 [monitor.py:34] torch.compile takes 21.00 s in total
[1;36m(EngineCore_DP0 pid=2880334)[0;0m INFO 12-04 09:48:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:52343 backend=nccl
[W1204 09:48:06.490900465 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:52343 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880334)[0;0m INFO 12-04 09:48:06 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ERROR 12-04 09:48:06 [core.py:842] ValueError: Free memory on device (13.61/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880334)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880334)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880334)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880334)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880334)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880334)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880334)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880334)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880334)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880334)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880334)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880334)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880334)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880334)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880334)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880334)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880334)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880334)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880334)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880334)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880334)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880334)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880334)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880334)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880334)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880334)[0;0m ValueError: Free memory on device (13.61/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:48:07.662232411 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:48:07 [gpu_worker.py:359] Available KV cache memory: 10.44 GiB
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:48:07 [kv_cache_utils.py:1229] GPU KV cache size: 68,416 tokens
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:48:07 [kv_cache_utils.py:1234] Maximum concurrency for 40,960 tokens per request: 1.67x
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:06,  8.22it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:06,  7.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:05,  8.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:00<00:04,  9.49it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:00<00:04,  9.84it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:00<00:04, 10.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:01<00:03, 10.62it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:01<00:03, 11.00it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:01<00:03, 11.20it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:01<00:03, 11.31it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:01<00:02, 11.60it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:01<00:02, 11.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:02<00:02, 11.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 25/51 [00:02<00:02, 12.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:02<00:01, 12.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:02<00:01, 12.89it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:02<00:01, 12.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:02<00:01, 13.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:02<00:01, 13.43it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:03<00:01, 13.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:03<00:00, 13.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:03<00:00, 13.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:03<00:00, 14.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 45/51 [00:03<00:00, 14.30it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:03<00:00, 14.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 49/51 [00:03<00:00, 14.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:04<00:00, 14.67it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:04<00:00, 12.45it/s]
[1;36m(EngineCore_DP0 pid=2880143)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:02, 13.46it/s]Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:02, 13.79it/s]Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:02, 13.96it/s]Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:00<00:01, 14.10it/s]Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:00<00:01, 14.24it/s]Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:00<00:01, 14.39it/s]Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:00<00:01, 14.34it/s]Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:01<00:01, 14.38it/s]Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:01<00:01, 14.61it/s]Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:01<00:01, 14.77it/s]Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:01<00:00, 14.91it/s]Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:01<00:00, 15.09it/s]Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:01<00:00, 15.22it/s]Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:01<00:00, 15.46it/s]Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:02<00:00, 15.60it/s]Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:02<00:00, 15.99it/s]Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:02<00:00, 16.20it/s]Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:02<00:00, 15.08it/s]
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:48:14 [gpu_model_runner.py:4244] Graph capturing finished in 7 secs, took 0.15 GiB
[1;36m(EngineCore_DP0 pid=2880143)[0;0m INFO 12-04 09:48:14 [core.py:250] init engine (profile, create kv cache, warmup model) took 35.06 seconds
INFO 12-04 09:48:16 [llm.py:352] Supported tasks: ['generate']

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 628.17it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:48:28 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:48:28 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:48:28 [model.py:1745] Using max model len 40960
INFO 12-04 09:48:28 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2880423)[0;0m INFO 12-04 09:48:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880423)[0;0m INFO 12-04 09:48:42 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:40603 backend=nccl
[W1204 09:48:42.364422287 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:40603 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880423)[0;0m INFO 12-04 09:48:42 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ERROR 12-04 09:48:42 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880423)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880423)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880423)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880423)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880423)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880423)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880423)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880423)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880423)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880423)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880423)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880423)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880423)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880423)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880423)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880423)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880423)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880423)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880423)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880423)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880423)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880423)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880423)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880423)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880423)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880423)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:48:42.191591870 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.75s/it, est. speed input: 2.26 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.75s/it, est. speed input: 2.26 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.75s/it, est. speed input: 2.26 toks/s, output: 25.13 toks/s]
Agent 1 response: The solution involves following the order of operations (PEMDAS/BODMAS):  
1. Multiply: 19 * 28 = 53...

--- Problem 1/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1352.56it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:49:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:49:04 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:49:04 [model.py:1745] Using max model len 40960
INFO 12-04 09:49:04 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.84s/it, est. speed input: 3.93 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.84s/it, est. speed input: 3.93 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.84s/it, est. speed input: 3.93 toks/s, output: 25.20 toks/s]
Agent 2 response: Why do clouds drift? Because they are not bound by calculation. The answer is 482....

--- Problem 1/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1031.30it/s]

[1;36m(EngineCore_DP0 pid=2880485)[0;0m INFO 12-04 09:49:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880485)[0;0m INFO 12-04 09:49:18 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50697 backend=nccl
[W1204 09:49:18.908518209 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50697 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880485)[0;0m INFO 12-04 09:49:18 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ERROR 12-04 09:49:18 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880485)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880485)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880485)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880485)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880485)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880485)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880485)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880485)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880485)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880485)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880485)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880485)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880485)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880485)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880485)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880485)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:49:19.729848387 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.93s/it, est. speed input: 4.71 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.93s/it, est. speed input: 4.71 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.93s/it, est. speed input: 4.71 toks/s, output: 25.11 toks/s]
Agent 3 response: The result of 6 + 19*28 + 14 - 10*7 is calculated by following the order of operations. First, perfo...

--- Problem 1/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 661.88it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:49:40 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:49:40 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:49:40 [model.py:1745] Using max model len 40960
INFO 12-04 09:49:40 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.22s/it, est. speed input: 23.44 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.22s/it, est. speed input: 23.44 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.22s/it, est. speed input: 23.44 toks/s, output: 25.14 toks/s]
Agent 1 response: Following the order of operations (PEMDAS/BODMAS), the calculation proceeds as:  
1. Multiply: 19 × ...

--- Problem 1/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 637.04it/s]

[1;36m(EngineCore_DP0 pid=2880542)[0;0m INFO 12-04 09:49:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880542)[0;0m INFO 12-04 09:49:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:53523 backend=nccl
[W1204 09:49:53.580290146 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:53523 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880542)[0;0m INFO 12-04 09:49:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ERROR 12-04 09:49:53 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880542)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880542)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880542)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880542)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880542)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880542)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880542)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880542)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880542)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880542)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880542)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880542)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880542)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880542)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880542)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880542)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880542)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:49:54.402234754 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.46s/it, est. speed input: 27.87 toks/s, output: 25.03 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.46s/it, est. speed input: 27.87 toks/s, output: 25.03 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.46s/it, est. speed input: 27.87 toks/s, output: 25.03 toks/s]
Agent 2 response: What is the sound of one hand clapping? Silence. The answer is 482....

--- Problem 1/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 798.31it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:50:15 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:50:15 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:50:15 [model.py:1745] Using max model len 40960
INFO 12-04 09:50:15 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.47s/it, est. speed input: 18.24 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.47s/it, est. speed input: 18.24 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.47s/it, est. speed input: 18.24 toks/s, output: 25.14 toks/s]
Agent 3 response: The calculation follows the order of operations (PEMDAS/BODMAS):  
1. Multiply: $19 \times 28 = 532$...

--- Problem 1/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 451.97it/s]

[1;36m(EngineCore_DP0 pid=2880679)[0;0m INFO 12-04 09:50:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880679)[0;0m INFO 12-04 09:50:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:40757 backend=nccl
[W1204 09:50:29.158703996 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:40757 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880679)[0;0m INFO 12-04 09:50:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ERROR 12-04 09:50:30 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880679)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880679)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880679)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880679)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880679)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880679)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880679)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880679)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880679)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880679)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880679)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880679)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880679)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880679)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880679)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880679)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880679)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880679)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880679)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880679)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880679)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880679)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880679)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880679)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880679)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880679)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:50:30.978523164 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.65s/it, est. speed input: 45.89 toks/s, output: 25.05 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.65s/it, est. speed input: 45.89 toks/s, output: 25.05 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.65s/it, est. speed input: 45.89 toks/s, output: 25.05 toks/s]
Agent 1 response: Following the order of operations (PEMDAS/BODMAS):  
1. Multiply: $19 \times 28 = 532$ and $10 \time...

--- Problem 1/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 555.68it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.41s/it, est. speed input: 61.89 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.41s/it, est. speed input: 61.89 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.41s/it, est. speed input: 61.89 toks/s, output: 25.14 toks/s]
Agent 2 response: What is the number that remains when all equations are silent? The answer is 482....

--- Problem 1/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 539.60it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:50:51 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:50:51 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:50:51 [model.py:1745] Using max model len 40960
INFO 12-04 09:50:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2880743)[0;0m INFO 12-04 09:51:03 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880743)[0;0m INFO 12-04 09:51:05 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:58189 backend=nccl
[W1204 09:51:05.560244791 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:58189 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880743)[0;0m INFO 12-04 09:51:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ERROR 12-04 09:51:05 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880743)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880743)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880743)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880743)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880743)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880743)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880743)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880743)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880743)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880743)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880743)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880743)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880743)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880743)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880743)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880743)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:51:06.380648424 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.88s/it, est. speed input: 36.63 toks/s, output: 25.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.88s/it, est. speed input: 36.63 toks/s, output: 25.00 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.88s/it, est. speed input: 36.63 toks/s, output: 25.00 toks/s]
Agent 3 response: The calculation follows the order of operations (PEMDAS/BODMAS):  
1. Multiply: $19 \times 28 = 532$...
performance: 0.0 0.0

--- Problem 2/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
  5%|▌         | 1/20 [21:59<6:57:50, 1319.49s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1485.76it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:51:27 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:51:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:51:27 [model.py:1745] Using max model len 40960
INFO 12-04 09:51:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.67s/it, est. speed input: 3.81 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.67s/it, est. speed input: 3.81 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.67s/it, est. speed input: 3.81 toks/s, output: 25.22 toks/s]
Agent 1 response: The result is calculated as follows:  
First, perform multiplications: 20*6 = 120 and 18*22 = 396.  ...

--- Problem 2/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1124.78it/s]

[1;36m(EngineCore_DP0 pid=2880801)[0;0m INFO 12-04 09:51:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880801)[0;0m INFO 12-04 09:51:42 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50325 backend=nccl
[W1204 09:51:42.529218052 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50325 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880801)[0;0m INFO 12-04 09:51:42 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ERROR 12-04 09:51:42 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880801)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880801)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880801)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880801)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880801)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880801)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880801)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880801)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880801)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880801)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880801)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880801)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880801)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880801)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880801)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880801)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880801)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880801)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880801)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880801)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880801)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880801)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880801)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880801)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880801)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880801)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:51:43.354772840 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:52:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:52:04 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:52:04 [model.py:1745] Using max model len 40960
INFO 12-04 09:52:04 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.93s/it, est. speed input: 2.40 toks/s, output: 25.17 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.93s/it, est. speed input: 2.40 toks/s, output: 25.17 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.93s/it, est. speed input: 2.40 toks/s, output: 25.17 toks/s]
Agent 2 response: The weight of the sky. A shadow without light. Numbers are not doors. Answer: -223....

--- Problem 2/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1582.76it/s]

[1;36m(EngineCore_DP0 pid=2880862)[0;0m INFO 12-04 09:52:15 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880862)[0;0m INFO 12-04 09:52:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42237 backend=nccl
[W1204 09:52:16.057519020 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42237 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880862)[0;0m INFO 12-04 09:52:16 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ERROR 12-04 09:52:17 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880862)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880862)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880862)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880862)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880862)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880862)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880862)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880862)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880862)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880862)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880862)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880862)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880862)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880862)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880862)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880862)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:52:17.874779024 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.91s/it, est. speed input: 4.02 toks/s, output: 25.12 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.91s/it, est. speed input: 4.02 toks/s, output: 25.12 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.91s/it, est. speed input: 4.02 toks/s, output: 25.12 toks/s]
Agent 3 response: To solve the expression **28 + 20*6 + 25 - 18*22** systematically:  
1. Perform multiplications firs...

--- Problem 2/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 737.01it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.57s/it, est. speed input: 32.20 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.57s/it, est. speed input: 32.20 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.57s/it, est. speed input: 32.20 toks/s, output: 25.20 toks/s]
Agent 1 response: The calculation follows standard order of operations: multiplication first, then addition/subtractio...

--- Problem 2/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 781.21it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:52:38 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:52:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:52:38 [model.py:1745] Using max model len 40960
INFO 12-04 09:52:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2880914)[0;0m INFO 12-04 09:52:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880914)[0;0m INFO 12-04 09:52:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55965 backend=nccl
[W1204 09:52:53.318210865 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55965 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880914)[0;0m INFO 12-04 09:52:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ERROR 12-04 09:52:53 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880914)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880914)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880914)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880914)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880914)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880914)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880914)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880914)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880914)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880914)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880914)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880914)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880914)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880914)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880914)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880914)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880914)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880914)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880914)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880914)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880914)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880914)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880914)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880914)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880914)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880914)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:52:53.146037485 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.50s/it, est. speed input: 25.20 toks/s, output: 25.03 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.50s/it, est. speed input: 25.20 toks/s, output: 25.03 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.50s/it, est. speed input: 25.20 toks/s, output: 25.03 toks/s]
Agent 2 response: A cloud dissolves into the wind. A bell rings in silence. The path is not the destination. Answer: -...

--- Problem 2/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 791.23it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.49s/it, est. speed input: 22.48 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.49s/it, est. speed input: 22.48 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.49s/it, est. speed input: 22.48 toks/s, output: 25.20 toks/s]
Agent 3 response: The calculation remains consistent with prior responses. Following order of operations:  
1. Multipl...

--- Problem 2/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 524.81it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:53:14 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:53:14 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:53:14 [model.py:1745] Using max model len 40960
INFO 12-04 09:53:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2880978)[0;0m INFO 12-04 09:53:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2880978)[0;0m INFO 12-04 09:53:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44331 backend=nccl
[W1204 09:53:27.963052658 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44331 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2880978)[0;0m INFO 12-04 09:53:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ERROR 12-04 09:53:27 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2880978)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2880978)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2880978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2880978)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2880978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2880978)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2880978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880978)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2880978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2880978)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2880978)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2880978)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2880978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2880978)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2880978)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2880978)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2880978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2880978)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2880978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2880978)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2880978)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2880978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2880978)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2880978)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:53:28.781091901 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.42s/it, est. speed input: 41.70 toks/s, output: 24.98 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.42s/it, est. speed input: 41.70 toks/s, output: 24.98 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.42s/it, est. speed input: 41.70 toks/s, output: 24.98 toks/s]
Agent 1 response: The calculation aligns with established methods: priority to multiplication (20×6=120, 18×22=396), t...

--- Problem 2/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 550.22it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:53:49 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:53:49 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:53:49 [model.py:1745] Using max model len 40960
INFO 12-04 09:53:49 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.06s/it, est. speed input: 45.25 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.06s/it, est. speed input: 45.25 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.06s/it, est. speed input: 45.25 toks/s, output: 25.09 toks/s]
Agent 2 response: A pebble in the stream. The moon reflects in water. Silence holds the flame. Answer: -223....

--- Problem 2/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 320.64it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.51s/it, est. speed input: 52.98 toks/s, output: 24.94 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.51s/it, est. speed input: 52.98 toks/s, output: 24.94 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.51s/it, est. speed input: 52.98 toks/s, output: 24.94 toks/s]
Agent 3 response: The calculation confirms the result through standard order of operations:  
1. Multiplications: 20×6...
performance: 0.5 0.35355339059327373

--- Problem 3/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 10%|█         | 2/20 [24:51<3:13:21, 644.54s/it] 
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1165.73it/s]

[1;36m(EngineCore_DP0 pid=2881070)[0;0m INFO 12-04 09:54:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2881070)[0;0m INFO 12-04 09:54:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38815 backend=nccl
[W1204 09:54:06.340016720 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38815 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881070)[0;0m INFO 12-04 09:54:06 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ERROR 12-04 09:54:06 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881070)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881070)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881070)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881070)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881070)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881070)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881070)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881070)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881070)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881070)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881070)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881070)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881070)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881070)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881070)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881070)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881070)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881070)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881070)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881070)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881070)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881070)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881070)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881070)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881070)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881070)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:54:06.179024104 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.39s/it, est. speed input: 4.81 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.39s/it, est. speed input: 4.81 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.39s/it, est. speed input: 4.81 toks/s, output: 25.14 toks/s]
Agent 1 response: The result of the expression is calculated by following the order of operations (multiplication befo...

--- Problem 3/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1586.95it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:54:27 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:54:28 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:54:28 [model.py:1745] Using max model len 40960
INFO 12-04 09:54:28 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.65s/it, est. speed input: 7.32 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.65s/it, est. speed input: 7.32 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.65s/it, est. speed input: 7.32 toks/s, output: 25.15 toks/s]
Agent 2 response: The moon does not question the tide. The wave replies with silence. 239....

--- Problem 3/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1111.37it/s]

[1;36m(EngineCore_DP0 pid=2881128)[0;0m INFO 12-04 09:54:39 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2881128)[0;0m INFO 12-04 09:54:41 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51623 backend=nccl
[W1204 09:54:41.830749128 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51623 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881128)[0;0m INFO 12-04 09:54:41 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ERROR 12-04 09:54:41 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881128)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881128)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881128)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881128)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881128)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881128)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881128)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881128)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881128)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881128)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881128)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881128)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881128)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881128)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881128)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881128)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881128)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881128)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881128)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881128)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881128)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881128)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881128)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881128)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881128)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881128)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:54:42.668363553 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.78s/it, est. speed input: 5.07 toks/s, output: 25.03 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.78s/it, est. speed input: 5.07 toks/s, output: 25.03 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.78s/it, est. speed input: 5.07 toks/s, output: 25.03 toks/s]
Agent 3 response: The result of 10 + 10*23 + 20 - 3*7 is calculated by following the order of operations (PEMDAS/BODMA...

--- Problem 3/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 791.83it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:55:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:55:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:55:03 [model.py:1745] Using max model len 40960
INFO 12-04 09:55:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.15s/it, est. speed input: 16.59 toks/s, output: 25.10 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.15s/it, est. speed input: 16.59 toks/s, output: 25.10 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.15s/it, est. speed input: 16.59 toks/s, output: 25.10 toks/s]
Agent 1 response: The calculation follows the order of operations (multiplication before addition and subtraction). Mu...

--- Problem 3/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 587.11it/s]

[1;36m(EngineCore_DP0 pid=2881188)[0;0m INFO 12-04 09:55:16 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2881188)[0;0m INFO 12-04 09:55:17 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:35529 backend=nccl
[W1204 09:55:17.216935053 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:35529 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881188)[0;0m INFO 12-04 09:55:17 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.64s/it, est. speed input: 40.23 toks/s, output: 24.99 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.64s/it, est. speed input: 40.23 toks/s, output: 24.99 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.64s/it, est. speed input: 40.23 toks/s, output: 24.99 toks/s]
Agent 2 response: The bamboo bends but does not break. The stone remains still as the river flows. 239....

--- Problem 3/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 452.07it/s]

[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ERROR 12-04 09:55:18 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881188)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881188)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881188)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881188)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881188)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881188)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881188)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881188)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881188)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881188)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881188)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881188)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881188)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881188)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881188)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881188)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:55:18.032521232 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.15s/it, est. speed input: 25.41 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.15s/it, est. speed input: 25.41 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.15s/it, est. speed input: 25.41 toks/s, output: 25.15 toks/s]
Agent 3 response: The expression is evaluated using the order of operations (multiplication first, then addition and s...

--- Problem 3/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 558.64it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:55:39 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:55:39 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:55:39 [model.py:1745] Using max model len 40960
INFO 12-04 09:55:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.05s/it, est. speed input: 41.28 toks/s, output: 24.98 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.05s/it, est. speed input: 41.28 toks/s, output: 24.98 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.06s/it, est. speed input: 41.28 toks/s, output: 24.98 toks/s]
Agent 1 response: The bamboo bends but does not break. The stone remains still as the river flows. The calculation adh...

--- Problem 3/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 402.60it/s]

[1;36m(EngineCore_DP0 pid=2881363)[0;0m INFO 12-04 09:55:50 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2881363)[0;0m INFO 12-04 09:55:52 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47819 backend=nccl
[W1204 09:55:52.754103960 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47819 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881363)[0;0m INFO 12-04 09:55:52 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ERROR 12-04 09:55:52 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881363)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881363)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881363)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881363)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881363)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881363)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881363)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881363)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881363)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881363)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881363)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881363)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881363)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881363)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881363)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881363)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:55:53.575409329 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.05s/it, est. speed input: 64.05 toks/s, output: 24.97 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.05s/it, est. speed input: 64.05 toks/s, output: 24.97 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.05s/it, est. speed input: 64.05 toks/s, output: 24.97 toks/s]
Agent 2 response: The wind does not question the tree. The path dissolves into the shadow. 239....

--- Problem 3/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 561.86it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:56:14 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:56:14 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:56:14 [model.py:1745] Using max model len 40960
INFO 12-04 09:56:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.76s/it, est. speed input: 42.06 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.76s/it, est. speed input: 42.06 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.76s/it, est. speed input: 42.06 toks/s, output: 25.06 toks/s]
Agent 3 response: The expression is evaluated by prioritizing multiplication first: 10*23 = 230 and 3*7 = 21. Substitu...
performance: 0.6666666666666666 0.2721655269759087

--- Problem 4/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 15%|█▌        | 3/20 [27:05<1:56:31, 411.27s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1431.50it/s]

[1;36m(EngineCore_DP0 pid=2881421)[0;0m INFO 12-04 09:56:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2881421)[0;0m INFO 12-04 09:56:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:46901 backend=nccl
[W1204 09:56:29.850682503 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:46901 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881421)[0;0m INFO 12-04 09:56:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ERROR 12-04 09:56:29 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881421)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881421)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881421)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881421)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881421)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881421)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881421)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881421)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881421)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881421)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881421)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881421)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881421)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881421)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881421)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881421)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881421)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881421)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881421)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881421)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881421)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881421)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881421)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881421)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881421)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881421)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:56:30.681459745 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.95s/it, est. speed input: 3.53 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.95s/it, est. speed input: 3.53 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.95s/it, est. speed input: 3.53 toks/s, output: 25.11 toks/s]
Agent 1 response: The result of 23 + 2*21 + 20 - 1*23 is calculated by following the order of operations. First, perfo...

--- Problem 4/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1580.97it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.20s/it, est. speed input: 9.51 toks/s, output: 25.23 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.20s/it, est. speed input: 9.51 toks/s, output: 25.23 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.20s/it, est. speed input: 9.51 toks/s, output: 25.23 toks/s]
Agent 2 response: The stone does not question the path.  
62....

--- Problem 4/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1501.72it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:56:51 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:56:51 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:56:51 [model.py:1745] Using max model len 40960
INFO 12-04 09:56:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2881485)[0;0m INFO 12-04 09:57:03 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2881485)[0;0m INFO 12-04 09:57:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:46389 backend=nccl
[W1204 09:57:04.253698329 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:46389 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881485)[0;0m INFO 12-04 09:57:04 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ERROR 12-04 09:57:05 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881485)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881485)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881485)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881485)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881485)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881485)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881485)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881485)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881485)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881485)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881485)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881485)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881485)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881485)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881485)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881485)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881485)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:57:05.090322429 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.63s/it, est. speed input: 2.53 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.63s/it, est. speed input: 2.53 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.63s/it, est. speed input: 2.53 toks/s, output: 25.11 toks/s]
Agent 3 response: The result is calculated by following the order of operations (PEMDAS): first performing the multipl...

--- Problem 4/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 792.13it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:57:26 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:57:26 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:57:26 [model.py:1745] Using max model len 40960
INFO 12-04 09:57:26 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.22s/it, est. speed input: 29.43 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.22s/it, est. speed input: 29.43 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.22s/it, est. speed input: 29.43 toks/s, output: 25.11 toks/s]
Agent 1 response: The calculation follows the order of operations (multiplication before addition/subtraction), result...

--- Problem 4/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 526.59it/s]

[1;36m(EngineCore_DP0 pid=2881557)[0;0m INFO 12-04 09:57:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.63s/it, est. speed input: 33.78 toks/s, output: 25.01 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.63s/it, est. speed input: 33.78 toks/s, output: 25.01 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.63s/it, est. speed input: 33.78 toks/s, output: 25.01 toks/s]
Agent 2 response: The moon does not need a mirror to shine.  
62....

--- Problem 4/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 555.17it/s]

[1;36m(EngineCore_DP0 pid=2881557)[0;0m INFO 12-04 09:57:42 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:56853 backend=nccl
[W1204 09:57:42.733493283 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:56853 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881557)[0;0m INFO 12-04 09:57:42 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ERROR 12-04 09:57:42 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881557)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881557)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881557)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881557)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881557)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881557)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881557)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881557)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881557)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881557)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881557)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881557)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881557)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881557)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881557)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881557)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881557)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881557)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881557)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881557)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881557)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881557)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881557)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881557)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881557)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881557)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:57:43.557651397 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.57s/it, est. speed input: 18.08 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.57s/it, est. speed input: 18.08 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.57s/it, est. speed input: 18.08 toks/s, output: 25.13 toks/s]
Agent 3 response: The calculation follows the order of operations. Multiplying first: 2*21 = 42 and 1*23 = 23. Substit...

--- Problem 4/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 551.95it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:58:04 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:58:04 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:58:04 [model.py:1745] Using max model len 40960
INFO 12-04 09:58:04 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2881618)[0;0m INFO 12-04 09:58:15 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2881618)[0;0m INFO 12-04 09:58:17 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42107 backend=nccl
[W1204 09:58:17.473506468 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42107 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881618)[0;0m INFO 12-04 09:58:17 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ERROR 12-04 09:58:17 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881618)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881618)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881618)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881618)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881618)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881618)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881618)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881618)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881618)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881618)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881618)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881618)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881618)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881618)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881618)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881618)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:58:17.299802973 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.13s/it, est. speed input: 32.67 toks/s, output: 24.99 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.13s/it, est. speed input: 32.67 toks/s, output: 24.99 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.13s/it, est. speed input: 32.67 toks/s, output: 24.99 toks/s]
Agent 1 response: The calculation adheres to the order of operations (multiplication first): 2*21 = 42, 1*23 = 23. Sub...

--- Problem 4/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 602.54it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.19s/it, est. speed input: 76.76 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.19s/it, est. speed input: 76.76 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.19s/it, est. speed input: 76.76 toks/s, output: 25.14 toks/s]
Agent 2 response: The echo of a bell does not count its rings.  
62....

--- Problem 4/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 598.08it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:58:38 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:58:39 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:58:39 [model.py:1745] Using max model len 40960
INFO 12-04 09:58:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.32s/it, est. speed input: 38.36 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.32s/it, est. speed input: 38.36 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.32s/it, est. speed input: 38.36 toks/s, output: 25.06 toks/s]
Agent 3 response: The calculation adheres to standard order of operations (multiplication first, then left-to-right ad...
performance: 0.75 0.21650635094610965

--- Problem 5/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 20%|██        | 4/20 [29:34<1:22:02, 307.67s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1483.13it/s]

[1;36m(EngineCore_DP0 pid=2881692)[0;0m INFO 12-04 09:58:53 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2881692)[0;0m INFO 12-04 09:58:54 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38251 backend=nccl
[W1204 09:58:54.905831665 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38251 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881692)[0;0m INFO 12-04 09:58:54 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ERROR 12-04 09:58:54 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881692)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881692)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881692)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881692)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881692)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881692)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881692)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881692)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881692)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881692)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881692)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881692)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881692)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881692)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881692)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881692)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881692)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:58:55.724487262 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:59:16 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:59:16 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:59:16 [model.py:1745] Using max model len 40960
INFO 12-04 09:59:16 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.62s/it, est. speed input: 2.50 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.62s/it, est. speed input: 2.50 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.62s/it, est. speed input: 2.50 toks/s, output: 25.15 toks/s]
Agent 1 response: The result of 11 + 29*5 + 1 - 27*20 is calculated by first performing the multiplications: 29*5 = 14...

--- Problem 5/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1554.02it/s]

[1;36m(EngineCore_DP0 pid=2881751)[0;0m INFO 12-04 09:59:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.42s/it, est. speed input: 6.28 toks/s, output: 25.03 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.42s/it, est. speed input: 6.28 toks/s, output: 25.03 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.42s/it, est. speed input: 6.28 toks/s, output: 25.03 toks/s]
Agent 2 response: The moon reflects the sun's light. A single breath holds the universe.  
-383...

--- Problem 5/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1327.73it/s]

[1;36m(EngineCore_DP0 pid=2881751)[0;0m INFO 12-04 09:59:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34229 backend=nccl
[W1204 09:59:29.655765308 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34229 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881751)[0;0m INFO 12-04 09:59:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ERROR 12-04 09:59:29 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881751)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881751)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881751)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881751)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881751)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881751)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881751)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881751)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881751)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881751)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881751)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881751)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881751)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881751)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881751)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881751)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881751)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881751)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881751)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881751)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881751)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881751)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881751)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881751)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881751)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881751)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 09:59:30.484203816 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 09:59:51 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 09:59:51 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 09:59:51 [model.py:1745] Using max model len 40960
INFO 12-04 09:59:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.37s/it, est. speed input: 2.64 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.37s/it, est. speed input: 2.64 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.37s/it, est. speed input: 2.64 toks/s, output: 25.13 toks/s]
Agent 3 response: The result of 11 + 29*5 + 1 - 27*20 is calculated as follows:  
First, compute the multiplications: ...

--- Problem 5/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 642.90it/s]

[1;36m(EngineCore_DP0 pid=2881815)[0;0m INFO 12-04 10:00:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2881815)[0;0m INFO 12-04 10:00:05 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:39439 backend=nccl
[W1204 10:00:05.177113788 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:39439 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881815)[0;0m INFO 12-04 10:00:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ERROR 12-04 10:00:06 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881815)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881815)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881815)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881815)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881815)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881815)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881815)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881815)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881815)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881815)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881815)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881815)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881815)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881815)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881815)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881815)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.19s/it, est. speed input: 47.53 toks/s, output: 24.91 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.19s/it, est. speed input: 47.53 toks/s, output: 24.91 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.20s/it, est. speed input: 47.53 toks/s, output: 24.91 toks/s]
Agent 1 response: The calculation adheres to standard order of operations. Multiplying first: 29×5=145 and 27×20=540. ...

--- Problem 5/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 416.31it/s]

[rank0]:[W1204 10:00:06.998675006 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.48s/it, est. speed input: 42.08 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.48s/it, est. speed input: 42.08 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.48s/it, est. speed input: 42.08 toks/s, output: 25.09 toks/s]
Agent 2 response: The wind does not seek to be heard.  
-383...

--- Problem 5/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 785.01it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:00:27 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:00:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:00:27 [model.py:1745] Using max model len 40960
INFO 12-04 10:00:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it, est. speed input: 24.85 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it, est. speed input: 24.85 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it, est. speed input: 24.85 toks/s, output: 25.07 toks/s]
Agent 3 response: The calculation follows standard arithmetic rules:  
1. Multiply first: 29*5 = 145 and 27*20 = 540. ...

--- Problem 5/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 291.82it/s]

[1;36m(EngineCore_DP0 pid=2881949)[0;0m INFO 12-04 10:00:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2881949)[0;0m INFO 12-04 10:00:42 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42219 backend=nccl
[W1204 10:00:42.108307414 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42219 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2881949)[0;0m INFO 12-04 10:00:42 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ERROR 12-04 10:00:43 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2881949)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2881949)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2881949)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2881949)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2881949)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2881949)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2881949)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881949)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2881949)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2881949)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2881949)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881949)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2881949)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2881949)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2881949)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2881949)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881949)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2881949)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2881949)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2881949)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2881949)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2881949)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2881949)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2881949)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2881949)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2881949)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:00:43.933344531 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.40s/it, est. speed input: 41.64 toks/s, output: 25.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.40s/it, est. speed input: 41.64 toks/s, output: 25.00 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.40s/it, est. speed input: 41.64 toks/s, output: 25.00 toks/s]
Agent 1 response: The calculation remains consistent with previous confirmations:  
1. **Multiplication first**: 29×5 ...

--- Problem 5/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 498.79it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:01:04 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:01:04 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:01:04 [model.py:1745] Using max model len 40960
INFO 12-04 10:01:04 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.32s/it, est. speed input: 53.76 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.32s/it, est. speed input: 53.76 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.32s/it, est. speed input: 53.76 toks/s, output: 25.06 toks/s]
Agent 2 response: The river flows without end. Silence speaks volumes.  
-383...

--- Problem 5/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 456.30it/s]

[1;36m(EngineCore_DP0 pid=2882022)[0;0m INFO 12-04 10:01:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2882022)[0;0m INFO 12-04 10:01:19 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42427 backend=nccl
[W1204 10:01:19.830521540 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42427 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2882022)[0;0m INFO 12-04 10:01:19 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ERROR 12-04 10:01:19 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2882022)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2882022)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2882022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2882022)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2882022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2882022)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2882022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882022)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2882022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882022)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2882022)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2882022)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2882022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2882022)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2882022)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2882022)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2882022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2882022)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2882022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2882022)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2882022)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882022)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2882022)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2882022)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:01:20.651825082 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.47s/it, est. speed input: 46.56 toks/s, output: 24.95 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.47s/it, est. speed input: 46.56 toks/s, output: 24.95 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.47s/it, est. speed input: 46.56 toks/s, output: 24.95 toks/s]
Agent 3 response: The calculation adheres to standard order of operations. Multiplying first: 29×5=145 and 27×20=540. ...
performance: 0.8 0.1788854381999832

--- Problem 6/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 25%|██▌       | 5/20 [32:11<1:03:19, 253.32s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1533.57it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:01:41 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:01:41 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:01:41 [model.py:1745] Using max model len 40960
INFO 12-04 10:01:41 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.93s/it, est. speed input: 2.69 toks/s, output: 25.17 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.93s/it, est. speed input: 2.69 toks/s, output: 25.17 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.93s/it, est. speed input: 2.69 toks/s, output: 25.17 toks/s]
Agent 1 response: The result of the expression 0 + 11*25 + 21 - 28*11 is calculated as follows:  
1. Perform multiplic...

--- Problem 6/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1222.12it/s]

[1;36m(EngineCore_DP0 pid=2882078)[0;0m INFO 12-04 10:01:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2882078)[0;0m INFO 12-04 10:01:55 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:54911 backend=nccl
[W1204 10:01:55.008897146 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:54911 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2882078)[0;0m INFO 12-04 10:01:55 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ERROR 12-04 10:01:55 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2882078)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2882078)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2882078)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2882078)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2882078)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2882078)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2882078)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882078)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2882078)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882078)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2882078)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882078)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2882078)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2882078)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2882078)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2882078)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882078)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2882078)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2882078)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2882078)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2882078)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2882078)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2882078)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882078)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2882078)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2882078)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:01:56.837331216 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:02:17 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:02:17 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:02:17 [model.py:1745] Using max model len 40960
INFO 12-04 10:02:17 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.90s/it, est. speed input: 2.40 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.90s/it, est. speed input: 2.40 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.90s/it, est. speed input: 2.40 toks/s, output: 25.14 toks/s]
Agent 2 response: The wheel turns, but the ground remains. The key is not in the lock. But the answer is -12....

--- Problem 6/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1513.64it/s]

[1;36m(EngineCore_DP0 pid=2882137)[0;0m INFO 12-04 10:02:30 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2882137)[0;0m INFO 12-04 10:02:32 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:35981 backend=nccl
[W1204 10:02:32.811041463 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:35981 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2882137)[0;0m INFO 12-04 10:02:32 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ERROR 12-04 10:02:32 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2882137)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2882137)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2882137)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2882137)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2882137)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2882137)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2882137)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882137)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2882137)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882137)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2882137)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882137)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2882137)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2882137)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2882137)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2882137)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882137)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2882137)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2882137)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2882137)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2882137)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2882137)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2882137)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882137)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2882137)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2882137)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:02:33.639614870 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.46s/it, est. speed input: 3.24 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.46s/it, est. speed input: 3.24 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.46s/it, est. speed input: 3.24 toks/s, output: 25.15 toks/s]
Agent 3 response: The result of $0 + 11 \times 25 + 21 - 28 \times 11$ is calculated as follows:  
1. Perform the mult...

--- Problem 6/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 717.71it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:02:54 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:02:54 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:02:54 [model.py:1745] Using max model len 40960
INFO 12-04 10:02:54 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.82s/it, est. speed input: 37.22 toks/s, output: 24.97 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.82s/it, est. speed input: 37.22 toks/s, output: 24.97 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.82s/it, est. speed input: 37.22 toks/s, output: 24.97 toks/s]
Agent 1 response: The provided opinions corroborate the calculation. Both agents confirm the result through detailed s...

--- Problem 6/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 623.22it/s]

[1;36m(EngineCore_DP0 pid=2882202)[0;0m INFO 12-04 10:03:05 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2882202)[0;0m INFO 12-04 10:03:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47957 backend=nccl
[W1204 10:03:07.305326571 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47957 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2882202)[0;0m INFO 12-04 10:03:07 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ERROR 12-04 10:03:07 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2882202)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2882202)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2882202)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2882202)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2882202)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2882202)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2882202)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882202)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2882202)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882202)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2882202)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882202)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2882202)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2882202)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2882202)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2882202)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882202)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2882202)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2882202)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2882202)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2882202)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2882202)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2882202)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882202)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2882202)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2882202)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:03:07.125715439 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.95s/it, est. speed input: 60.47 toks/s, output: 24.77 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.95s/it, est. speed input: 60.47 toks/s, output: 24.77 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.95s/it, est. speed input: 60.47 toks/s, output: 24.77 toks/s]
Agent 2 response: A stone falls, but the sky does not answer. The river flows, yet the moon does not change. The answe...

--- Problem 6/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 727.67it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.42s/it, est. speed input: 29.11 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.42s/it, est. speed input: 29.11 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.42s/it, est. speed input: 29.11 toks/s, output: 25.09 toks/s]
Agent 3 response: The calculation of $0 + 11 \times 25 + 21 - 28 \times 11$ follows standard order of operations:  
1....

--- Problem 6/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 521.16it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:03:28 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:03:28 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:03:28 [model.py:1745] Using max model len 40960
INFO 12-04 10:03:28 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.93s/it, est. speed input: 61.77 toks/s, output: 24.98 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.93s/it, est. speed input: 61.77 toks/s, output: 24.98 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.93s/it, est. speed input: 61.77 toks/s, output: 24.98 toks/s]
Agent 1 response: The poetic metaphors and arithmetic confirmations remain consistent with prior calculations. The fin...

--- Problem 6/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 464.90it/s]

[1;36m(EngineCore_DP0 pid=2882273)[0;0m INFO 12-04 10:03:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2882273)[0;0m INFO 12-04 10:03:44 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:36577 backend=nccl
[W1204 10:03:44.137711600 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:36577 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2882273)[0;0m INFO 12-04 10:03:44 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ERROR 12-04 10:03:45 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2882273)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2882273)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2882273)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2882273)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2882273)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2882273)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2882273)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882273)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2882273)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2882273)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2882273)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882273)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2882273)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2882273)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2882273)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2882273)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882273)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2882273)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2882273)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2882273)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2882273)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2882273)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2882273)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2882273)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2882273)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2882273)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:03:45.972478764 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.44s/it, est. speed input: 55.12 toks/s, output: 24.92 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.44s/it, est. speed input: 55.12 toks/s, output: 24.92 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.44s/it, est. speed input: 55.12 toks/s, output: 24.92 toks/s]
Agent 2 response: The wind whispers, but the tree does not listen. The shadow moves, yet the sun does not age. The ans...

--- Problem 6/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 524.68it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.13s/it, est. speed input: 52.23 toks/s, output: 25.05 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.13s/it, est. speed input: 52.23 toks/s, output: 25.05 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.13s/it, est. speed input: 52.23 toks/s, output: 25.05 toks/s]
Agent 3 response: The calculation aligns with prior confirmations, as all agents consistently derive the result throug...
performance: 0.8333333333333334 0.15214515486254618

--- Problem 7/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 30%|███       | 6/20 [34:52<51:47, 221.93s/it]  
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1461.43it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:04:06 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:04:06 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:04:06 [model.py:1745] Using max model len 40960
INFO 12-04 10:04:06 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2893846)[0;0m INFO 12-04 10:04:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2893846)[0;0m INFO 12-04 10:04:19 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:59201 backend=nccl
[W1204 10:04:19.750561665 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:59201 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2893846)[0;0m INFO 12-04 10:04:19 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ERROR 12-04 10:04:19 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2893846)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2893846)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2893846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2893846)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2893846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2893846)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2893846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2893846)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2893846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2893846)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2893846)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2893846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2893846)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2893846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2893846)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2893846)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2893846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2893846)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2893846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2893846)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2893846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2893846)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2893846)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2893846)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2893846)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2893846)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:04:20.590418613 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.62s/it, est. speed input: 2.93 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.62s/it, est. speed input: 2.93 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.62s/it, est. speed input: 2.93 toks/s, output: 25.06 toks/s]
Agent 1 response: To solve the expression, follow the order of operations (multiplication before addition and subtract...

--- Problem 7/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1531.89it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:04:41 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:04:41 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:04:41 [model.py:1745] Using max model len 40960
INFO 12-04 10:04:41 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.12s/it, est. speed input: 4.90 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.12s/it, est. speed input: 4.90 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.12s/it, est. speed input: 4.90 toks/s, output: 25.13 toks/s]
Agent 2 response: The moon reflects the sun's light. A stone does not ask why it falls.  
223...

--- Problem 7/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1455.34it/s]

[1;36m(EngineCore_DP0 pid=2910849)[0;0m INFO 12-04 10:04:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2910849)[0;0m INFO 12-04 10:04:55 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:43377 backend=nccl
[W1204 10:04:55.780750536 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:43377 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2910849)[0;0m INFO 12-04 10:04:55 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ERROR 12-04 10:04:55 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2910849)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2910849)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2910849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2910849)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2910849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2910849)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2910849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2910849)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2910849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2910849)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2910849)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2910849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2910849)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2910849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2910849)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2910849)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2910849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2910849)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2910849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2910849)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2910849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2910849)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2910849)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2910849)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2910849)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2910849)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:04:56.620693803 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.09s/it, est. speed input: 3.98 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.09s/it, est. speed input: 3.98 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.09s/it, est. speed input: 3.98 toks/s, output: 25.09 toks/s]
Agent 3 response: The result of 24 + 16 * 26 + 26 - 9 * 27 is 223....

--- Problem 7/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 807.37it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:05:17 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:05:17 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:05:17 [model.py:1745] Using max model len 40960
INFO 12-04 10:05:17 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.78s/it, est. speed input: 28.79 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.78s/it, est. speed input: 28.79 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.78s/it, est. speed input: 28.79 toks/s, output: 25.14 toks/s]
Agent 1 response: The calculations align with the provided opinions, as both confirm the result is 223. The expression...

--- Problem 7/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 619.09it/s]

[1;36m(EngineCore_DP0 pid=2921987)[0;0m INFO 12-04 10:05:29 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2921987)[0;0m INFO 12-04 10:05:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:43001 backend=nccl
[W1204 10:05:30.043298930 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:43001 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2921987)[0;0m INFO 12-04 10:05:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ERROR 12-04 10:05:31 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2921987)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2921987)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2921987)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2921987)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2921987)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2921987)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2921987)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2921987)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2921987)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2921987)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2921987)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2921987)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2921987)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2921987)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2921987)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2921987)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2921987)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2921987)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2921987)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2921987)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2921987)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2921987)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2921987)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2921987)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2921987)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2921987)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:05:31.880187361 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.00s/it, est. speed input: 18.05 toks/s, output: 25.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.00s/it, est. speed input: 18.05 toks/s, output: 25.00 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.00s/it, est. speed input: 18.05 toks/s, output: 25.00 toks/s]
Agent 2 response: The wind does not explain its path to the tree. A mountain holds its silence until the river speaks....

--- Problem 7/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 765.52it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:05:52 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:05:52 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:05:52 [model.py:1745] Using max model len 40960
INFO 12-04 10:05:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.60s/it, est. speed input: 15.04 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.60s/it, est. speed input: 15.04 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.60s/it, est. speed input: 15.04 toks/s, output: 25.09 toks/s]
Agent 3 response: The calculation follows the order of operations (multiplication before addition/subtraction):  
1. $...

--- Problem 7/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 263.33it/s]

[1;36m(EngineCore_DP0 pid=2932615)[0;0m INFO 12-04 10:06:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2932615)[0;0m INFO 12-04 10:06:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:58619 backend=nccl
[W1204 10:06:06.512694569 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:58619 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2932615)[0;0m INFO 12-04 10:06:06 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ERROR 12-04 10:06:06 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2932615)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2932615)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2932615)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2932615)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2932615)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2932615)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2932615)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2932615)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2932615)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2932615)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2932615)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2932615)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2932615)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2932615)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2932615)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2932615)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2932615)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2932615)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2932615)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2932615)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2932615)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2932615)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2932615)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2932615)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2932615)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2932615)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:06:07.349891184 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.63s/it, est. speed input: 54.92 toks/s, output: 24.93 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.63s/it, est. speed input: 54.92 toks/s, output: 24.93 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.63s/it, est. speed input: 54.92 toks/s, output: 24.93 toks/s]
Agent 1 response: The calculation adheres to standard mathematical precedence: multiplication is resolved first ($16 \...

--- Problem 7/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 563.67it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.73s/it, est. speed input: 66.09 toks/s, output: 25.08 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.73s/it, est. speed input: 66.09 toks/s, output: 25.08 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.73s/it, est. speed input: 66.09 toks/s, output: 25.08 toks/s]
Agent 2 response: The bamboo bends but does not break. The shadow knows the shape of the flame.  
223...

--- Problem 7/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 562.16it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:06:28 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:06:28 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:06:28 [model.py:1745] Using max model len 40960
INFO 12-04 10:06:28 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2943236)[0;0m INFO 12-04 10:06:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.19s/it, est. speed input: 30.20 toks/s, output: 24.96 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.19s/it, est. speed input: 30.20 toks/s, output: 24.96 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.19s/it, est. speed input: 30.20 toks/s, output: 24.96 toks/s]
Agent 3 response: The calculation adheres to the standard order of operations (multiplication before addition/subtract...
performance: 0.8571428571428571 0.13226001425322165

--- Problem 8/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 35%|███▌      | 7/20 [37:28<43:28, 200.63s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1271.39it/s]

[1;36m(EngineCore_DP0 pid=2943236)[0;0m INFO 12-04 10:06:42 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45191 backend=nccl
[W1204 10:06:42.895459624 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45191 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2943236)[0;0m INFO 12-04 10:06:42 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ERROR 12-04 10:06:42 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2943236)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2943236)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2943236)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2943236)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2943236)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2943236)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2943236)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2943236)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2943236)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2943236)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2943236)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2943236)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2943236)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2943236)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2943236)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2943236)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2943236)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2943236)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2943236)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2943236)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2943236)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2943236)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2943236)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2943236)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2943236)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2943236)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:06:43.740495929 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.37s/it, est. speed input: 3.73 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.37s/it, est. speed input: 3.73 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.37s/it, est. speed input: 3.73 toks/s, output: 25.14 toks/s]
Agent 1 response: The result of 27 + 15 * 14 + 29 - 29 * 14 is calculated by following the order of operations. First,...

--- Problem 8/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1560.38it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:07:04 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:07:04 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:07:04 [model.py:1745] Using max model len 40960
INFO 12-04 10:07:04 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2954562)[0;0m INFO 12-04 10:07:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2954562)[0;0m INFO 12-04 10:07:18 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37341 backend=nccl
[W1204 10:07:18.745762525 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37341 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2954562)[0;0m INFO 12-04 10:07:18 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ERROR 12-04 10:07:18 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2954562)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2954562)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2954562)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2954562)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2954562)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2954562)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2954562)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2954562)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2954562)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2954562)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2954562)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2954562)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2954562)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2954562)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2954562)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2954562)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2954562)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2954562)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2954562)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2954562)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2954562)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2954562)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2954562)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2954562)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2954562)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2954562)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:07:19.579308654 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.26s/it, est. speed input: 3.05 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.26s/it, est. speed input: 3.05 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.26s/it, est. speed input: 3.05 toks/s, output: 25.06 toks/s]
Agent 2 response: A stone falls, but the mountain does not move. The result is -140....

--- Problem 8/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1494.76it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:07:40 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:07:40 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:07:40 [model.py:1745] Using max model len 40960
INFO 12-04 10:07:40 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2965448)[0;0m INFO 12-04 10:07:52 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2965448)[0;0m INFO 12-04 10:07:54 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50511 backend=nccl
[W1204 10:07:54.541119333 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50511 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2965448)[0;0m INFO 12-04 10:07:54 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ERROR 12-04 10:07:54 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2965448)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2965448)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2965448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2965448)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2965448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2965448)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2965448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2965448)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2965448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2965448)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2965448)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2965448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2965448)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2965448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2965448)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2965448)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2965448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2965448)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2965448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2965448)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2965448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2965448)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2965448)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2965448)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2965448)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2965448)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:07:55.387754744 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.04s/it, est. speed input: 2.75 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.04s/it, est. speed input: 2.75 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.04s/it, est. speed input: 2.75 toks/s, output: 25.07 toks/s]
Agent 3 response: Following the order of operations (PEMDAS/BODMAS), first compute the multiplications:  
15*14 = 210 ...

--- Problem 8/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 703.74it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.94s/it, est. speed input: 29.05 toks/s, output: 25.10 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.94s/it, est. speed input: 29.05 toks/s, output: 25.10 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.94s/it, est. speed input: 29.05 toks/s, output: 25.10 toks/s]
Agent 1 response: The calculation adheres to the standard order of operations (multiplication before addition/subtract...

--- Problem 8/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 733.14it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:08:16 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:08:16 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:08:16 [model.py:1745] Using max model len 40960
INFO 12-04 10:08:16 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.68s/it, est. speed input: 45.24 toks/s, output: 25.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.68s/it, est. speed input: 45.24 toks/s, output: 25.00 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.68s/it, est. speed input: 45.24 toks/s, output: 25.00 toks/s]
Agent 2 response: A river flows, yet the moon reflects still. The result is -140....

--- Problem 8/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 502.19it/s]

[1;36m(EngineCore_DP0 pid=2976073)[0;0m INFO 12-04 10:08:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2976073)[0;0m INFO 12-04 10:08:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38857 backend=nccl
[W1204 10:08:29.967007258 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38857 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2976073)[0;0m INFO 12-04 10:08:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ERROR 12-04 10:08:29 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2976073)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2976073)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2976073)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2976073)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2976073)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2976073)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2976073)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2976073)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2976073)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2976073)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2976073)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2976073)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2976073)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2976073)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2976073)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2976073)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2976073)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2976073)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2976073)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2976073)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2976073)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2976073)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2976073)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2976073)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2976073)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2976073)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:08:30.815778059 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.07s/it, est. speed input: 30.91 toks/s, output: 24.94 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.07s/it, est. speed input: 30.91 toks/s, output: 24.94 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.07s/it, est. speed input: 30.91 toks/s, output: 24.94 toks/s]
Agent 3 response: The calculation follows standard mathematical order of operations (multiplication before addition/su...

--- Problem 8/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 510.07it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:08:51 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:08:51 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:08:51 [model.py:1745] Using max model len 40960
INFO 12-04 10:08:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.37s/it, est. speed input: 33.75 toks/s, output: 24.99 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.37s/it, est. speed input: 33.75 toks/s, output: 24.99 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.37s/it, est. speed input: 33.75 toks/s, output: 24.99 toks/s]
Agent 1 response: The calculation follows the standard order of operations (multiplication before addition/subtraction...

--- Problem 8/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 350.11it/s]

[1;36m(EngineCore_DP0 pid=2986714)[0;0m INFO 12-04 10:09:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2986714)[0;0m INFO 12-04 10:09:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44063 backend=nccl
[W1204 10:09:04.348249034 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44063 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2986714)[0;0m INFO 12-04 10:09:04 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ERROR 12-04 10:09:04 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2986714)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2986714)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2986714)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2986714)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2986714)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2986714)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2986714)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2986714)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2986714)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2986714)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2986714)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2986714)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2986714)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2986714)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2986714)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2986714)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2986714)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2986714)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2986714)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2986714)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2986714)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2986714)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2986714)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2986714)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2986714)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2986714)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:09:04.194937823 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.78s/it, est. speed input: 86.43 toks/s, output: 24.83 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.78s/it, est. speed input: 86.43 toks/s, output: 24.83 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.78s/it, est. speed input: 86.43 toks/s, output: 24.83 toks/s]
Agent 2 response: A silent echo in the void. The result is -140....

--- Problem 8/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 492.06it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.06s/it, est. speed input: 57.89 toks/s, output: 25.04 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.06s/it, est. speed input: 57.89 toks/s, output: 25.04 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.06s/it, est. speed input: 57.89 toks/s, output: 25.04 toks/s]
Agent 3 response: The calculation remains consistent with the order of operations: 15*14=210 and 29*14=406, leading to...
performance: 0.875 0.11692679333668567

--- Problem 9/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 40%|████      | 8/20 [40:06<37:23, 186.93s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1492.10it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:09:25 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:09:26 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:09:26 [model.py:1745] Using max model len 40960
INFO 12-04 10:09:26 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2996365)[0;0m INFO 12-04 10:09:39 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.06s/it, est. speed input: 3.61 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.06s/it, est. speed input: 3.61 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.06s/it, est. speed input: 3.61 toks/s, output: 25.07 toks/s]
Agent 1 response: The result of 29 + 18*11 + 22 - 19*24 is calculated by first performing the multiplications: 18*11 =...

--- Problem 9/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1152.60it/s]

[1;36m(EngineCore_DP0 pid=2996365)[0;0m INFO 12-04 10:09:41 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51473 backend=nccl
[W1204 10:09:41.659906631 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51473 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2996365)[0;0m INFO 12-04 10:09:41 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ERROR 12-04 10:09:41 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=2996365)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2996365)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2996365)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2996365)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2996365)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2996365)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2996365)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2996365)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2996365)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2996365)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2996365)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2996365)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2996365)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2996365)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2996365)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2996365)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2996365)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2996365)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2996365)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=2996365)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=2996365)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=2996365)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2996365)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2996365)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=2996365)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=2996365)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:09:42.509176617 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.70s/it, est. speed input: 3.86 toks/s, output: 25.12 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.70s/it, est. speed input: 3.86 toks/s, output: 25.12 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.70s/it, est. speed input: 3.86 toks/s, output: 25.12 toks/s]
Agent 2 response: The silence between stars. A shadow without form. The answer is -207....

--- Problem 9/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1463.47it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:10:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:10:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:10:03 [model.py:1745] Using max model len 40960
INFO 12-04 10:10:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3007959)[0;0m INFO 12-04 10:10:14 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3007959)[0;0m INFO 12-04 10:10:15 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55395 backend=nccl
[W1204 10:10:15.227526123 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55395 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3007959)[0;0m INFO 12-04 10:10:15 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ERROR 12-04 10:10:16 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3007959)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3007959)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3007959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3007959)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3007959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3007959)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3007959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3007959)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3007959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3007959)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3007959)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3007959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3007959)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3007959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3007959)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3007959)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3007959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3007959)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3007959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3007959)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3007959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3007959)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3007959)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3007959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3007959)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3007959)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:10:16.067277403 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.94s/it, est. speed input: 4.07 toks/s, output: 25.03 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.94s/it, est. speed input: 4.07 toks/s, output: 25.03 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.94s/it, est. speed input: 4.07 toks/s, output: 25.03 toks/s]
Agent 3 response: The result is calculated by following the order of operations (multiplication before addition/subtra...

--- Problem 9/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 724.78it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.81s/it, est. speed input: 25.34 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.81s/it, est. speed input: 25.34 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.81s/it, est. speed input: 25.34 toks/s, output: 25.11 toks/s]
Agent 1 response: The calculation adheres to the order of operations, confirming prior results. Multiplying first: 18×...

--- Problem 9/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 754.10it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:10:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:10:37 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:10:37 [model.py:1745] Using max model len 40960
INFO 12-04 10:10:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3018659)[0;0m INFO 12-04 10:10:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3018659)[0;0m INFO 12-04 10:10:52 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:39959 backend=nccl
[W1204 10:10:52.811147690 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:39959 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3018659)[0;0m INFO 12-04 10:10:52 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ERROR 12-04 10:10:52 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3018659)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3018659)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3018659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3018659)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3018659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3018659)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3018659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3018659)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3018659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3018659)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3018659)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3018659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3018659)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3018659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3018659)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3018659)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3018659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3018659)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3018659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3018659)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3018659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3018659)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3018659)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3018659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3018659)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3018659)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:10:53.649603718 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.10s/it, est. speed input: 20.37 toks/s, output: 24.97 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.10s/it, est. speed input: 20.37 toks/s, output: 24.97 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.11s/it, est. speed input: 20.37 toks/s, output: 24.97 toks/s]
Agent 2 response: The wind whispers through hollow bones. Seasons forget their names. The answer is -207....

--- Problem 9/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 714.41it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:11:14 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:11:14 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:11:14 [model.py:1745] Using max model len 40960
INFO 12-04 10:11:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.51s/it, est. speed input: 21.89 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.51s/it, est. speed input: 21.89 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.51s/it, est. speed input: 21.89 toks/s, output: 25.07 toks/s]
Agent 3 response: The calculation follows standard order of operations: multiplications (18×11=198, 19×24=456) are res...

--- Problem 9/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 374.59it/s]

[1;36m(EngineCore_DP0 pid=3029283)[0;0m INFO 12-04 10:11:25 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3029283)[0;0m INFO 12-04 10:11:26 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50211 backend=nccl
[W1204 10:11:26.204368764 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50211 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3029283)[0;0m INFO 12-04 10:11:26 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ERROR 12-04 10:11:27 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3029283)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3029283)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3029283)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3029283)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3029283)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3029283)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3029283)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3029283)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3029283)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3029283)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3029283)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3029283)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3029283)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3029283)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3029283)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3029283)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3029283)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3029283)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3029283)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3029283)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3029283)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3029283)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3029283)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3029283)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3029283)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3029283)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:11:27.046800612 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.13s/it, est. speed input: 37.40 toks/s, output: 24.93 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.13s/it, est. speed input: 37.40 toks/s, output: 24.93 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.13s/it, est. speed input: 37.40 toks/s, output: 24.93 toks/s]
Agent 1 response: The calculation remains consistent with prior confirmations: multiplication precedes addition/subtra...

--- Problem 9/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 539.39it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.54s/it, est. speed input: 64.73 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.54s/it, est. speed input: 64.73 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.54s/it, est. speed input: 64.73 toks/s, output: 25.06 toks/s]
Agent 2 response: The echo of a stone in the void. Shadows without edges. The answer is -207....

--- Problem 9/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 538.91it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:11:48 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:11:48 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:11:48 [model.py:1745] Using max model len 40960
INFO 12-04 10:11:48 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3039907)[0;0m INFO 12-04 10:12:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3039907)[0;0m INFO 12-04 10:12:03 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60677 backend=nccl
[W1204 10:12:03.137570531 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60677 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3039907)[0;0m INFO 12-04 10:12:03 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ERROR 12-04 10:12:04 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3039907)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3039907)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3039907)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3039907)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3039907)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3039907)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3039907)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3039907)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3039907)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3039907)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3039907)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3039907)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3039907)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3039907)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3039907)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3039907)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3039907)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3039907)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3039907)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3039907)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3039907)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3039907)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3039907)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3039907)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3039907)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3039907)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:12:04.968373706 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.29s/it, est. speed input: 30.46 toks/s, output: 24.95 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.29s/it, est. speed input: 30.46 toks/s, output: 24.95 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.29s/it, est. speed input: 30.46 toks/s, output: 24.95 toks/s]
Agent 3 response: The calculation remains unchanged: adhering to multiplication first (18×11=198, 19×24=456), then seq...
performance: 0.8888888888888888 0.10475656017578483

--- Problem 10/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 45%|████▌     | 9/20 [42:55<33:14, 181.36s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1510.92it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:12:25 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:12:25 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:12:25 [model.py:1745] Using max model len 40960
INFO 12-04 10:12:25 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.56s/it, est. speed input: 4.10 toks/s, output: 25.17 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.56s/it, est. speed input: 4.10 toks/s, output: 25.17 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.56s/it, est. speed input: 4.10 toks/s, output: 25.17 toks/s]
Agent 1 response: The result of 2 + 4*18 + 6 - 20*8 is calculated by following the order of operations (multiplication...

--- Problem 10/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1072.71it/s]

[1;36m(EngineCore_DP0 pid=3050526)[0;0m INFO 12-04 10:12:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3050526)[0;0m INFO 12-04 10:12:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:56867 backend=nccl
[W1204 10:12:38.350208152 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:56867 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3050526)[0;0m INFO 12-04 10:12:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ERROR 12-04 10:12:38 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3050526)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3050526)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3050526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3050526)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3050526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3050526)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3050526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3050526)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3050526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3050526)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3050526)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3050526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3050526)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3050526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3050526)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3050526)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3050526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3050526)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3050526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3050526)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3050526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3050526)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3050526)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3050526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3050526)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3050526)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:12:38.195326318 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.67s/it, est. speed input: 4.30 toks/s, output: 25.02 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.67s/it, est. speed input: 4.30 toks/s, output: 25.02 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.67s/it, est. speed input: 4.30 toks/s, output: 25.02 toks/s]
Agent 2 response: Why does the moon reflect the sun's light? The answer is -80....

--- Problem 10/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1514.19it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.80s/it, est. speed input: 4.62 toks/s, output: 25.19 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.80s/it, est. speed input: 4.62 toks/s, output: 25.19 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.80s/it, est. speed input: 4.62 toks/s, output: 25.19 toks/s]
Agent 3 response: Following the order of operations (multiplication before addition/subtraction):  
2 + (4 × 18) + 6 -...

--- Problem 10/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 759.56it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:12:59 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:13:00 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:13:00 [model.py:1745] Using max model len 40960
INFO 12-04 10:13:00 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.82s/it, est. speed input: 33.50 toks/s, output: 24.96 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.82s/it, est. speed input: 33.50 toks/s, output: 24.96 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.82s/it, est. speed input: 33.50 toks/s, output: 24.96 toks/s]
Agent 1 response: The calculation follows standard arithmetic rules, prioritizing multiplication before addition and s...

--- Problem 10/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 580.37it/s]

[1;36m(EngineCore_DP0 pid=3060390)[0;0m INFO 12-04 10:13:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3060390)[0;0m INFO 12-04 10:13:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37267 backend=nccl
[W1204 10:13:13.008661894 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37267 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3060390)[0;0m INFO 12-04 10:13:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ERROR 12-04 10:13:13 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3060390)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3060390)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3060390)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3060390)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3060390)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3060390)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3060390)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3060390)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3060390)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3060390)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3060390)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3060390)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3060390)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3060390)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3060390)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3060390)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3060390)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3060390)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3060390)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3060390)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3060390)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3060390)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3060390)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3060390)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3060390)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3060390)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:13:14.837771119 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.21s/it, est. speed input: 23.24 toks/s, output: 25.04 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.21s/it, est. speed input: 23.24 toks/s, output: 25.04 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.21s/it, est. speed input: 23.24 toks/s, output: 25.04 toks/s]
Agent 2 response: What is the echo of silence in a thunderstorm? The answer is -80....

--- Problem 10/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 753.96it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:13:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:13:35 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:13:35 [model.py:1745] Using max model len 40960
INFO 12-04 10:13:35 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.26s/it, est. speed input: 23.00 toks/s, output: 25.03 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.26s/it, est. speed input: 23.00 toks/s, output: 25.03 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.26s/it, est. speed input: 23.00 toks/s, output: 25.03 toks/s]
Agent 3 response: The correct calculation follows the order of operations (multiplication first, then addition/subtrac...

--- Problem 10/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 368.79it/s]

[1;36m(EngineCore_DP0 pid=3066601)[0;0m INFO 12-04 10:13:46 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3066601)[0;0m INFO 12-04 10:13:48 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42339 backend=nccl
[W1204 10:13:48.681497924 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42339 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3066601)[0;0m INFO 12-04 10:13:48 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ERROR 12-04 10:13:48 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3066601)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3066601)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3066601)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3066601)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3066601)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3066601)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3066601)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3066601)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3066601)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3066601)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3066601)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3066601)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3066601)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3066601)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3066601)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3066601)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3066601)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3066601)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3066601)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3066601)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3066601)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3066601)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3066601)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3066601)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3066601)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3066601)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:13:49.501779623 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.14s/it, est. speed input: 48.85 toks/s, output: 25.03 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.14s/it, est. speed input: 48.85 toks/s, output: 25.03 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.14s/it, est. speed input: 48.85 toks/s, output: 25.03 toks/s]
Agent 1 response: The calculation adheres strictly to the order of operations (multiplication first, then left-to-righ...

--- Problem 10/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 509.82it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:14:10 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:14:10 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:14:10 [model.py:1745] Using max model len 40960
INFO 12-04 10:14:10 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.29s/it, est. speed input: 61.58 toks/s, output: 25.08 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.29s/it, est. speed input: 61.58 toks/s, output: 25.08 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.29s/it, est. speed input: 61.58 toks/s, output: 25.08 toks/s]
Agent 2 response: What is the shadow of a shadow in a cave? The answer is -80....

--- Problem 10/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 512.69it/s]

[1;36m(EngineCore_DP0 pid=3067342)[0;0m INFO 12-04 10:14:23 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3067342)[0;0m INFO 12-04 10:14:25 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:59143 backend=nccl
[W1204 10:14:25.619289191 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:59143 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3067342)[0;0m INFO 12-04 10:14:25 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ERROR 12-04 10:14:25 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3067342)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3067342)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3067342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3067342)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3067342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3067342)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3067342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3067342)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3067342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3067342)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3067342)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3067342)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3067342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3067342)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3067342)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3067342)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3067342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3067342)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3067342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3067342)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3067342)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067342)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3067342)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3067342)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:14:26.434665686 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.96s/it, est. speed input: 43.35 toks/s, output: 24.93 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.96s/it, est. speed input: 43.35 toks/s, output: 24.93 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.96s/it, est. speed input: 43.35 toks/s, output: 24.93 toks/s]
Agent 3 response: The calculation adheres to standard arithmetic rules (multiplication first, then left-to-right addit...
performance: 0.8 0.12649110640673517

--- Problem 11/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 50%|█████     | 10/20 [45:14<28:01, 168.20s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1544.86it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.69s/it, est. speed input: 3.76 toks/s, output: 25.24 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.69s/it, est. speed input: 3.76 toks/s, output: 25.24 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.69s/it, est. speed input: 3.76 toks/s, output: 25.24 toks/s]
Agent 1 response: The result is calculated by following the order of operations. First, compute the multiplications: 1...

--- Problem 11/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1529.65it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:14:47 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:14:47 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:14:47 [model.py:1745] Using max model len 40960
INFO 12-04 10:14:47 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3067939)[0;0m INFO 12-04 10:14:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3067939)[0;0m INFO 12-04 10:15:00 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60547 backend=nccl
[W1204 10:15:00.921960870 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60547 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3067939)[0;0m INFO 12-04 10:15:00 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ERROR 12-04 10:15:00 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3067939)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3067939)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3067939)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3067939)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3067939)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3067939)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3067939)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3067939)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3067939)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3067939)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3067939)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067939)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3067939)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3067939)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3067939)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3067939)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067939)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3067939)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3067939)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3067939)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3067939)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3067939)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3067939)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3067939)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3067939)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3067939)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:15:01.742638728 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.69s/it, est. speed input: 5.31 toks/s, output: 25.05 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.69s/it, est. speed input: 5.31 toks/s, output: 25.05 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.69s/it, est. speed input: 5.31 toks/s, output: 25.05 toks/s]
Agent 2 response: The moon reflects the sun's light. A stone cannot be both heavy and light. The result is -270....

--- Problem 11/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1170.94it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.32s/it, est. speed input: 4.09 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.32s/it, est. speed input: 4.09 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.32s/it, est. speed input: 4.09 toks/s, output: 25.22 toks/s]
Agent 3 response: The result of 6 + 17*3 + 24 - 27*13 is calculated as follows:  
1. 17*3 = 51  
2. 27*13 = 351  
3. C...

--- Problem 11/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 800.90it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:15:22 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:15:22 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:15:22 [model.py:1745] Using max model len 40960
INFO 12-04 10:15:22 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.58s/it, est. speed input: 25.48 toks/s, output: 25.04 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.58s/it, est. speed input: 25.48 toks/s, output: 25.04 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.58s/it, est. speed input: 25.48 toks/s, output: 25.04 toks/s]
Agent 1 response: The calculation follows the standard order of operations. Multiplying first: 17×3 = 51 and 27×13 = 3...

--- Problem 11/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 591.25it/s]

[1;36m(EngineCore_DP0 pid=3068619)[0;0m INFO 12-04 10:15:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3068619)[0;0m INFO 12-04 10:15:37 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38151 backend=nccl
[W1204 10:15:37.377763820 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38151 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3068619)[0;0m INFO 12-04 10:15:37 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ERROR 12-04 10:15:37 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3068619)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3068619)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3068619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3068619)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3068619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3068619)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3068619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3068619)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3068619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3068619)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3068619)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3068619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3068619)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3068619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3068619)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3068619)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3068619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3068619)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3068619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3068619)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3068619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3068619)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3068619)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3068619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3068619)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3068619)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:15:37.197734020 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.80s/it, est. speed input: 23.65 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.80s/it, est. speed input: 23.65 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.80s/it, est. speed input: 23.65 toks/s, output: 25.07 toks/s]
Agent 2 response: The river flows without direction. A shadow has no weight. The result is -270....

--- Problem 11/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 830.88it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:15:58 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:15:58 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:15:58 [model.py:1745] Using max model len 40960
INFO 12-04 10:15:58 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.41s/it, est. speed input: 19.94 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.41s/it, est. speed input: 19.94 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.41s/it, est. speed input: 19.94 toks/s, output: 25.11 toks/s]
Agent 3 response: The calculation follows the order of operations:  
1. Multiplications: 17*3 = 51 and 27*13 = 351.  
...

--- Problem 11/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 417.22it/s]

[1;36m(EngineCore_DP0 pid=3069221)[0;0m INFO 12-04 10:16:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3069221)[0;0m INFO 12-04 10:16:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:36057 backend=nccl
[W1204 10:16:11.204858159 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:36057 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3069221)[0;0m INFO 12-04 10:16:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ERROR 12-04 10:16:12 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3069221)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3069221)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3069221)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3069221)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3069221)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3069221)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3069221)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3069221)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3069221)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3069221)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3069221)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3069221)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3069221)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3069221)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3069221)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3069221)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3069221)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3069221)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3069221)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3069221)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3069221)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3069221)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3069221)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3069221)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3069221)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3069221)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:16:12.024700226 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.47s/it, est. speed input: 28.62 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.47s/it, est. speed input: 28.62 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.47s/it, est. speed input: 28.62 toks/s, output: 25.06 toks/s]
Agent 1 response: The calculation adheres to the order of operations. Multiplying first: 17×3 = 51, 27×13 = 351. Subst...

--- Problem 11/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 571.98it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:16:33 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:16:33 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:16:33 [model.py:1745] Using max model len 40960
INFO 12-04 10:16:33 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.46s/it, est. speed input: 56.46 toks/s, output: 25.05 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.46s/it, est. speed input: 56.46 toks/s, output: 25.05 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.46s/it, est. speed input: 56.46 toks/s, output: 25.05 toks/s]
Agent 2 response: A bell tolls without a hand to ring it. The mountain does not ask the sky for permission to rise. Th...

--- Problem 11/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 552.39it/s]

[1;36m(EngineCore_DP0 pid=3070355)[0;0m INFO 12-04 10:16:47 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3070355)[0;0m INFO 12-04 10:16:48 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:53985 backend=nccl
[W1204 10:16:48.853512385 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:53985 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3070355)[0;0m INFO 12-04 10:16:48 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ERROR 12-04 10:16:48 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3070355)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3070355)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3070355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3070355)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3070355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3070355)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3070355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3070355)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3070355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3070355)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3070355)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3070355)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3070355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3070355)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3070355)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3070355)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3070355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3070355)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3070355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3070355)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3070355)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3070355)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3070355)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:16:49.673894112 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.72s/it, est. speed input: 34.40 toks/s, output: 25.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.72s/it, est. speed input: 34.40 toks/s, output: 25.00 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.72s/it, est. speed input: 34.40 toks/s, output: 25.00 toks/s]
Agent 3 response: The calculation adheres to the order of operations (multiplication first, then addition/subtraction)...
performance: 0.8181818181818182 0.11629129983033296

--- Problem 12/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 55%|█████▌    | 11/20 [47:45<24:26, 162.98s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1563.87it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:17:10 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:17:10 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:17:10 [model.py:1745] Using max model len 40960
INFO 12-04 10:17:10 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.24s/it, est. speed input: 6.05 toks/s, output: 25.25 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.24s/it, est. speed input: 6.05 toks/s, output: 25.25 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.24s/it, est. speed input: 6.05 toks/s, output: 25.25 toks/s]
Agent 1 response: Following the order of operations (multiplication before addition/subtraction):  
17 + (25 × 8) + 25...

--- Problem 12/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1127.50it/s]

[1;36m(EngineCore_DP0 pid=3070956)[0;0m INFO 12-04 10:17:21 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3070956)[0;0m INFO 12-04 10:17:23 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:54063 backend=nccl
[W1204 10:17:23.670428259 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:54063 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3070956)[0;0m INFO 12-04 10:17:23 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ERROR 12-04 10:17:23 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3070956)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3070956)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3070956)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3070956)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3070956)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3070956)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3070956)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3070956)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3070956)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3070956)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3070956)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070956)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3070956)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3070956)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3070956)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3070956)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070956)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3070956)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3070956)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3070956)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3070956)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3070956)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3070956)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3070956)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3070956)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3070956)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:17:24.497514831 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.43s/it, est. speed input: 4.47 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.43s/it, est. speed input: 4.47 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.43s/it, est. speed input: 4.47 toks/s, output: 25.07 toks/s]
Agent 2 response: What is the sound of one hand clapping?  
The river flows uphill.  
A stone is not a stone.  
222....

--- Problem 12/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1549.43it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.24s/it, est. speed input: 6.13 toks/s, output: 25.24 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.24s/it, est. speed input: 6.13 toks/s, output: 25.24 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.24s/it, est. speed input: 6.13 toks/s, output: 25.24 toks/s]
Agent 3 response: The result of 17 + 25 * 8 + 25 - 20 * 1 is 222....

--- Problem 12/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 893.17it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:17:45 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:17:45 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:17:45 [model.py:1745] Using max model len 40960
INFO 12-04 10:17:45 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.59s/it, est. speed input: 21.12 toks/s, output: 25.10 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.59s/it, est. speed input: 21.12 toks/s, output: 25.10 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.59s/it, est. speed input: 21.12 toks/s, output: 25.10 toks/s]
Agent 1 response: The calculation follows standard arithmetic rules:  
17 + (25 × 8) + 25 - (20 × 1) = 17 + 200 + 25 -...

--- Problem 12/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 804.59it/s]

[1;36m(EngineCore_DP0 pid=3071551)[0;0m INFO 12-04 10:17:58 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3071551)[0;0m INFO 12-04 10:17:59 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42433 backend=nccl
[W1204 10:17:59.107401283 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42433 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3071551)[0;0m INFO 12-04 10:17:59 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ERROR 12-04 10:18:00 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3071551)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3071551)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3071551)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3071551)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3071551)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3071551)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3071551)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3071551)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3071551)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3071551)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3071551)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3071551)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3071551)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3071551)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3071551)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3071551)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3071551)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3071551)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3071551)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3071551)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3071551)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3071551)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3071551)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3071551)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3071551)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3071551)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:18:00.929033114 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.42s/it, est. speed input: 25.49 toks/s, output: 25.05 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.42s/it, est. speed input: 25.49 toks/s, output: 25.05 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.42s/it, est. speed input: 25.49 toks/s, output: 25.05 toks/s]
Agent 2 response: The moon cannot count.  
A bell does not ring in silence.  
The path is not the path.  
222....

--- Problem 12/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 916.59it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.40s/it, est. speed input: 19.99 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.40s/it, est. speed input: 19.99 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.40s/it, est. speed input: 19.99 toks/s, output: 25.20 toks/s]
Agent 3 response: The calculation follows the order of operations: multiplication first, then addition and subtraction...

--- Problem 12/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 632.24it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:18:21 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:18:21 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:18:21 [model.py:1745] Using max model len 40960
INFO 12-04 10:18:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.28s/it, est. speed input: 30.09 toks/s, output: 25.05 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.28s/it, est. speed input: 30.09 toks/s, output: 25.05 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.28s/it, est. speed input: 30.09 toks/s, output: 25.05 toks/s]
Agent 1 response: The calculation adheres to standard order of operations:  
17 + (25 × 8) + 25 - (20 × 1) = 17 + 200 ...

--- Problem 12/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 430.36it/s]

[1;36m(EngineCore_DP0 pid=3072169)[0;0m INFO 12-04 10:18:37 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3072169)[0;0m INFO 12-04 10:18:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:33079 backend=nccl
[W1204 10:18:38.892516136 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:33079 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3072169)[0;0m INFO 12-04 10:18:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ERROR 12-04 10:18:38 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3072169)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3072169)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3072169)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3072169)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3072169)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3072169)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3072169)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3072169)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3072169)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3072169)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3072169)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072169)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3072169)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3072169)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3072169)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3072169)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072169)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3072169)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3072169)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3072169)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3072169)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3072169)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3072169)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072169)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3072169)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3072169)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:18:39.713051321 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.63s/it, est. speed input: 38.45 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.63s/it, est. speed input: 38.45 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.63s/it, est. speed input: 38.45 toks/s, output: 25.09 toks/s]
Agent 2 response: The wind does not read.  
A shadow has no weight.  
The question is not the answer.  
222....

--- Problem 12/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 639.77it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:19:00 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:19:00 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:19:00 [model.py:1745] Using max model len 40960
INFO 12-04 10:19:00 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.25s/it, est. speed input: 39.32 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.25s/it, est. speed input: 39.32 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.25s/it, est. speed input: 39.32 toks/s, output: 25.13 toks/s]
Agent 3 response: The calculation adheres to standard arithmetic rules (PEMDAS/BODMAS):  
17 + (25 × 8) + 25 - (20 × 1...
performance: 0.8333333333333334 0.1075828707279838

--- Problem 13/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 60%|██████    | 12/20 [49:50<20:12, 151.58s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1146.92it/s]

[1;36m(EngineCore_DP0 pid=3072771)[0;0m INFO 12-04 10:19:14 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3072771)[0;0m INFO 12-04 10:19:15 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37939 backend=nccl
[W1204 10:19:15.705622866 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37939 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3072771)[0;0m INFO 12-04 10:19:15 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ERROR 12-04 10:19:15 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3072771)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3072771)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3072771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3072771)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3072771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3072771)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3072771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3072771)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3072771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3072771)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3072771)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3072771)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3072771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3072771)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3072771)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3072771)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3072771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3072771)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3072771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3072771)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3072771)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3072771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3072771)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3072771)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:19:16.534220482 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.49s/it, est. speed input: 2.83 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.49s/it, est. speed input: 2.83 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.49s/it, est. speed input: 2.83 toks/s, output: 25.14 toks/s]
Agent 1 response: The result of the expression is calculated by following the order of operations: multiplication firs...

--- Problem 13/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1560.96it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:19:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:19:37 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:19:37 [model.py:1745] Using max model len 40960
INFO 12-04 10:19:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.79s/it, est. speed input: 4.71 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.79s/it, est. speed input: 4.71 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.79s/it, est. speed input: 4.71 toks/s, output: 25.14 toks/s]
Agent 2 response: What is the sound of one hand clapping?  
The moon reflects the sun's light.  
Where does the path e...

--- Problem 13/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1302.58it/s]

[1;36m(EngineCore_DP0 pid=3073909)[0;0m INFO 12-04 10:19:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3073909)[0;0m INFO 12-04 10:19:50 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:57057 backend=nccl
[W1204 10:19:50.280037743 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:57057 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3073909)[0;0m INFO 12-04 10:19:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ERROR 12-04 10:19:51 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3073909)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3073909)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3073909)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3073909)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3073909)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3073909)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3073909)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3073909)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3073909)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3073909)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3073909)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3073909)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3073909)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3073909)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3073909)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3073909)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3073909)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3073909)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3073909)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3073909)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3073909)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3073909)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3073909)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3073909)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3073909)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3073909)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:19:51.099277195 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.77s/it, est. speed input: 3.34 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.77s/it, est. speed input: 3.34 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.77s/it, est. speed input: 3.34 toks/s, output: 25.16 toks/s]
Agent 3 response: Following the order of operations (PEMDAS/BODMAS):  
1. Calculate multiplications first:  
   - 27 *...

--- Problem 13/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 678.14it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:20:12 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:20:13 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:20:13 [model.py:1745] Using max model len 40960
INFO 12-04 10:20:13 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.14s/it, est. speed input: 36.30 toks/s, output: 24.96 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.14s/it, est. speed input: 36.30 toks/s, output: 24.96 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.14s/it, est. speed input: 36.30 toks/s, output: 24.96 toks/s]
Agent 1 response: The calculated result of the expression, adhering strictly to the order of operations, is confirmed ...

--- Problem 13/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 578.21it/s]

[1;36m(EngineCore_DP0 pid=3074509)[0;0m INFO 12-04 10:20:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3074509)[0;0m INFO 12-04 10:20:28 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34225 backend=nccl
[W1204 10:20:28.379357788 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34225 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3074509)[0;0m INFO 12-04 10:20:28 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ERROR 12-04 10:20:28 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3074509)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3074509)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3074509)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3074509)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3074509)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3074509)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3074509)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3074509)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3074509)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3074509)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3074509)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3074509)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3074509)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3074509)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3074509)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3074509)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3074509)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3074509)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3074509)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3074509)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3074509)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3074509)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3074509)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3074509)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3074509)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3074509)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:20:28.202207956 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:20:49 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:20:49 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:20:49 [model.py:1745] Using max model len 40960
INFO 12-04 10:20:49 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.41s/it, est. speed input: 14.84 toks/s, output: 25.02 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.41s/it, est. speed input: 14.84 toks/s, output: 25.02 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.41s/it, est. speed input: 14.84 toks/s, output: 25.02 toks/s]
Agent 2 response: The river flows upward.  
A stone is not a stone.  
What is the shadow of a shadow?  

358....

--- Problem 13/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 459.55it/s]

[1;36m(EngineCore_DP0 pid=3075193)[0;0m INFO 12-04 10:21:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3075193)[0;0m INFO 12-04 10:21:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:54905 backend=nccl
[W1204 10:21:02.072510744 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:54905 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3075193)[0;0m INFO 12-04 10:21:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ERROR 12-04 10:21:03 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3075193)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3075193)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3075193)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3075193)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3075193)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3075193)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3075193)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3075193)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3075193)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3075193)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3075193)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075193)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3075193)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3075193)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3075193)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3075193)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075193)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3075193)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3075193)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3075193)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3075193)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3075193)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3075193)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075193)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3075193)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3075193)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:21:03.882876536 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.72s/it, est. speed input: 17.89 toks/s, output: 25.04 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.72s/it, est. speed input: 17.89 toks/s, output: 25.04 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.72s/it, est. speed input: 17.89 toks/s, output: 25.04 toks/s]
Agent 3 response: The calculation follows standard order of operations (multiplication first, then left-to-right addit...

--- Problem 13/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 483.88it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:21:24 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:21:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:21:24 [model.py:1745] Using max model len 40960
INFO 12-04 10:21:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3075789)[0;0m INFO 12-04 10:21:38 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.29s/it, est. speed input: 46.64 toks/s, output: 24.98 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.29s/it, est. speed input: 46.64 toks/s, output: 24.98 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.29s/it, est. speed input: 46.64 toks/s, output: 24.98 toks/s]
Agent 1 response: The calculation remains consistent with the order of operations: multiplication first, then addition...

--- Problem 13/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 347.12it/s]

[1;36m(EngineCore_DP0 pid=3075789)[0;0m INFO 12-04 10:21:39 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42463 backend=nccl
[W1204 10:21:39.899466282 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42463 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3075789)[0;0m INFO 12-04 10:21:39 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ERROR 12-04 10:21:39 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3075789)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3075789)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3075789)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3075789)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3075789)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3075789)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3075789)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3075789)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3075789)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3075789)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3075789)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075789)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3075789)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3075789)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3075789)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3075789)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075789)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3075789)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3075789)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3075789)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3075789)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3075789)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3075789)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3075789)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3075789)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3075789)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:21:40.721456379 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.23s/it, est. speed input: 57.76 toks/s, output: 25.02 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.23s/it, est. speed input: 57.76 toks/s, output: 25.02 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.23s/it, est. speed input: 57.76 toks/s, output: 25.02 toks/s]
Agent 2 response: The clock ticks without hands.  
A whisper echoes in the void.  
What is the color of silence?  

35...

--- Problem 13/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 502.49it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:22:01 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:22:01 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:22:01 [model.py:1745] Using max model len 40960
INFO 12-04 10:22:01 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.22s/it, est. speed input: 44.19 toks/s, output: 25.02 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.22s/it, est. speed input: 44.19 toks/s, output: 25.02 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.22s/it, est. speed input: 44.19 toks/s, output: 25.02 toks/s]
Agent 3 response: The expression evaluates to **358** through standard arithmetic rules (multiplication first, then le...
performance: 0.8461538461538461 0.10006825162892168

--- Problem 14/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 65%|██████▌   | 13/20 [52:56<18:52, 161.73s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1167.68it/s]

[1;36m(EngineCore_DP0 pid=3076392)[0;0m INFO 12-04 10:22:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3076392)[0;0m INFO 12-04 10:22:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50215 backend=nccl
[W1204 10:22:14.672837476 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50215 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3076392)[0;0m INFO 12-04 10:22:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ERROR 12-04 10:22:14 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3076392)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3076392)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3076392)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3076392)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3076392)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3076392)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3076392)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3076392)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3076392)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3076392)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3076392)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3076392)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3076392)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3076392)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3076392)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3076392)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3076392)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3076392)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3076392)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3076392)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3076392)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3076392)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3076392)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3076392)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3076392)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3076392)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:22:15.493718112 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:22:36 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:22:36 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:22:36 [model.py:1745] Using max model len 40960
INFO 12-04 10:22:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.46s/it, est. speed input: 2.60 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.46s/it, est. speed input: 2.60 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.46s/it, est. speed input: 2.60 toks/s, output: 25.16 toks/s]
Agent 1 response: The result of 28 + 7*14 + 2 - 13*16 is calculated by following the order of operations (multiplicati...

--- Problem 14/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1141.31it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.95s/it, est. speed input: 6.52 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.95s/it, est. speed input: 6.52 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.96s/it, est. speed input: 6.52 toks/s, output: 25.09 toks/s]
Agent 2 response: The river flows upstream. Silence holds the echo. The answer is -80....

--- Problem 14/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1142.86it/s]

[1;36m(EngineCore_DP0 pid=3077526)[0;0m INFO 12-04 10:22:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3077526)[0;0m INFO 12-04 10:22:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:56403 backend=nccl
[W1204 10:22:51.357264051 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:56403 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3077526)[0;0m INFO 12-04 10:22:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ERROR 12-04 10:22:51 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3077526)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3077526)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3077526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3077526)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3077526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3077526)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3077526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3077526)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3077526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3077526)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3077526)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3077526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3077526)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3077526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3077526)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3077526)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3077526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3077526)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3077526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3077526)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3077526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3077526)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3077526)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3077526)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3077526)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3077526)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:22:51.170304553 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.44s/it, est. speed input: 3.50 toks/s, output: 25.19 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.44s/it, est. speed input: 3.50 toks/s, output: 25.19 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.44s/it, est. speed input: 3.50 toks/s, output: 25.19 toks/s]
Agent 3 response: The result of 28 + 7*14 + 2 - 13*16 is calculated by following the order of operations (multiplicati...

--- Problem 14/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 660.62it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:23:12 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:23:12 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:23:12 [model.py:1745] Using max model len 40960
INFO 12-04 10:23:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3078127)[0;0m INFO 12-04 10:23:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3078127)[0;0m INFO 12-04 10:23:25 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42423 backend=nccl
[W1204 10:23:25.963715208 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42423 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3078127)[0;0m INFO 12-04 10:23:25 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ERROR 12-04 10:23:25 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3078127)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3078127)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3078127)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3078127)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3078127)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3078127)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3078127)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3078127)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3078127)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3078127)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3078127)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078127)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3078127)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3078127)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3078127)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3078127)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078127)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3078127)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3078127)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3078127)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3078127)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3078127)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3078127)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078127)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3078127)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3078127)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:23:26.787871972 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.68s/it, est. speed input: 25.91 toks/s, output: 24.95 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.68s/it, est. speed input: 25.91 toks/s, output: 24.95 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.68s/it, est. speed input: 25.91 toks/s, output: 24.95 toks/s]
Agent 1 response: The calculations align with the order of operations (multiplication first, then left-to-right additi...

--- Problem 14/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 706.23it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.43s/it, est. speed input: 34.39 toks/s, output: 25.08 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.43s/it, est. speed input: 34.39 toks/s, output: 25.08 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.43s/it, est. speed input: 34.39 toks/s, output: 25.08 toks/s]
Agent 2 response: The wind does not choose the mountain.  
The moon reflects the sky’s silence.  
The answer is -80....

--- Problem 14/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 716.49it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:23:47 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:23:47 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:23:47 [model.py:1745] Using max model len 40960
INFO 12-04 10:23:47 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3078740)[0;0m INFO 12-04 10:24:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.13s/it, est. speed input: 22.80 toks/s, output: 24.98 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.13s/it, est. speed input: 22.80 toks/s, output: 24.98 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.13s/it, est. speed input: 22.80 toks/s, output: 24.98 toks/s]
Agent 3 response: The calculation follows standard order of operations:  
1. Multiplication: 7×14 = 98 and 13×16 = 208...

--- Problem 14/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 281.89it/s]

[1;36m(EngineCore_DP0 pid=3078740)[0;0m INFO 12-04 10:24:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:56979 backend=nccl
[W1204 10:24:02.674648763 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:56979 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3078740)[0;0m INFO 12-04 10:24:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ERROR 12-04 10:24:02 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3078740)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3078740)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3078740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3078740)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3078740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3078740)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3078740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3078740)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3078740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3078740)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3078740)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3078740)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3078740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3078740)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3078740)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3078740)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3078740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3078740)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3078740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3078740)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3078740)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3078740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3078740)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3078740)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:24:03.505872293 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.36s/it, est. speed input: 40.45 toks/s, output: 25.01 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.36s/it, est. speed input: 40.45 toks/s, output: 25.01 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.36s/it, est. speed input: 40.45 toks/s, output: 25.01 toks/s]
Agent 1 response: The calculation adheres to standard mathematical order of operations:  
1. Multiplication: 7×14 = 98...

--- Problem 14/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 470.79it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:24:24 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:24:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:24:24 [model.py:1745] Using max model len 40960
INFO 12-04 10:24:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.80s/it, est. speed input: 66.67 toks/s, output: 24.91 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.80s/it, est. speed input: 66.67 toks/s, output: 24.91 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.80s/it, est. speed input: 66.67 toks/s, output: 24.91 toks/s]
Agent 2 response: The stone does not question the path.  
The flame forgets its own heat.  
The answer is -80....

--- Problem 14/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 341.72it/s]

[1;36m(EngineCore_DP0 pid=3079355)[0;0m INFO 12-04 10:24:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3079355)[0;0m INFO 12-04 10:24:37 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:40661 backend=nccl
[W1204 10:24:37.650747395 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:40661 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3079355)[0;0m INFO 12-04 10:24:37 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ERROR 12-04 10:24:37 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3079355)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3079355)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3079355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3079355)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3079355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3079355)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3079355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3079355)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3079355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3079355)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3079355)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3079355)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3079355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3079355)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3079355)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3079355)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3079355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3079355)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3079355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3079355)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3079355)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079355)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3079355)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3079355)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:24:38.483741802 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.70s/it, est. speed input: 41.92 toks/s, output: 24.97 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.70s/it, est. speed input: 41.92 toks/s, output: 24.97 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.70s/it, est. speed input: 41.92 toks/s, output: 24.97 toks/s]
Agent 3 response: The calculation adheres to standard mathematical rules:  
1. **Multiplication first**: 7×14 = 98 and...
performance: 0.8571428571428571 0.09352195295828246

--- Problem 15/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 70%|███████   | 14/20 [55:38<16:12, 162.11s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1474.79it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:24:59 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:24:59 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:24:59 [model.py:1745] Using max model len 40960
INFO 12-04 10:24:59 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.41s/it, est. speed input: 4.39 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.41s/it, est. speed input: 4.39 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.41s/it, est. speed input: 4.39 toks/s, output: 25.11 toks/s]
Agent 1 response: Following the order of operations (multiplication before addition/subtraction):  
3 + (17 * 7) + 3 -...

--- Problem 15/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1414.61it/s]

[1;36m(EngineCore_DP0 pid=3079958)[0;0m INFO 12-04 10:25:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3079958)[0;0m INFO 12-04 10:25:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45817 backend=nccl
[W1204 10:25:13.122194450 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45817 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3079958)[0;0m INFO 12-04 10:25:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ERROR 12-04 10:25:14 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3079958)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3079958)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3079958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3079958)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3079958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3079958)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3079958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3079958)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3079958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3079958)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3079958)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3079958)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3079958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3079958)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3079958)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3079958)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3079958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3079958)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3079958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3079958)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3079958)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3079958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3079958)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3079958)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:25:14.950263589 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.48s/it, est. speed input: 6.09 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.48s/it, est. speed input: 6.09 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.48s/it, est. speed input: 6.09 toks/s, output: 25.07 toks/s]
Agent 2 response: The moon is a stone.  
The stone is a question.  
What is the question?  
96....

--- Problem 15/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1531.33it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:25:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:25:35 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:25:35 [model.py:1745] Using max model len 40960
INFO 12-04 10:25:35 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.34s/it, est. speed input: 3.27 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.34s/it, est. speed input: 3.27 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.34s/it, est. speed input: 3.27 toks/s, output: 25.16 toks/s]
Agent 3 response: The result of 3 + 17*7 + 3 - 1*29 is calculated by following the order of operations (multiplication...

--- Problem 15/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 652.81it/s]

[1;36m(EngineCore_DP0 pid=3081210)[0;0m INFO 12-04 10:25:48 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3081210)[0;0m INFO 12-04 10:25:50 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50465 backend=nccl
[W1204 10:25:50.329080031 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50465 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3081210)[0;0m INFO 12-04 10:25:50 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ERROR 12-04 10:25:50 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3081210)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3081210)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3081210)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3081210)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3081210)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3081210)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3081210)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3081210)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3081210)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3081210)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3081210)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081210)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3081210)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3081210)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3081210)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3081210)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081210)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3081210)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3081210)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3081210)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3081210)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3081210)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3081210)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081210)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3081210)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3081210)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:25:50.144159074 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.27s/it, est. speed input: 31.29 toks/s, output: 25.02 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.27s/it, est. speed input: 31.29 toks/s, output: 25.02 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.27s/it, est. speed input: 31.29 toks/s, output: 25.02 toks/s]
Agent 1 response: The calculation follows standard order of operations, confirming the result is **96**. The poetic an...

--- Problem 15/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 762.46it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.39s/it, est. speed input: 28.97 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.39s/it, est. speed input: 28.97 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.39s/it, est. speed input: 28.97 toks/s, output: 25.16 toks/s]
Agent 2 response: The sky is a clock.  
The clock is a whisper.  
What is the whisper?  
96....

--- Problem 15/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 776.15it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:26:11 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:26:11 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:26:11 [model.py:1745] Using max model len 40960
INFO 12-04 10:26:11 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3081811)[0;0m INFO 12-04 10:26:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.11s/it, est. speed input: 22.50 toks/s, output: 25.01 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.11s/it, est. speed input: 22.50 toks/s, output: 25.01 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.11s/it, est. speed input: 22.50 toks/s, output: 25.01 toks/s]
Agent 3 response: The calculation follows standard order of operations: multiplication first, then addition/subtractio...

--- Problem 15/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 361.05it/s]

[1;36m(EngineCore_DP0 pid=3081811)[0;0m INFO 12-04 10:26:25 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:48913 backend=nccl
[W1204 10:26:25.288331940 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:48913 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3081811)[0;0m INFO 12-04 10:26:26 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ERROR 12-04 10:26:26 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3081811)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3081811)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3081811)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3081811)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3081811)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3081811)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3081811)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3081811)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3081811)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3081811)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3081811)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081811)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3081811)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3081811)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3081811)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3081811)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081811)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3081811)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3081811)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3081811)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3081811)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3081811)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3081811)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3081811)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3081811)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3081811)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:26:26.104561442 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.04s/it, est. speed input: 34.81 toks/s, output: 25.12 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.04s/it, est. speed input: 34.81 toks/s, output: 25.12 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.04s/it, est. speed input: 34.81 toks/s, output: 25.12 toks/s]
Agent 1 response: The mathematical process and poetic metaphors both align with the consistent result of **96**. The c...

--- Problem 15/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 563.45it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:26:47 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:26:48 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:26:48 [model.py:1745] Using max model len 40960
INFO 12-04 10:26:48 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.26s/it, est. speed input: 53.03 toks/s, output: 25.05 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.26s/it, est. speed input: 53.03 toks/s, output: 25.05 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.26s/it, est. speed input: 53.03 toks/s, output: 25.05 toks/s]
Agent 2 response: The river is a mirror.  
The mirror reflects the code.  
What is the code?  
96....

--- Problem 15/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 321.99it/s]

[1;36m(EngineCore_DP0 pid=3082409)[0;0m INFO 12-04 10:27:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3082409)[0;0m INFO 12-04 10:27:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:56907 backend=nccl
[W1204 10:27:02.491859373 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:56907 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3082409)[0;0m INFO 12-04 10:27:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ERROR 12-04 10:27:02 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3082409)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3082409)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3082409)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3082409)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3082409)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3082409)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3082409)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3082409)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3082409)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3082409)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3082409)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3082409)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3082409)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3082409)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3082409)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3082409)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3082409)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3082409)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3082409)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3082409)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3082409)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3082409)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3082409)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3082409)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3082409)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3082409)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:27:03.315172864 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.47s/it, est. speed input: 27.67 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.47s/it, est. speed input: 27.67 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.47s/it, est. speed input: 27.67 toks/s, output: 25.06 toks/s]
Agent 3 response: The calculation adheres to standard order of operations, confirming the result is **96**. The poetic...
performance: 0.8666666666666667 0.0877707451472511

--- Problem 16/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 75%|███████▌  | 15/20 [58:02<13:02, 156.59s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1371.14it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:27:23 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:27:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:27:24 [model.py:1745] Using max model len 40960
INFO 12-04 10:27:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3083010)[0;0m INFO 12-04 10:27:37 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3083010)[0;0m INFO 12-04 10:27:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51499 backend=nccl
[W1204 10:27:38.746437465 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51499 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3083010)[0;0m INFO 12-04 10:27:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ERROR 12-04 10:27:38 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3083010)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3083010)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3083010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3083010)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3083010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3083010)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3083010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3083010)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3083010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3083010)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3083010)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3083010)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3083010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3083010)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3083010)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3083010)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3083010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3083010)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3083010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3083010)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3083010)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3083010)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3083010)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:27:39.565905130 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.42s/it, est. speed input: 2.48 toks/s, output: 25.12 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.42s/it, est. speed input: 2.48 toks/s, output: 25.12 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.42s/it, est. speed input: 2.48 toks/s, output: 25.12 toks/s]
Agent 1 response: The result of 5 + 21*9 + 3 - 21*28 is calculated by following the order of operations (PEMDAS/BODMAS...

--- Problem 16/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1514.19it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.68s/it, est. speed input: 6.07 toks/s, output: 25.23 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.68s/it, est. speed input: 6.07 toks/s, output: 25.23 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.68s/it, est. speed input: 6.07 toks/s, output: 25.23 toks/s]
Agent 2 response: The moon reflects the sun's light, yet remains silent.  
The answer is -391....

--- Problem 16/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1586.95it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:28:00 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:28:00 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:28:00 [model.py:1745] Using max model len 40960
INFO 12-04 10:28:00 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3083613)[0;0m INFO 12-04 10:28:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3083613)[0;0m INFO 12-04 10:28:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60765 backend=nccl
[W1204 10:28:13.957770653 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60765 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3083613)[0;0m INFO 12-04 10:28:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ERROR 12-04 10:28:13 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3083613)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3083613)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3083613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3083613)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3083613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3083613)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3083613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3083613)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3083613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3083613)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3083613)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3083613)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3083613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3083613)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3083613)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3083613)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3083613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3083613)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3083613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3083613)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3083613)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3083613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3083613)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3083613)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:28:14.770837923 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.91s/it, est. speed input: 3.91 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.91s/it, est. speed input: 3.91 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.91s/it, est. speed input: 3.91 toks/s, output: 25.07 toks/s]
Agent 3 response: The result of 5 + 21*9 + 3 - 21*28 is calculated as follows:  
21*9 = 189, 21*28 = 588. Substituting...

--- Problem 16/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 722.91it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.48s/it, est. speed input: 33.56 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.48s/it, est. speed input: 33.56 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.49s/it, est. speed input: 33.56 toks/s, output: 25.15 toks/s]
Agent 1 response: The calculation adheres to standard arithmetic rules, prioritizing multiplication before addition/su...

--- Problem 16/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 724.53it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:28:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:28:35 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:28:35 [model.py:1745] Using max model len 40960
INFO 12-04 10:28:35 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.09s/it, est. speed input: 38.14 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.09s/it, est. speed input: 38.14 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.09s/it, est. speed input: 38.14 toks/s, output: 25.07 toks/s]
Agent 2 response: The river flows to the sea, yet the sea is never full.  
The answer is -391....

--- Problem 16/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 557.09it/s]

[1;36m(EngineCore_DP0 pid=3084763)[0;0m INFO 12-04 10:28:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3084763)[0;0m INFO 12-04 10:28:50 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42773 backend=nccl
[W1204 10:28:50.901896101 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42773 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3084763)[0;0m INFO 12-04 10:28:50 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ERROR 12-04 10:28:50 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3084763)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3084763)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3084763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3084763)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3084763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3084763)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3084763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3084763)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3084763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3084763)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3084763)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3084763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3084763)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3084763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3084763)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3084763)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3084763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3084763)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3084763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3084763)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3084763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3084763)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3084763)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3084763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3084763)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3084763)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:28:51.717733764 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.04s/it, est. speed input: 29.91 toks/s, output: 24.99 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.04s/it, est. speed input: 29.91 toks/s, output: 24.99 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.04s/it, est. speed input: 29.91 toks/s, output: 24.99 toks/s]
Agent 3 response: The calculation follows standard order of operations (multiplication before addition/subtraction):  ...

--- Problem 16/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 503.03it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:29:12 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:29:12 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:29:12 [model.py:1745] Using max model len 40960
INFO 12-04 10:29:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.20s/it, est. speed input: 35.89 toks/s, output: 25.10 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.20s/it, est. speed input: 35.89 toks/s, output: 25.10 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.20s/it, est. speed input: 35.89 toks/s, output: 25.10 toks/s]
Agent 1 response: The arithmetic expression adheres to standard order of operations (multiplication first, then additi...

--- Problem 16/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 407.69it/s]

[1;36m(EngineCore_DP0 pid=3085364)[0;0m INFO 12-04 10:29:23 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.47s/it, est. speed input: 76.99 toks/s, output: 24.92 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.47s/it, est. speed input: 76.99 toks/s, output: 24.92 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.47s/it, est. speed input: 76.99 toks/s, output: 24.92 toks/s]
Agent 2 response: The wind does not carry the scent of the mountain.  
The answer is -391....

--- Problem 16/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 417.34it/s]

[1;36m(EngineCore_DP0 pid=3085364)[0;0m INFO 12-04 10:29:24 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:39639 backend=nccl
[W1204 10:29:24.075252046 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:39639 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3085364)[0;0m INFO 12-04 10:29:24 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ERROR 12-04 10:29:25 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3085364)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3085364)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3085364)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3085364)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3085364)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3085364)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3085364)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3085364)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3085364)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3085364)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3085364)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085364)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3085364)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3085364)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3085364)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3085364)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085364)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3085364)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3085364)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3085364)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3085364)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3085364)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3085364)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085364)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3085364)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3085364)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:29:25.892117042 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.33s/it, est. speed input: 35.71 toks/s, output: 25.03 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.33s/it, est. speed input: 35.71 toks/s, output: 25.03 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.33s/it, est. speed input: 35.71 toks/s, output: 25.03 toks/s]
Agent 3 response: The arithmetic follows standard order of operations (multiplication before addition/subtraction):  
...
performance: 0.875 0.08267972847076846

--- Problem 17/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 80%|████████  | 16/20 [1:00:31<10:16, 154.20s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1433.46it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:29:46 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:29:46 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:29:46 [model.py:1745] Using max model len 40960
INFO 12-04 10:29:46 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.59s/it, est. speed input: 4.46 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.59s/it, est. speed input: 4.46 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.59s/it, est. speed input: 4.46 toks/s, output: 25.07 toks/s]
Agent 1 response: The result of the expression 17 + 25*11 + 1 - 9*29 is 32.  
Answer: 32....

--- Problem 17/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1228.56it/s]

[1;36m(EngineCore_DP0 pid=3085974)[0;0m INFO 12-04 10:30:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3085974)[0;0m INFO 12-04 10:30:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47005 backend=nccl
[W1204 10:30:02.047023504 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47005 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3085974)[0;0m INFO 12-04 10:30:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ERROR 12-04 10:30:03 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3085974)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3085974)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3085974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3085974)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3085974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3085974)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3085974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3085974)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3085974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3085974)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3085974)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3085974)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3085974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3085974)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3085974)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3085974)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3085974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3085974)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3085974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3085974)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3085974)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3085974)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3085974)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3085974)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:30:03.881446946 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.13s/it, est. speed input: 3.87 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.13s/it, est. speed input: 3.87 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.13s/it, est. speed input: 3.87 toks/s, output: 25.14 toks/s]
Agent 2 response: The moon does not illuminate the stone. The stone does not ask why. The answer is thirty-two....

--- Problem 17/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1474.79it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:30:24 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:30:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:30:24 [model.py:1745] Using max model len 40960
INFO 12-04 10:30:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.76s/it, est. speed input: 6.38 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.76s/it, est. speed input: 6.38 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.76s/it, est. speed input: 6.38 toks/s, output: 25.09 toks/s]
Agent 3 response: The result is 32....

--- Problem 17/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 744.07it/s]

[1;36m(EngineCore_DP0 pid=3086655)[0;0m INFO 12-04 10:30:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3086655)[0;0m INFO 12-04 10:30:37 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:41679 backend=nccl
[W1204 10:30:37.775969209 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:41679 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3086655)[0;0m INFO 12-04 10:30:37 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ERROR 12-04 10:30:37 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3086655)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3086655)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3086655)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3086655)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3086655)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3086655)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3086655)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3086655)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3086655)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3086655)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3086655)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3086655)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3086655)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3086655)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3086655)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3086655)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3086655)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3086655)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3086655)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3086655)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3086655)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3086655)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3086655)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3086655)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3086655)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3086655)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:30:38.611297349 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.90s/it, est. speed input: 20.41 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.90s/it, est. speed input: 20.41 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.90s/it, est. speed input: 20.41 toks/s, output: 25.06 toks/s]
Agent 1 response: The calculation adheres to standard arithmetic rules, confirming the result as 32. The consensus amo...

--- Problem 17/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 974.51it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:30:59 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:30:59 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:30:59 [model.py:1745] Using max model len 40960
INFO 12-04 10:30:59 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.85s/it, est. speed input: 12.22 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.85s/it, est. speed input: 12.22 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.85s/it, est. speed input: 12.22 toks/s, output: 25.22 toks/s]
Agent 2 response: The river does not remember the source. The source does not ask for silence. The answer is thirty-tw...

--- Problem 17/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 775.00it/s]

[1;36m(EngineCore_DP0 pid=3087296)[0;0m INFO 12-04 10:31:13 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.56s/it, est. speed input: 13.05 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.56s/it, est. speed input: 13.05 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.56s/it, est. speed input: 13.05 toks/s, output: 25.06 toks/s]
Agent 3 response: The result of the expression is 32.  
Answer: 32....

--- Problem 17/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 498.79it/s]

[1;36m(EngineCore_DP0 pid=3087296)[0;0m INFO 12-04 10:31:15 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:53709 backend=nccl
[W1204 10:31:15.593991763 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:53709 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3087296)[0;0m INFO 12-04 10:31:15 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ERROR 12-04 10:31:15 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3087296)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3087296)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3087296)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3087296)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3087296)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3087296)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3087296)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3087296)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3087296)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3087296)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3087296)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3087296)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3087296)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3087296)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3087296)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3087296)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3087296)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3087296)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3087296)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3087296)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3087296)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3087296)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3087296)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3087296)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3087296)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3087296)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:31:16.414935059 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.18s/it, est. speed input: 30.94 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.18s/it, est. speed input: 30.94 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.18s/it, est. speed input: 30.94 toks/s, output: 25.13 toks/s]
Agent 1 response: The consistent consensus among agents and the arithmetic validation reaffirm the result as 32.  
Ans...

--- Problem 17/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 686.92it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:31:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:31:37 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:31:37 [model.py:1745] Using max model len 40960
INFO 12-04 10:31:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.63s/it, est. speed input: 27.70 toks/s, output: 25.17 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.63s/it, est. speed input: 27.70 toks/s, output: 25.17 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.64s/it, est. speed input: 27.70 toks/s, output: 25.17 toks/s]
Agent 2 response: The wind does not measure the mountain. The mountain does not seek the breeze. The answer is thirty-...

--- Problem 17/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 587.60it/s]

[1;36m(EngineCore_DP0 pid=3088430)[0;0m INFO 12-04 10:31:48 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3088430)[0;0m INFO 12-04 10:31:50 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55813 backend=nccl
[W1204 10:31:50.469225039 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55813 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3088430)[0;0m INFO 12-04 10:31:50 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ERROR 12-04 10:31:50 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3088430)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3088430)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3088430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3088430)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3088430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3088430)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3088430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3088430)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3088430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3088430)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3088430)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3088430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3088430)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3088430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3088430)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3088430)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3088430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3088430)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3088430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3088430)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3088430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3088430)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3088430)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3088430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3088430)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3088430)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:31:50.287302133 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.44s/it, est. speed input: 25.82 toks/s, output: 25.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.44s/it, est. speed input: 25.82 toks/s, output: 25.00 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.44s/it, est. speed input: 25.82 toks/s, output: 25.00 toks/s]
Agent 3 response: The calculation follows standard arithmetic rules, with multiplication prioritized over addition and...
performance: 0.8823529411764706 0.07814248990059663

--- Problem 18/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 85%|████████▌ | 17/20 [1:02:39<07:19, 146.34s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1423.25it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.75s/it, est. speed input: 4.17 toks/s, output: 25.24 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.75s/it, est. speed input: 4.17 toks/s, output: 25.24 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.75s/it, est. speed input: 4.17 toks/s, output: 25.24 toks/s]
Agent 1 response: The result of the expression is 121....

--- Problem 18/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1454.34it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:32:11 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:32:12 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:32:12 [model.py:1745] Using max model len 40960
INFO 12-04 10:32:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3089030)[0;0m INFO 12-04 10:32:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3089030)[0;0m INFO 12-04 10:32:26 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42921 backend=nccl
[W1204 10:32:26.581545383 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42921 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3089030)[0;0m INFO 12-04 10:32:26 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ERROR 12-04 10:32:26 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3089030)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3089030)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3089030)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3089030)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3089030)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3089030)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3089030)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3089030)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3089030)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3089030)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3089030)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089030)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3089030)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3089030)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3089030)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3089030)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089030)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3089030)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3089030)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3089030)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3089030)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3089030)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3089030)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089030)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3089030)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3089030)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:32:27.403170216 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.02s/it, est. speed input: 4.10 toks/s, output: 25.08 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.02s/it, est. speed input: 4.10 toks/s, output: 25.08 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.02s/it, est. speed input: 4.10 toks/s, output: 25.08 toks/s]
Agent 2 response: The moon reflects the sun's light.  
The sound of one hand clapping.  
A bell without a sound.  
121...

--- Problem 18/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1483.66it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.52s/it, est. speed input: 4.54 toks/s, output: 25.24 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.52s/it, est. speed input: 4.54 toks/s, output: 25.24 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.52s/it, est. speed input: 4.54 toks/s, output: 25.24 toks/s]
Agent 3 response: The calculation follows the order of operations: multiplication first, then addition and subtraction...

--- Problem 18/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 799.22it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:32:48 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:32:48 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:32:48 [model.py:1745] Using max model len 40960
INFO 12-04 10:32:48 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.68s/it, est. speed input: 21.25 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.68s/it, est. speed input: 21.25 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.68s/it, est. speed input: 21.25 toks/s, output: 25.07 toks/s]
Agent 1 response: The calculation follows the order of operations: multiplication first, then addition and subtraction...

--- Problem 18/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 552.03it/s]

[1;36m(EngineCore_DP0 pid=3089627)[0;0m INFO 12-04 10:33:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3089627)[0;0m INFO 12-04 10:33:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44793 backend=nccl
[W1204 10:33:02.628578882 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44793 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3089627)[0;0m INFO 12-04 10:33:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ERROR 12-04 10:33:02 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3089627)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3089627)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3089627)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3089627)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3089627)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3089627)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3089627)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3089627)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3089627)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3089627)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3089627)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089627)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3089627)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3089627)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3089627)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3089627)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089627)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3089627)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3089627)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3089627)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3089627)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3089627)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3089627)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3089627)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3089627)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3089627)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:33:03.458412765 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.30s/it, est. speed input: 23.76 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.30s/it, est. speed input: 23.76 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.30s/it, est. speed input: 23.76 toks/s, output: 25.11 toks/s]
Agent 2 response: The river flows uphill.  
A stone cannot be both smooth and rough.  
121....

--- Problem 18/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 777.30it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:33:24 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:33:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:33:24 [model.py:1745] Using max model len 40960
INFO 12-04 10:33:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.76s/it, est. speed input: 22.75 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.76s/it, est. speed input: 22.75 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.76s/it, est. speed input: 22.75 toks/s, output: 25.15 toks/s]
Agent 3 response: The calculation confirms the result is **121**, as all steps and agent responses align with this val...

--- Problem 18/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 342.53it/s]

[1;36m(EngineCore_DP0 pid=3090244)[0;0m INFO 12-04 10:33:37 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3090244)[0;0m INFO 12-04 10:33:39 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:59571 backend=nccl
[W1204 10:33:39.348310227 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:59571 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3090244)[0;0m INFO 12-04 10:33:39 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ERROR 12-04 10:33:39 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3090244)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3090244)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3090244)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3090244)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3090244)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3090244)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3090244)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3090244)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3090244)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3090244)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3090244)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090244)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3090244)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3090244)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3090244)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3090244)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090244)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3090244)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3090244)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3090244)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3090244)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3090244)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3090244)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090244)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3090244)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3090244)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:33:39.176813178 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.32s/it, est. speed input: 40.64 toks/s, output: 24.93 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.32s/it, est. speed input: 40.64 toks/s, output: 24.93 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.32s/it, est. speed input: 40.64 toks/s, output: 24.93 toks/s]
Agent 1 response: The calculation remains consistent with previous steps:  
1. **13 * 15 = 195**  
2. **7 * 13 = 91** ...

--- Problem 18/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 544.71it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.92s/it, est. speed input: 42.11 toks/s, output: 25.08 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.92s/it, est. speed input: 42.11 toks/s, output: 25.08 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.92s/it, est. speed input: 42.11 toks/s, output: 25.08 toks/s]
Agent 2 response: The wind does not know the shape of the mountain.  
A shadow without a source.  
121....

--- Problem 18/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 551.16it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:34:00 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:34:01 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:34:01 [model.py:1745] Using max model len 40960
INFO 12-04 10:34:01 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.09s/it, est. speed input: 52.58 toks/s, output: 24.98 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.09s/it, est. speed input: 52.58 toks/s, output: 24.98 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.09s/it, est. speed input: 52.58 toks/s, output: 24.98 toks/s]
Agent 3 response: The calculation aligns with the order of operations (multiplication first, then addition/subtraction...
performance: 0.8333333333333334 0.08784104611578833

--- Problem 19/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 90%|█████████ | 18/20 [1:04:53<04:45, 142.75s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1118.78it/s]

[1;36m(EngineCore_DP0 pid=3090859)[0;0m INFO 12-04 10:34:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3090859)[0;0m INFO 12-04 10:34:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44575 backend=nccl
[W1204 10:34:13.113041707 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44575 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3090859)[0;0m INFO 12-04 10:34:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ERROR 12-04 10:34:14 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3090859)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3090859)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3090859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3090859)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3090859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3090859)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3090859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3090859)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3090859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3090859)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3090859)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3090859)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3090859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3090859)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3090859)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3090859)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3090859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3090859)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3090859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3090859)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3090859)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3090859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3090859)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3090859)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:34:14.947748430 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.71s/it, est. speed input: 2.61 toks/s, output: 25.12 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.71s/it, est. speed input: 2.61 toks/s, output: 25.12 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.71s/it, est. speed input: 2.61 toks/s, output: 25.12 toks/s]
Agent 1 response: The result of 22 + 27*24 + 29 - 7*20 is calculated by following the order of operations (multiplicat...

--- Problem 19/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1513.10it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:34:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:34:35 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:34:35 [model.py:1745] Using max model len 40960
INFO 12-04 10:34:35 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.25s/it, est. speed input: 5.96 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.25s/it, est. speed input: 5.96 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.25s/it, est. speed input: 5.96 toks/s, output: 25.06 toks/s]
Agent 2 response: The moon reflects the sun's light.  
A stone cannot sing.  
The answer is 559....

--- Problem 19/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1139.45it/s]

[1;36m(EngineCore_DP0 pid=3091995)[0;0m INFO 12-04 10:34:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3091995)[0;0m INFO 12-04 10:34:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:40339 backend=nccl
[W1204 10:34:51.589963568 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:40339 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3091995)[0;0m INFO 12-04 10:34:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ERROR 12-04 10:34:51 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3091995)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3091995)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3091995)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3091995)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3091995)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3091995)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3091995)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3091995)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3091995)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3091995)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3091995)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3091995)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3091995)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3091995)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3091995)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3091995)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3091995)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3091995)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3091995)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3091995)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3091995)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3091995)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3091995)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3091995)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3091995)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3091995)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:34:52.421189596 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:35:13 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:35:13 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:35:13 [model.py:1745] Using max model len 40960
INFO 12-04 10:35:13 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.97s/it, est. speed input: 3.04 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.97s/it, est. speed input: 3.04 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.98s/it, est. speed input: 3.04 toks/s, output: 25.15 toks/s]
Agent 3 response: The result of 22 + 27*24 + 29 - 7*20 is calculated as follows: first, perform the multiplications (2...

--- Problem 19/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 486.69it/s]

[1;36m(EngineCore_DP0 pid=3092636)[0;0m INFO 12-04 10:35:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.33s/it, est. speed input: 35.04 toks/s, output: 24.98 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.33s/it, est. speed input: 35.04 toks/s, output: 24.98 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.33s/it, est. speed input: 35.04 toks/s, output: 24.98 toks/s]
Agent 1 response: The calculation confirms the result is 559, as verified by both the order of operations and prior ag...

--- Problem 19/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 515.59it/s]

[1;36m(EngineCore_DP0 pid=3092636)[0;0m INFO 12-04 10:35:26 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:48643 backend=nccl
[W1204 10:35:26.526964987 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:48643 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3092636)[0;0m INFO 12-04 10:35:26 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ERROR 12-04 10:35:26 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3092636)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3092636)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3092636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3092636)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3092636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3092636)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3092636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3092636)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3092636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3092636)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3092636)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3092636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3092636)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3092636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3092636)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3092636)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3092636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3092636)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3092636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3092636)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3092636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3092636)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3092636)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3092636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3092636)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3092636)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:35:27.350358628 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.49s/it, est. speed input: 41.56 toks/s, output: 25.07 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.49s/it, est. speed input: 41.56 toks/s, output: 25.07 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.49s/it, est. speed input: 41.56 toks/s, output: 25.07 toks/s]
Agent 2 response: The river flows uphill.  
A shadow has no weight.  
The answer is 559....

--- Problem 19/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 697.08it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:35:48 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:35:48 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:35:48 [model.py:1745] Using max model len 40960
INFO 12-04 10:35:48 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.45s/it, est. speed input: 28.02 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.45s/it, est. speed input: 28.02 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.45s/it, est. speed input: 28.02 toks/s, output: 25.11 toks/s]
Agent 3 response: The calculation follows standard order of operations: multiplication first (27*24 = 648; 7*20 = 140)...

--- Problem 19/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 294.13it/s]

[1;36m(EngineCore_DP0 pid=3093313)[0;0m INFO 12-04 10:36:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3093313)[0;0m INFO 12-04 10:36:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38361 backend=nccl
[W1204 10:36:02.917621742 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38361 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3093313)[0;0m INFO 12-04 10:36:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ERROR 12-04 10:36:02 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3093313)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3093313)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3093313)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3093313)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3093313)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3093313)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3093313)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3093313)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3093313)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3093313)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3093313)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093313)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3093313)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3093313)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3093313)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3093313)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093313)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3093313)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3093313)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3093313)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3093313)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3093313)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3093313)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093313)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3093313)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3093313)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:36:03.730953463 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.60s/it, est. speed input: 41.66 toks/s, output: 24.99 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.60s/it, est. speed input: 41.66 toks/s, output: 24.99 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.60s/it, est. speed input: 41.66 toks/s, output: 24.99 toks/s]
Agent 1 response: The calculation adheres to standard mathematical rules (multiplication first, then sequential additi...

--- Problem 19/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 509.70it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.02s/it, est. speed input: 40.83 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.02s/it, est. speed input: 40.83 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.02s/it, est. speed input: 40.83 toks/s, output: 25.16 toks/s]
Agent 2 response: The mountain wears a crown of clouds.  
Even silence has a heartbeat.  
The answer is 559....

--- Problem 19/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 517.11it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:36:24 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:36:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:36:24 [model.py:1745] Using max model len 40960
INFO 12-04 10:36:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3093918)[0;0m INFO 12-04 10:36:37 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.84s/it, est. speed input: 43.88 toks/s, output: 25.01 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.84s/it, est. speed input: 43.88 toks/s, output: 25.01 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.84s/it, est. speed input: 43.88 toks/s, output: 25.01 toks/s]
Agent 3 response: The calculation adheres to the order of operations: multiplication (27*24 = 648; 7*20 = 140) first, ...
performance: 0.8421052631578947 0.08365467518305539

--- Problem 20/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 95%|█████████▌| 19/20 [1:07:25<02:25, 145.43s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1128.11it/s]

[1;36m(EngineCore_DP0 pid=3093918)[0;0m INFO 12-04 10:36:39 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51403 backend=nccl
[W1204 10:36:39.354884782 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51403 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3093918)[0;0m INFO 12-04 10:36:39 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ERROR 12-04 10:36:39 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3093918)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3093918)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3093918)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3093918)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3093918)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3093918)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3093918)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3093918)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3093918)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3093918)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3093918)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093918)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3093918)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3093918)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3093918)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3093918)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093918)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3093918)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3093918)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3093918)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3093918)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3093918)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3093918)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3093918)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3093918)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3093918)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:36:39.171648439 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:37:00 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:37:00 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:37:00 [model.py:1745] Using max model len 40960
INFO 12-04 10:37:00 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.33s/it, est. speed input: 3.12 toks/s, output: 25.19 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.33s/it, est. speed input: 3.12 toks/s, output: 25.19 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.33s/it, est. speed input: 3.12 toks/s, output: 25.19 toks/s]
Agent 1 response: The result of 15 + 12*17 + 14 - 20*23 is calculated by following the order of operations (multiplica...

--- Problem 20/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1094.55it/s]

[1;36m(EngineCore_DP0 pid=3094520)[0;0m INFO 12-04 10:37:13 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3094520)[0;0m INFO 12-04 10:37:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55519 backend=nccl
[W1204 10:37:14.027370648 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55519 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3094520)[0;0m INFO 12-04 10:37:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ERROR 12-04 10:37:14 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3094520)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3094520)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3094520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3094520)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3094520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3094520)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3094520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3094520)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3094520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3094520)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3094520)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3094520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3094520)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3094520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3094520)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3094520)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3094520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3094520)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3094520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3094520)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3094520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3094520)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3094520)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3094520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3094520)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3094520)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:37:15.840677398 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.99s/it, est. speed input: 5.00 toks/s, output: 25.08 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.99s/it, est. speed input: 5.00 toks/s, output: 25.08 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.99s/it, est. speed input: 5.00 toks/s, output: 25.08 toks/s]
Agent 2 response: Clouds in the sky, water in the jar.  
-227...

--- Problem 20/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1478.95it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:37:36 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:37:36 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:37:36 [model.py:1745] Using max model len 40960
INFO 12-04 10:37:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.62s/it, est. speed input: 3.56 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.62s/it, est. speed input: 3.56 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.62s/it, est. speed input: 3.56 toks/s, output: 25.21 toks/s]
Agent 3 response: The result of 15 + 12*17 + 14 - 20*23 is calculated as follows:  
1. Multiply 12*17 = 204 and 20*23 ...

--- Problem 20/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 627.14it/s]

[1;36m(EngineCore_DP0 pid=3095653)[0;0m INFO 12-04 10:37:47 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3095653)[0;0m INFO 12-04 10:37:49 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:33083 backend=nccl
[W1204 10:37:49.794771226 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:33083 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3095653)[0;0m INFO 12-04 10:37:49 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ERROR 12-04 10:37:49 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3095653)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3095653)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3095653)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3095653)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3095653)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3095653)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3095653)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3095653)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3095653)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3095653)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3095653)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3095653)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3095653)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3095653)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3095653)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3095653)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3095653)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3095653)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3095653)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3095653)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3095653)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3095653)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3095653)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3095653)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3095653)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3095653)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:37:50.619979291 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.76s/it, est. speed input: 21.00 toks/s, output: 25.05 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.76s/it, est. speed input: 21.00 toks/s, output: 25.05 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.76s/it, est. speed input: 21.00 toks/s, output: 25.05 toks/s]
Agent 1 response: The calculation follows the order of operations: multiply first (12*17=204, 20*23=460), then combine...

--- Problem 20/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 763.43it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:38:11 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:38:11 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:38:11 [model.py:1745] Using max model len 40960
INFO 12-04 10:38:11 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3096254)[0;0m INFO 12-04 10:38:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.99s/it, est. speed input: 14.75 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.99s/it, est. speed input: 14.75 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.99s/it, est. speed input: 14.75 toks/s, output: 25.09 toks/s]
Agent 2 response: The wind whispers numbers.  
The answer is -227....

--- Problem 20/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 511.06it/s]

[1;36m(EngineCore_DP0 pid=3096254)[0;0m INFO 12-04 10:38:26 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50889 backend=nccl
[W1204 10:38:26.624528521 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50889 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3096254)[0;0m INFO 12-04 10:38:26 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ERROR 12-04 10:38:26 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3096254)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3096254)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3096254)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3096254)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3096254)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3096254)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3096254)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3096254)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3096254)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3096254)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3096254)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096254)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3096254)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3096254)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3096254)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3096254)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096254)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3096254)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3096254)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3096254)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3096254)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3096254)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3096254)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096254)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3096254)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3096254)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:38:27.447009328 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 21.59 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 21.59 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 21.59 toks/s, output: 25.14 toks/s]
Agent 3 response: The calculation adheres to standard arithmetic rules (multiplication before addition/subtraction):  ...

--- Problem 20/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 522.07it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:38:48 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:38:48 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:38:48 [model.py:1745] Using max model len 40960
INFO 12-04 10:38:48 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3096866)[0;0m INFO 12-04 10:38:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3096866)[0;0m INFO 12-04 10:39:00 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55395 backend=nccl
[W1204 10:39:00.991127448 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55395 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3096866)[0;0m INFO 12-04 10:39:00 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ERROR 12-04 10:39:00 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3096866)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3096866)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3096866)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3096866)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3096866)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3096866)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3096866)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3096866)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3096866)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3096866)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3096866)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096866)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3096866)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3096866)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3096866)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3096866)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096866)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3096866)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3096866)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3096866)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3096866)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3096866)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3096866)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3096866)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3096866)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3096866)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:39:01.809617964 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.49s/it, est. speed input: 31.42 toks/s, output: 24.99 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.49s/it, est. speed input: 31.42 toks/s, output: 24.99 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.49s/it, est. speed input: 31.42 toks/s, output: 24.99 toks/s]
Agent 1 response: The calculation adheres to standard arithmetic rules (multiplication before addition/subtraction):  ...

--- Problem 20/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 507.11it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.17s/it, est. speed input: 47.93 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.17s/it, est. speed input: 47.93 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.17s/it, est. speed input: 47.93 toks/s, output: 25.13 toks/s]
Agent 2 response: The river flows, the stone remains.  
The answer is -227....

--- Problem 20/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 525.67it/s]

Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:39:22 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:39:22 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:39:22 [model.py:1745] Using max model len 40960
INFO 12-04 10:39:22 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3097468)[0;0m INFO 12-04 10:39:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3097468)[0;0m INFO 12-04 10:39:36 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:43451 backend=nccl
[W1204 10:39:36.283770176 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:43451 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3097468)[0;0m INFO 12-04 10:39:37 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842]     raise ValueError(
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ERROR 12-04 10:39:37 [core.py:842] ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[1;36m(EngineCore_DP0 pid=3097468)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3097468)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3097468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3097468)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3097468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3097468)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3097468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3097468)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3097468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3097468)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3097468)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3097468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3097468)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3097468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3097468)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3097468)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3097468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3097468)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3097468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
[1;36m(EngineCore_DP0 pid=3097468)[0;0m     self.driver_worker.init_device()
[1;36m(EngineCore_DP0 pid=3097468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/worker_base.py", line 324, in init_device
[1;36m(EngineCore_DP0 pid=3097468)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=3097468)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3097468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 247, in init_device
[1;36m(EngineCore_DP0 pid=3097468)[0;0m     raise ValueError(
[1;36m(EngineCore_DP0 pid=3097468)[0;0m ValueError: Free memory on device (3.27/44.39 GiB) on startup is less than desired GPU memory utilization (0.9, 39.95 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W1204 10:39:37.103270938 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.43s/it, est. speed input: 36.68 toks/s, output: 24.96 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.43s/it, est. speed input: 36.68 toks/s, output: 24.96 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.43s/it, est. speed input: 36.68 toks/s, output: 24.96 toks/s]
100%|██████████| 20/20 [1:10:25<00:00, 155.84s/it]100%|██████████| 20/20 [1:10:25<00:00, 211.28s/it]
[rank0]:[W1204 10:39:38.005718800 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Agent 3 response: The calculation follows the standard order of operations, prioritizing multiplication before additio...
performance: 0.85 0.07984359711335655
============================================================
Results saved to: /home/ch269957/projects/slm_multiagent_debate/experiments/linux_single/results/math/math_Qwen3-14B_persona_enigma+zen+deep-sea_agents3_rounds3.p
Final performance: 0.850 ± 0.080
============================================================
[ModelCache] Shut down vLLM model: vllm:Qwen/Qwen3-14B
[ModelCache] All models shut down
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 10:39:58 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 10:39:58 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 10:39:58 [model.py:1745] Using max model len 40960
INFO 12-04 10:39:58 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:40:13 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:40:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:49871 backend=nccl
[W1204 10:40:14.155849457 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:49871 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:40:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:40:15 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:40:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:40:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/8 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Loading safetensors checkpoint shards:  12% Completed | 1/8 [00:07<00:50,  7.18s/it]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Loading safetensors checkpoint shards:  25% Completed | 2/8 [00:15<00:45,  7.65s/it]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Loading safetensors checkpoint shards:  38% Completed | 3/8 [00:23<00:39,  7.89s/it]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Loading safetensors checkpoint shards:  50% Completed | 4/8 [00:31<00:32,  8.02s/it]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Loading safetensors checkpoint shards:  62% Completed | 5/8 [00:39<00:24,  8.11s/it]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Loading safetensors checkpoint shards:  75% Completed | 6/8 [00:47<00:16,  8.10s/it]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Loading safetensors checkpoint shards:  88% Completed | 7/8 [00:56<00:08,  8.14s/it]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Loading safetensors checkpoint shards: 100% Completed | 8/8 [01:00<00:00,  6.83s/it]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Loading safetensors checkpoint shards: 100% Completed | 8/8 [01:00<00:00,  7.52s/it]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m 
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:41:16 [default_loader.py:314] Loading weights took 60.20 seconds
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:41:17 [gpu_model_runner.py:3338] Model loading took 27.5185 GiB memory and 61.180150 seconds
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:41:28 [backends.py:631] Using cache directory: /home/ch269957/.cache/vllm/torch_compile_cache/d7ea762554/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:41:28 [backends.py:647] Dynamo bytecode transform time: 11.01 s
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:41:34 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 5.574 s
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:41:36 [monitor.py:34] torch.compile takes 16.58 s in total
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:41:38 [gpu_worker.py:359] Available KV cache memory: 10.93 GiB
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:41:38 [kv_cache_utils.py:1229] GPU KV cache size: 71,616 tokens
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:41:38 [kv_cache_utils.py:1234] Maximum concurrency for 40,960 tokens per request: 1.75x
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:05,  9.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:04,  9.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:04,  9.96it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:00<00:04, 10.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:00<00:04, 10.17it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:00<00:04, 10.47it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:01<00:03, 10.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:01<00:03, 11.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:01<00:03, 11.46it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:01<00:02, 11.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:01<00:02, 11.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:01<00:02, 11.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:02<00:02, 12.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 25/51 [00:02<00:02, 12.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:02<00:01, 12.45it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:02<00:01, 12.50it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:02<00:01, 12.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:02<00:01, 12.29it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:03<00:01, 12.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:03<00:01, 12.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:03<00:00, 12.76it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:03<00:00, 12.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:03<00:00, 13.00it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 45/51 [00:03<00:00, 13.22it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:03<00:00, 13.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 49/51 [00:04<00:00, 13.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:04<00:00, 13.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:04<00:00, 12.14it/s]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:02, 12.33it/s]Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:02, 12.67it/s]Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:02, 12.89it/s]Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:00<00:02, 13.10it/s]Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:00<00:01, 13.29it/s]Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:00<00:01, 13.42it/s]Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:01<00:01, 13.45it/s]Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:01<00:01, 13.45it/s]Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:01<00:01, 13.65it/s]Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:01<00:01, 13.76it/s]Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:01<00:00, 13.94it/s]Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:01<00:00, 14.16it/s]Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:01<00:00, 14.61it/s]Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:02<00:00, 14.95it/s]Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:02<00:00, 15.26it/s]Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:02<00:00, 15.69it/s]Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:02<00:00, 15.98it/s]Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:02<00:00, 14.34it/s]
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:41:45 [gpu_model_runner.py:4244] Graph capturing finished in 7 secs, took 0.64 GiB
[1;36m(EngineCore_DP0 pid=3098077)[0;0m INFO 12-04 10:41:45 [core.py:250] init engine (profile, create kv cache, warmup model) took 28.68 seconds
INFO 12-04 10:41:47 [llm.py:352] Supported tasks: ['generate']

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 553.12it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.59s/it, est. speed input: 2.27 toks/s, output: 25.25 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.59s/it, est. speed input: 2.27 toks/s, output: 25.25 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.59s/it, est. speed input: 2.27 toks/s, output: 25.25 toks/s]
Agent 1 response: The solution involves following the order of operations (PEMDAS/BODMAS):  
1. Multiply: 19 * 28 = 53...

--- Problem 1/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1332.37it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.78s/it, est. speed input: 3.94 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.78s/it, est. speed input: 3.94 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.78s/it, est. speed input: 3.94 toks/s, output: 25.28 toks/s]
Agent 2 response: Why do clouds drift? Because they are not bound by calculation. The answer is 482....

--- Problem 1/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1447.81it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.82s/it, est. speed input: 4.74 toks/s, output: 25.29 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.82s/it, est. speed input: 4.74 toks/s, output: 25.29 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.82s/it, est. speed input: 4.74 toks/s, output: 25.29 toks/s]
Agent 3 response: The result of 6 + 19*28 + 14 - 10*7 is calculated by following the order of operations. First, perfo...

--- Problem 1/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 638.79it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.16s/it, est. speed input: 23.51 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.16s/it, est. speed input: 23.51 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.16s/it, est. speed input: 23.51 toks/s, output: 25.22 toks/s]
Agent 1 response: Following the order of operations (PEMDAS/BODMAS), the calculation proceeds as:  
1. Multiply: 19 × ...

--- Problem 1/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 753.83it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.35s/it, est. speed input: 28.09 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.35s/it, est. speed input: 28.09 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.35s/it, est. speed input: 28.09 toks/s, output: 25.22 toks/s]
Agent 2 response: What is the sound of one hand clapping? Silence. The answer is 482....

--- Problem 1/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 776.00it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.40s/it, est. speed input: 18.29 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.40s/it, est. speed input: 18.29 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.40s/it, est. speed input: 18.29 toks/s, output: 25.21 toks/s]
Agent 3 response: The calculation follows the order of operations (PEMDAS/BODMAS):  
1. Multiply: $19 \times 28 = 532$...

--- Problem 1/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 529.65it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.57s/it, est. speed input: 46.10 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.57s/it, est. speed input: 46.10 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.57s/it, est. speed input: 46.10 toks/s, output: 25.16 toks/s]
Agent 1 response: Following the order of operations (PEMDAS/BODMAS):  
1. Multiply: $19 \times 28 = 532$ and $10 \time...

--- Problem 1/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 543.94it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.41s/it, est. speed input: 61.91 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.41s/it, est. speed input: 61.91 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.41s/it, est. speed input: 61.91 toks/s, output: 25.15 toks/s]
Agent 2 response: What is the number that remains when all equations are silent? The answer is 482....

--- Problem 1/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 558.64it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.75s/it, est. speed input: 36.86 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.75s/it, est. speed input: 36.86 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.75s/it, est. speed input: 36.86 toks/s, output: 25.15 toks/s]
Agent 3 response: The calculation follows the order of operations (PEMDAS/BODMAS):  
1. Multiply: $19 \times 28 = 532$...
performance: 0.0 0.0

--- Problem 2/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
  5%|▌         | 1/20 [1:15:29<23:54:22, 4529.61s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1516.38it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.62s/it, est. speed input: 3.82 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.62s/it, est. speed input: 3.82 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.62s/it, est. speed input: 3.82 toks/s, output: 25.28 toks/s]
Agent 1 response: The result is calculated as follows:  
First, perform multiplications: 20*6 = 120 and 18*22 = 396.  ...

--- Problem 2/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1566.21it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.82s/it, est. speed input: 2.41 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.82s/it, est. speed input: 2.41 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.82s/it, est. speed input: 2.41 toks/s, output: 25.26 toks/s]
Agent 2 response: The weight of the sky. A shadow without light. Numbers are not doors. Answer: -223....

--- Problem 2/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1558.64it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it, est. speed input: 4.05 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it, est. speed input: 4.05 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it, est. speed input: 4.05 toks/s, output: 25.28 toks/s]
Agent 3 response: To solve the expression **28 + 20*6 + 25 - 18*22** systematically:  
1. Perform multiplications firs...

--- Problem 2/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 732.37it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.57s/it, est. speed input: 32.21 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.57s/it, est. speed input: 32.21 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.57s/it, est. speed input: 32.21 toks/s, output: 25.21 toks/s]
Agent 1 response: The calculation follows standard order of operations: multiplication first, then addition/subtractio...

--- Problem 2/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 770.30it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it, est. speed input: 25.39 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it, est. speed input: 25.39 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it, est. speed input: 25.39 toks/s, output: 25.22 toks/s]
Agent 2 response: A cloud dissolves into the wind. A bell rings in silence. The path is not the destination. Answer: -...

--- Problem 2/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 781.50it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.47s/it, est. speed input: 22.49 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.47s/it, est. speed input: 22.49 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.47s/it, est. speed input: 22.49 toks/s, output: 25.21 toks/s]
Agent 3 response: The calculation remains consistent with prior responses. Following order of operations:  
1. Multipl...

--- Problem 2/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 522.46it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.28s/it, est. speed input: 42.00 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.28s/it, est. speed input: 42.00 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.28s/it, est. speed input: 42.00 toks/s, output: 25.16 toks/s]
Agent 1 response: The calculation aligns with established methods: priority to multiplication (20×6=120, 18×22=396), t...

--- Problem 2/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 546.13it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.01s/it, est. speed input: 45.38 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.01s/it, est. speed input: 45.38 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.01s/it, est. speed input: 45.38 toks/s, output: 25.16 toks/s]
Agent 2 response: A pebble in the stream. The moon reflects in water. Silence holds the flame. Answer: -223....

--- Problem 2/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 552.90it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.39s/it, est. speed input: 53.45 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.39s/it, est. speed input: 53.45 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.39s/it, est. speed input: 53.45 toks/s, output: 25.16 toks/s]
Agent 3 response: The calculation confirms the result through standard order of operations:  
1. Multiplications: 20×6...
performance: 0.5 0.35355339059327373

--- Problem 3/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 10%|█         | 2/20 [1:18:20<9:49:46, 1965.92s/it] 
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1509.29it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.30s/it, est. speed input: 4.84 toks/s, output: 25.29 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.30s/it, est. speed input: 4.84 toks/s, output: 25.29 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.30s/it, est. speed input: 4.84 toks/s, output: 25.29 toks/s]
Agent 1 response: The result of the expression is calculated by following the order of operations (multiplication befo...

--- Problem 3/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1535.25it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.60s/it, est. speed input: 7.36 toks/s, output: 25.29 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.60s/it, est. speed input: 7.36 toks/s, output: 25.29 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.60s/it, est. speed input: 7.36 toks/s, output: 25.29 toks/s]
Agent 2 response: The moon does not question the tide. The wave replies with silence. 239....

--- Problem 3/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1513.64it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.63s/it, est. speed input: 5.13 toks/s, output: 25.29 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.63s/it, est. speed input: 5.13 toks/s, output: 25.29 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.63s/it, est. speed input: 5.13 toks/s, output: 25.29 toks/s]
Agent 3 response: The result of 10 + 10*23 + 20 - 3*7 is calculated by following the order of operations (PEMDAS/BODMA...

--- Problem 3/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 779.76it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.05s/it, est. speed input: 16.66 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.05s/it, est. speed input: 16.66 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.05s/it, est. speed input: 16.66 toks/s, output: 25.21 toks/s]
Agent 1 response: The calculation follows the order of operations (multiplication before addition and subtraction). Mu...

--- Problem 3/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 814.59it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.59s/it, est. speed input: 40.46 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.59s/it, est. speed input: 40.46 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.59s/it, est. speed input: 40.46 toks/s, output: 25.13 toks/s]
Agent 2 response: The bamboo bends but does not break. The stone remains still as the river flows. 239....

--- Problem 3/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 807.84it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.15s/it, est. speed input: 25.41 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.15s/it, est. speed input: 25.41 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.15s/it, est. speed input: 25.41 toks/s, output: 25.15 toks/s]
Agent 3 response: The expression is evaluated using the order of operations (multiplication first, then addition and s...

--- Problem 3/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 538.84it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.97s/it, est. speed input: 41.50 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.97s/it, est. speed input: 41.50 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.97s/it, est. speed input: 41.50 toks/s, output: 25.11 toks/s]
Agent 1 response: The bamboo bends but does not break. The stone remains still as the river flows. The calculation adh...

--- Problem 3/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 557.23it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 11.00s/it, est. speed input: 64.37 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 11.00s/it, est. speed input: 64.37 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:10<00:00, 11.00s/it, est. speed input: 64.37 toks/s, output: 25.09 toks/s]
Agent 2 response: The wind does not question the tree. The path dissolves into the shadow. 239....

--- Problem 3/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 547.27it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.73s/it, est. speed input: 42.15 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.73s/it, est. speed input: 42.15 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.73s/it, est. speed input: 42.15 toks/s, output: 25.11 toks/s]
Agent 3 response: The expression is evaluated by prioritizing multiplication first: 10*23 = 230 and 3*7 = 21. Substitu...
performance: 0.6666666666666666 0.2721655269759087

--- Problem 4/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 15%|█▌        | 3/20 [1:20:33<5:19:52, 1128.98s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1483.66it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.83s/it, est. speed input: 3.55 toks/s, output: 25.25 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.83s/it, est. speed input: 3.55 toks/s, output: 25.25 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.83s/it, est. speed input: 3.55 toks/s, output: 25.25 toks/s]
Agent 1 response: The result of 23 + 2*21 + 20 - 1*23 is calculated by following the order of operations. First, perfo...

--- Problem 4/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1535.25it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.20s/it, est. speed input: 9.52 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.20s/it, est. speed input: 9.52 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.20s/it, est. speed input: 9.52 toks/s, output: 25.26 toks/s]
Agent 2 response: The stone does not question the path.  
62....

--- Problem 4/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1565.62it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.46s/it, est. speed input: 2.55 toks/s, output: 25.25 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.46s/it, est. speed input: 2.55 toks/s, output: 25.25 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.46s/it, est. speed input: 2.55 toks/s, output: 25.25 toks/s]
Agent 3 response: The result is calculated by following the order of operations (PEMDAS): first performing the multipl...

--- Problem 4/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 782.23it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.17s/it, est. speed input: 29.53 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.17s/it, est. speed input: 29.53 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.17s/it, est. speed input: 29.53 toks/s, output: 25.21 toks/s]
Agent 1 response: The calculation follows the order of operations (multiplication before addition/subtraction), result...

--- Problem 4/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 808.00it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.55s/it, est. speed input: 34.04 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.55s/it, est. speed input: 34.04 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.55s/it, est. speed input: 34.04 toks/s, output: 25.20 toks/s]
Agent 2 response: The moon does not need a mirror to shine.  
62....

--- Problem 4/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 802.89it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.50s/it, est. speed input: 18.14 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.50s/it, est. speed input: 18.14 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.50s/it, est. speed input: 18.14 toks/s, output: 25.21 toks/s]
Agent 3 response: The calculation follows the order of operations. Multiplying first: 2*21 = 42 and 1*23 = 23. Substit...

--- Problem 4/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 522.33it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.98s/it, est. speed input: 32.93 toks/s, output: 25.18 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.98s/it, est. speed input: 32.93 toks/s, output: 25.18 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.98s/it, est. speed input: 32.93 toks/s, output: 25.18 toks/s]
Agent 1 response: The calculation adheres to the order of operations (multiplication first): 2*21 = 42, 1*23 = 23. Sub...

--- Problem 4/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 588.10it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.18s/it, est. speed input: 76.89 toks/s, output: 25.18 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.18s/it, est. speed input: 76.89 toks/s, output: 25.18 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.18s/it, est. speed input: 76.89 toks/s, output: 25.18 toks/s]
Agent 2 response: The echo of a bell does not count its rings.  
62....

--- Problem 4/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 594.01it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.24s/it, est. speed input: 38.55 toks/s, output: 25.19 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.24s/it, est. speed input: 38.55 toks/s, output: 25.19 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.24s/it, est. speed input: 38.55 toks/s, output: 25.19 toks/s]
Agent 3 response: The calculation adheres to standard order of operations (multiplication first, then left-to-right ad...
performance: 0.75 0.21650635094610965

--- Problem 5/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 20%|██        | 4/20 [1:23:02<3:17:48, 741.75s/it] 
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1507.66it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.49s/it, est. speed input: 2.51 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.49s/it, est. speed input: 2.51 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.49s/it, est. speed input: 2.51 toks/s, output: 25.26 toks/s]
Agent 1 response: The result of 11 + 29*5 + 1 - 27*20 is calculated by first performing the multiplications: 29*5 = 14...

--- Problem 5/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1556.33it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.30s/it, est. speed input: 6.34 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.30s/it, est. speed input: 6.34 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.30s/it, est. speed input: 6.34 toks/s, output: 25.28 toks/s]
Agent 2 response: The moon reflects the sun's light. A single breath holds the universe.  
-383...

--- Problem 5/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1544.86it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.22s/it, est. speed input: 2.66 toks/s, output: 25.27 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.22s/it, est. speed input: 2.66 toks/s, output: 25.27 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.22s/it, est. speed input: 2.66 toks/s, output: 25.27 toks/s]
Agent 3 response: The result of 11 + 29*5 + 1 - 27*20 is calculated as follows:  
First, compute the multiplications: ...

--- Problem 5/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 743.41it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.10s/it, est. speed input: 48.03 toks/s, output: 25.17 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.10s/it, est. speed input: 48.03 toks/s, output: 25.17 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.10s/it, est. speed input: 48.03 toks/s, output: 25.17 toks/s]
Agent 1 response: The calculation adheres to standard order of operations. Multiplying first: 29×5=145 and 27×20=540. ...

--- Problem 5/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 768.19it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.44s/it, est. speed input: 42.25 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.44s/it, est. speed input: 42.25 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.44s/it, est. speed input: 42.25 toks/s, output: 25.20 toks/s]
Agent 2 response: The wind does not seek to be heard.  
-383...

--- Problem 5/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 787.81it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.55s/it, est. speed input: 24.96 toks/s, output: 25.19 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.55s/it, est. speed input: 24.96 toks/s, output: 25.19 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.55s/it, est. speed input: 24.96 toks/s, output: 25.19 toks/s]
Agent 3 response: The calculation follows standard arithmetic rules:  
1. Multiply first: 29*5 = 145 and 27*20 = 540. ...

--- Problem 5/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 523.63it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 41.85 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 41.85 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 41.85 toks/s, output: 25.13 toks/s]
Agent 1 response: The calculation remains consistent with previous confirmations:  
1. **Multiplication first**: 29×5 ...

--- Problem 5/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 531.40it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.29s/it, est. speed input: 53.88 toks/s, output: 25.12 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.29s/it, est. speed input: 53.88 toks/s, output: 25.12 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.29s/it, est. speed input: 53.88 toks/s, output: 25.12 toks/s]
Agent 2 response: The river flows without end. Silence speaks volumes.  
-383...

--- Problem 5/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 492.64it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.36s/it, est. speed input: 46.89 toks/s, output: 25.12 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.36s/it, est. speed input: 46.89 toks/s, output: 25.12 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.36s/it, est. speed input: 46.89 toks/s, output: 25.12 toks/s]
Agent 3 response: The calculation adheres to standard order of operations. Multiplying first: 29×5=145 and 27×20=540. ...
performance: 0.8 0.1788854381999832

--- Problem 6/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 25%|██▌       | 5/20 [1:25:38<2:12:38, 530.55s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1403.25it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.84s/it, est. speed input: 2.69 toks/s, output: 25.25 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.84s/it, est. speed input: 2.69 toks/s, output: 25.25 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.84s/it, est. speed input: 2.69 toks/s, output: 25.25 toks/s]
Agent 1 response: The result of the expression 0 + 11*25 + 21 - 28*11 is calculated as follows:  
1. Perform multiplic...

--- Problem 6/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1492.10it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.76s/it, est. speed input: 2.41 toks/s, output: 25.24 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.76s/it, est. speed input: 2.41 toks/s, output: 25.24 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.76s/it, est. speed input: 2.41 toks/s, output: 25.24 toks/s]
Agent 2 response: The wheel turns, but the ground remains. The key is not in the lock. But the answer is -12....

--- Problem 6/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1474.79it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.35s/it, est. speed input: 3.25 toks/s, output: 25.27 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.35s/it, est. speed input: 3.25 toks/s, output: 25.27 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.35s/it, est. speed input: 3.25 toks/s, output: 25.27 toks/s]
Agent 3 response: The result of $0 + 11 \times 25 + 21 - 28 \times 11$ is calculated as follows:  
1. Perform the mult...

--- Problem 6/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 689.29it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.74s/it, est. speed input: 37.44 toks/s, output: 25.12 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.74s/it, est. speed input: 37.44 toks/s, output: 25.12 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.74s/it, est. speed input: 37.44 toks/s, output: 25.12 toks/s]
Agent 1 response: The provided opinions corroborate the calculation. Both agents confirm the result through detailed s...

--- Problem 6/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 698.93it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.87s/it, est. speed input: 61.13 toks/s, output: 25.04 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.87s/it, est. speed input: 61.13 toks/s, output: 25.04 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.87s/it, est. speed input: 61.13 toks/s, output: 25.04 toks/s]
Agent 2 response: A stone falls, but the sky does not answer. The river flows, yet the moon does not change. The answe...

--- Problem 6/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 719.68it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.40s/it, est. speed input: 29.15 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.40s/it, est. speed input: 29.15 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.40s/it, est. speed input: 29.15 toks/s, output: 25.13 toks/s]
Agent 3 response: The calculation of $0 + 11 \times 25 + 21 - 28 \times 11$ follows standard order of operations:  
1....

--- Problem 6/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 520.84it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.86s/it, est. speed input: 62.15 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.86s/it, est. speed input: 62.15 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.86s/it, est. speed input: 62.15 toks/s, output: 25.13 toks/s]
Agent 1 response: The poetic metaphors and arithmetic confirmations remain consistent with prior calculations. The fin...

--- Problem 6/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 529.78it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.32s/it, est. speed input: 55.62 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.32s/it, est. speed input: 55.62 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.32s/it, est. speed input: 55.62 toks/s, output: 25.15 toks/s]
Agent 2 response: The wind whispers, but the tree does not listen. The shadow moves, yet the sun does not age. The ans...

--- Problem 6/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 532.00it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.08s/it, est. speed input: 52.40 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.08s/it, est. speed input: 52.40 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.08s/it, est. speed input: 52.40 toks/s, output: 25.13 toks/s]
Agent 3 response: The calculation aligns with prior confirmations, as all agents consistently derive the result throug...
performance: 0.8333333333333334 0.15214515486254618

--- Problem 7/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 30%|███       | 6/20 [1:28:18<1:34:25, 404.65s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1456.86it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.41s/it, est. speed input: 2.95 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.41s/it, est. speed input: 2.95 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:25<00:00, 25.41s/it, est. speed input: 2.95 toks/s, output: 25.26 toks/s]
Agent 1 response: To solve the expression, follow the order of operations (multiplication before addition and subtract...

--- Problem 7/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1567.38it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.03s/it, est. speed input: 4.93 toks/s, output: 25.27 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.03s/it, est. speed input: 4.93 toks/s, output: 25.27 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.03s/it, est. speed input: 4.93 toks/s, output: 25.27 toks/s]
Agent 2 response: The moon reflects the sun's light. A stone does not ask why it falls.  
223...

--- Problem 7/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1522.99it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.96s/it, est. speed input: 4.01 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.96s/it, est. speed input: 4.01 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.96s/it, est. speed input: 4.01 toks/s, output: 25.26 toks/s]
Agent 3 response: The result of 24 + 16 * 26 + 26 - 9 * 27 is 223....

--- Problem 7/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 763.43it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.75s/it, est. speed input: 28.85 toks/s, output: 25.19 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.75s/it, est. speed input: 28.85 toks/s, output: 25.19 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.75s/it, est. speed input: 28.85 toks/s, output: 25.19 toks/s]
Agent 1 response: The calculations align with the provided opinions, as both confirm the result is 223. The expression...

--- Problem 7/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 807.06it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.85s/it, est. speed input: 18.20 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.85s/it, est. speed input: 18.20 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.85s/it, est. speed input: 18.20 toks/s, output: 25.20 toks/s]
Agent 2 response: The wind does not explain its path to the tree. A mountain holds its silence until the river speaks....

--- Problem 7/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 812.69it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.50s/it, est. speed input: 15.11 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.50s/it, est. speed input: 15.11 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.50s/it, est. speed input: 15.11 toks/s, output: 25.20 toks/s]
Agent 3 response: The calculation follows the order of operations (multiplication before addition/subtraction):  
1. $...

--- Problem 7/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 508.40it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.53s/it, est. speed input: 55.40 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.53s/it, est. speed input: 55.40 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.53s/it, est. speed input: 55.40 toks/s, output: 25.14 toks/s]
Agent 1 response: The calculation adheres to standard mathematical precedence: multiplication is resolved first ($16 \...

--- Problem 7/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 564.59it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.71s/it, est. speed input: 66.23 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.71s/it, est. speed input: 66.23 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.71s/it, est. speed input: 66.23 toks/s, output: 25.13 toks/s]
Agent 2 response: The bamboo bends but does not break. The shadow knows the shape of the flame.  
223...

--- Problem 7/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 553.34it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.03s/it, est. speed input: 30.43 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.03s/it, est. speed input: 30.43 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.03s/it, est. speed input: 30.43 toks/s, output: 25.16 toks/s]
Agent 3 response: The calculation adheres to the standard order of operations (multiplication before addition/subtract...
performance: 0.8571428571428571 0.13226001425322165

--- Problem 8/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 35%|███▌      | 7/20 [1:30:54<1:10:02, 323.29s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1520.78it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.26s/it, est. speed input: 3.75 toks/s, output: 25.27 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.26s/it, est. speed input: 3.75 toks/s, output: 25.27 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.26s/it, est. speed input: 3.75 toks/s, output: 25.27 toks/s]
Agent 1 response: The result of 27 + 15 * 14 + 29 - 29 * 14 is calculated by following the order of operations. First,...

--- Problem 8/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1556.91it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.03s/it, est. speed input: 3.07 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.03s/it, est. speed input: 3.07 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.03s/it, est. speed input: 3.07 toks/s, output: 25.28 toks/s]
Agent 2 response: A stone falls, but the mountain does not move. The result is -140....

--- Problem 8/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1553.45it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.82s/it, est. speed input: 2.77 toks/s, output: 25.27 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.82s/it, est. speed input: 2.77 toks/s, output: 25.27 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:27<00:00, 27.82s/it, est. speed input: 2.77 toks/s, output: 25.27 toks/s]
Agent 3 response: Following the order of operations (PEMDAS/BODMAS), first compute the multiplications:  
15*14 = 210 ...

--- Problem 8/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 717.71it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.88s/it, est. speed input: 29.17 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.88s/it, est. speed input: 29.17 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.88s/it, est. speed input: 29.17 toks/s, output: 25.21 toks/s]
Agent 1 response: The calculation adheres to the standard order of operations (multiplication before addition/subtract...

--- Problem 8/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 753.83it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.61s/it, est. speed input: 45.58 toks/s, output: 25.18 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.61s/it, est. speed input: 45.58 toks/s, output: 25.18 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.61s/it, est. speed input: 45.58 toks/s, output: 25.18 toks/s]
Agent 2 response: A river flows, yet the moon reflects still. The result is -140....

--- Problem 8/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 737.52it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.93s/it, est. speed input: 31.23 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.93s/it, est. speed input: 31.23 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.93s/it, est. speed input: 31.23 toks/s, output: 25.20 toks/s]
Agent 3 response: The calculation follows standard mathematical order of operations (multiplication before addition/su...

--- Problem 8/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 500.33it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.22s/it, est. speed input: 33.98 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.22s/it, est. speed input: 33.98 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.22s/it, est. speed input: 33.98 toks/s, output: 25.16 toks/s]
Agent 1 response: The calculation follows the standard order of operations (multiplication before addition/subtraction...

--- Problem 8/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 517.11it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.68s/it, est. speed input: 87.48 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.68s/it, est. speed input: 87.48 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.68s/it, est. speed input: 87.48 toks/s, output: 25.13 toks/s]
Agent 2 response: A silent echo in the void. The result is -140....

--- Problem 8/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 513.88it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.00s/it, est. speed input: 58.13 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.00s/it, est. speed input: 58.13 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.00s/it, est. speed input: 58.13 toks/s, output: 25.15 toks/s]
Agent 3 response: The calculation remains consistent with the order of operations: 15*14=210 and 29*14=406, leading to...
performance: 0.875 0.11692679333668567

--- Problem 9/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 40%|████      | 8/20 [1:33:30<54:02, 270.17s/it]  
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1504.95it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.90s/it, est. speed input: 3.64 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.90s/it, est. speed input: 3.64 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.90s/it, est. speed input: 3.64 toks/s, output: 25.26 toks/s]
Agent 1 response: The result of 29 + 18*11 + 22 - 19*24 is calculated by first performing the multiplications: 18*11 =...

--- Problem 9/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1544.86it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.61s/it, est. speed input: 3.88 toks/s, output: 25.23 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.61s/it, est. speed input: 3.88 toks/s, output: 25.23 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.61s/it, est. speed input: 3.88 toks/s, output: 25.23 toks/s]
Agent 2 response: The silence between stars. A shadow without form. The answer is -207....

--- Problem 9/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1537.50it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it, est. speed input: 4.10 toks/s, output: 25.23 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it, est. speed input: 4.10 toks/s, output: 25.23 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it, est. speed input: 4.10 toks/s, output: 25.23 toks/s]
Agent 3 response: The result is calculated by following the order of operations (multiplication before addition/subtra...

--- Problem 9/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 748.45it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.78s/it, est. speed input: 25.39 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.78s/it, est. speed input: 25.39 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.78s/it, est. speed input: 25.39 toks/s, output: 25.15 toks/s]
Agent 1 response: The calculation adheres to the order of operations, confirming prior results. Multiplying first: 18×...

--- Problem 9/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 710.66it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.94s/it, est. speed input: 20.53 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.94s/it, est. speed input: 20.53 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.94s/it, est. speed input: 20.53 toks/s, output: 25.16 toks/s]
Agent 2 response: The wind whispers through hollow bones. Seasons forget their names. The answer is -207....

--- Problem 9/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 741.83it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.40s/it, est. speed input: 22.02 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.40s/it, est. speed input: 22.02 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.40s/it, est. speed input: 22.02 toks/s, output: 25.21 toks/s]
Agent 3 response: The calculation follows standard order of operations: multiplications (18×11=198, 19×24=456) are res...

--- Problem 9/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 531.26it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.94s/it, est. speed input: 37.78 toks/s, output: 25.19 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.94s/it, est. speed input: 37.78 toks/s, output: 25.19 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.94s/it, est. speed input: 37.78 toks/s, output: 25.19 toks/s]
Agent 1 response: The calculation remains consistent with prior confirmations: multiplication precedes addition/subtra...

--- Problem 9/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 543.09it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.48s/it, est. speed input: 65.10 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.48s/it, est. speed input: 65.10 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.48s/it, est. speed input: 65.10 toks/s, output: 25.20 toks/s]
Agent 2 response: The echo of a stone in the void. Shadows without edges. The answer is -207....

--- Problem 9/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 560.14it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.08s/it, est. speed input: 30.76 toks/s, output: 25.18 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.08s/it, est. speed input: 30.76 toks/s, output: 25.18 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.08s/it, est. speed input: 30.76 toks/s, output: 25.18 toks/s]
Agent 3 response: The calculation remains unchanged: adhering to multiplication first (18×11=198, 19×24=456), then seq...
performance: 0.8888888888888888 0.10475656017578483

--- Problem 10/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 45%|████▌     | 9/20 [1:36:18<43:40, 238.21s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1502.26it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.48s/it, est. speed input: 4.12 toks/s, output: 25.29 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.48s/it, est. speed input: 4.12 toks/s, output: 25.29 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.48s/it, est. speed input: 4.12 toks/s, output: 25.29 toks/s]
Agent 1 response: The result of 2 + 4*18 + 6 - 20*8 is calculated by following the order of operations (multiplication...

--- Problem 10/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1534.13it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.48s/it, est. speed input: 4.35 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.48s/it, est. speed input: 4.35 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.49s/it, est. speed input: 4.35 toks/s, output: 25.28 toks/s]
Agent 2 response: Why does the moon reflect the sun's light? The answer is -80....

--- Problem 10/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1548.28it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.74s/it, est. speed input: 4.64 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.74s/it, est. speed input: 4.64 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.74s/it, est. speed input: 4.64 toks/s, output: 25.28 toks/s]
Agent 3 response: Following the order of operations (multiplication before addition/subtraction):  
2 + (4 × 18) + 6 -...

--- Problem 10/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 768.19it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.70s/it, est. speed input: 33.84 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.70s/it, est. speed input: 33.84 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.70s/it, est. speed input: 33.84 toks/s, output: 25.21 toks/s]
Agent 1 response: The calculation follows standard arithmetic rules, prioritizing multiplication before addition and s...

--- Problem 10/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 761.08it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.09s/it, est. speed input: 23.41 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.09s/it, est. speed input: 23.41 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.09s/it, est. speed input: 23.41 toks/s, output: 25.22 toks/s]
Agent 2 response: What is the echo of silence in a thunderstorm? The answer is -80....

--- Problem 10/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 764.13it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.13s/it, est. speed input: 23.17 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.13s/it, est. speed input: 23.17 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.13s/it, est. speed input: 23.17 toks/s, output: 25.21 toks/s]
Agent 3 response: The correct calculation follows the order of operations (multiplication first, then addition/subtrac...

--- Problem 10/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 516.29it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.09s/it, est. speed input: 49.05 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.09s/it, est. speed input: 49.05 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.09s/it, est. speed input: 49.05 toks/s, output: 25.13 toks/s]
Agent 1 response: The calculation adheres strictly to the order of operations (multiplication first, then left-to-righ...

--- Problem 10/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 533.36it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.29s/it, est. speed input: 61.58 toks/s, output: 25.08 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.29s/it, est. speed input: 61.58 toks/s, output: 25.08 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.29s/it, est. speed input: 61.58 toks/s, output: 25.08 toks/s]
Agent 2 response: What is the shadow of a shadow in a cave? The answer is -80....

--- Problem 10/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 515.33it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.86s/it, est. speed input: 43.63 toks/s, output: 25.10 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.86s/it, est. speed input: 43.63 toks/s, output: 25.10 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.86s/it, est. speed input: 43.63 toks/s, output: 25.10 toks/s]
Agent 3 response: The calculation adheres to standard arithmetic rules (multiplication first, then left-to-right addit...
performance: 0.8 0.12649110640673517

--- Problem 11/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 50%|█████     | 10/20 [1:38:36<34:32, 207.24s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1208.04it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.69s/it, est. speed input: 3.76 toks/s, output: 25.24 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.69s/it, est. speed input: 3.76 toks/s, output: 25.24 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.69s/it, est. speed input: 3.76 toks/s, output: 25.24 toks/s]
Agent 1 response: The result is calculated by following the order of operations. First, compute the multiplications: 1...

--- Problem 11/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1360.02it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.59s/it, est. speed input: 5.35 toks/s, output: 25.23 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.59s/it, est. speed input: 5.35 toks/s, output: 25.23 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.59s/it, est. speed input: 5.35 toks/s, output: 25.23 toks/s]
Agent 2 response: The moon reflects the sun's light. A stone cannot be both heavy and light. The result is -270....

--- Problem 11/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1469.62it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 4.10 toks/s, output: 25.24 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 4.10 toks/s, output: 25.24 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 4.10 toks/s, output: 25.24 toks/s]
Agent 3 response: The result of 6 + 17*3 + 24 - 27*13 is calculated as follows:  
1. 17*3 = 51  
2. 27*13 = 351  
3. C...

--- Problem 11/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 674.33it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.50s/it, est. speed input: 25.63 toks/s, output: 25.19 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.50s/it, est. speed input: 25.63 toks/s, output: 25.19 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.50s/it, est. speed input: 25.63 toks/s, output: 25.19 toks/s]
Agent 1 response: The calculation follows the standard order of operations. Multiplying first: 17×3 = 51 and 27×13 = 3...

--- Problem 11/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 750.32it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.71s/it, est. speed input: 23.79 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.71s/it, est. speed input: 23.79 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.71s/it, est. speed input: 23.79 toks/s, output: 25.22 toks/s]
Agent 2 response: The river flows without direction. A shadow has no weight. The result is -270....

--- Problem 11/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 808.77it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.34s/it, est. speed input: 20.01 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.34s/it, est. speed input: 20.01 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.34s/it, est. speed input: 20.01 toks/s, output: 25.20 toks/s]
Agent 3 response: The calculation follows the order of operations:  
1. Multiplications: 17*3 = 51 and 27*13 = 351.  
...

--- Problem 11/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 518.33it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.38s/it, est. speed input: 28.73 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.38s/it, est. speed input: 28.73 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.38s/it, est. speed input: 28.73 toks/s, output: 25.16 toks/s]
Agent 1 response: The calculation adheres to the order of operations. Multiplying first: 17×3 = 51, 27×13 = 351. Subst...

--- Problem 11/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 532.68it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.41s/it, est. speed input: 56.71 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.41s/it, est. speed input: 56.71 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.41s/it, est. speed input: 56.71 toks/s, output: 25.15 toks/s]
Agent 2 response: A bell tolls without a hand to ring it. The mountain does not ask the sky for permission to rise. Th...

--- Problem 11/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 548.28it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.59s/it, est. speed input: 34.64 toks/s, output: 25.17 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.59s/it, est. speed input: 34.64 toks/s, output: 25.17 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.59s/it, est. speed input: 34.64 toks/s, output: 25.17 toks/s]
Agent 3 response: The calculation adheres to the order of operations (multiplication first, then addition/subtraction)...
performance: 0.8181818181818182 0.11629129983033296

--- Problem 12/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 55%|█████▌    | 11/20 [1:41:06<28:28, 189.88s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1465.52it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.22s/it, est. speed input: 6.05 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.22s/it, est. speed input: 6.05 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.22s/it, est. speed input: 6.05 toks/s, output: 25.28 toks/s]
Agent 1 response: Following the order of operations (multiplication before addition/subtraction):  
17 + (25 × 8) + 25...

--- Problem 12/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1499.57it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.29s/it, est. speed input: 4.51 toks/s, output: 25.27 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.29s/it, est. speed input: 4.51 toks/s, output: 25.27 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.29s/it, est. speed input: 4.51 toks/s, output: 25.27 toks/s]
Agent 2 response: What is the sound of one hand clapping?  
The river flows uphill.  
A stone is not a stone.  
222....

--- Problem 12/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1540.32it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.22s/it, est. speed input: 6.14 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.22s/it, est. speed input: 6.14 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.22s/it, est. speed input: 6.14 toks/s, output: 25.28 toks/s]
Agent 3 response: The result of 17 + 25 * 8 + 25 - 20 * 1 is 222....

--- Problem 12/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 861.08it/s]

Agent 1 response: The calculation follows standard arithmetic rules:  
17 + (25 × 8) + 25 - (20 × 1) = 17 + 200 + 25 -...

--- Problem 12/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B
Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.51s/it, est. speed input: 21.24 toks/s, output: 25.24 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.51s/it, est. speed input: 21.24 toks/s, output: 25.24 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.51s/it, est. speed input: 21.24 toks/s, output: 25.24 toks/s]

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 873.45it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.34s/it, est. speed input: 25.67 toks/s, output: 25.23 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.34s/it, est. speed input: 25.67 toks/s, output: 25.23 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.34s/it, est. speed input: 25.67 toks/s, output: 25.23 toks/s]
Agent 2 response: The moon cannot count.  
A bell does not ring in silence.  
The path is not the path.  
222....

--- Problem 12/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 834.69it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.38s/it, est. speed input: 20.02 toks/s, output: 25.24 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.38s/it, est. speed input: 20.02 toks/s, output: 25.24 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.38s/it, est. speed input: 20.02 toks/s, output: 25.24 toks/s]
Agent 3 response: The calculation follows the order of operations: multiplication first, then addition and subtraction...

--- Problem 12/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 636.18it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.18s/it, est. speed input: 30.27 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.18s/it, est. speed input: 30.27 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.18s/it, est. speed input: 30.27 toks/s, output: 25.20 toks/s]
Agent 1 response: The calculation adheres to standard order of operations:  
17 + (25 × 8) + 25 - (20 × 1) = 17 + 200 ...

--- Problem 12/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 630.44it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.57s/it, est. speed input: 38.61 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.57s/it, est. speed input: 38.61 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.57s/it, est. speed input: 38.61 toks/s, output: 25.20 toks/s]
Agent 2 response: The wind does not read.  
A shadow has no weight.  
The question is not the answer.  
222....

--- Problem 12/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 638.99it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.21s/it, est. speed input: 39.44 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.21s/it, est. speed input: 39.44 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.21s/it, est. speed input: 39.44 toks/s, output: 25.21 toks/s]
Agent 3 response: The calculation adheres to standard arithmetic rules (PEMDAS/BODMAS):  
17 + (25 × 8) + 25 - (20 × 1...
performance: 0.8333333333333334 0.1075828707279838

--- Problem 13/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 60%|██████    | 12/20 [1:43:11<22:41, 170.13s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1545.43it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.37s/it, est. speed input: 2.84 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.37s/it, est. speed input: 2.84 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.37s/it, est. speed input: 2.84 toks/s, output: 25.26 toks/s]
Agent 1 response: The result of the expression is calculated by following the order of operations: multiplication firs...

--- Problem 13/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1533.01it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.69s/it, est. speed input: 4.73 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.69s/it, est. speed input: 4.73 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.69s/it, est. speed input: 4.73 toks/s, output: 25.28 toks/s]
Agent 2 response: What is the sound of one hand clapping?  
The moon reflects the sun's light.  
Where does the path e...

--- Problem 13/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1518.03it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.66s/it, est. speed input: 3.35 toks/s, output: 25.29 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.66s/it, est. speed input: 3.35 toks/s, output: 25.29 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.66s/it, est. speed input: 3.35 toks/s, output: 25.29 toks/s]
Agent 3 response: Following the order of operations (PEMDAS/BODMAS):  
1. Calculate multiplications first:  
   - 27 *...

--- Problem 13/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 660.52it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.07s/it, est. speed input: 36.49 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.07s/it, est. speed input: 36.49 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.07s/it, est. speed input: 36.49 toks/s, output: 25.09 toks/s]
Agent 1 response: The calculated result of the expression, adhering strictly to the order of operations, is confirmed ...

--- Problem 13/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 661.25it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.31s/it, est. speed input: 14.89 toks/s, output: 25.10 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.31s/it, est. speed input: 14.89 toks/s, output: 25.10 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.31s/it, est. speed input: 14.89 toks/s, output: 25.10 toks/s]
Agent 2 response: The river flows upward.  
A stone is not a stone.  
What is the shadow of a shadow?  

358....

--- Problem 13/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 640.84it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.65s/it, est. speed input: 17.93 toks/s, output: 25.10 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.65s/it, est. speed input: 17.93 toks/s, output: 25.10 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.65s/it, est. speed input: 17.93 toks/s, output: 25.10 toks/s]
Agent 3 response: The calculation follows standard order of operations (multiplication first, then left-to-right addit...

--- Problem 13/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 471.11it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.24s/it, est. speed input: 46.80 toks/s, output: 25.06 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.24s/it, est. speed input: 46.80 toks/s, output: 25.06 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.24s/it, est. speed input: 46.80 toks/s, output: 25.06 toks/s]
Agent 1 response: The calculation remains consistent with the order of operations: multiplication first, then addition...

--- Problem 13/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 489.36it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.20s/it, est. speed input: 57.89 toks/s, output: 25.08 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.20s/it, est. speed input: 57.89 toks/s, output: 25.08 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.20s/it, est. speed input: 57.89 toks/s, output: 25.08 toks/s]
Agent 2 response: The clock ticks without hands.  
A whisper echoes in the void.  
What is the color of silence?  

35...

--- Problem 13/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 475.28it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.15s/it, est. speed input: 44.37 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.15s/it, est. speed input: 44.37 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.15s/it, est. speed input: 44.37 toks/s, output: 25.13 toks/s]
Agent 3 response: The expression evaluates to **358** through standard arithmetic rules (multiplication first, then le...
performance: 0.8461538461538461 0.10006825162892168

--- Problem 14/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 65%|██████▌   | 13/20 [1:46:16<20:21, 174.44s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1483.66it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.33s/it, est. speed input: 2.61 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.33s/it, est. speed input: 2.61 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.33s/it, est. speed input: 2.61 toks/s, output: 25.28 toks/s]
Agent 1 response: The result of 28 + 7*14 + 2 - 13*16 is calculated by following the order of operations (multiplicati...

--- Problem 14/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1533.57it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.88s/it, est. speed input: 6.57 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.88s/it, est. speed input: 6.57 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.88s/it, est. speed input: 6.57 toks/s, output: 25.26 toks/s]
Agent 2 response: The river flows upstream. Silence holds the echo. The answer is -80....

--- Problem 14/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1533.01it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.44s/it, est. speed input: 3.50 toks/s, output: 25.19 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.44s/it, est. speed input: 3.50 toks/s, output: 25.19 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.44s/it, est. speed input: 3.50 toks/s, output: 25.19 toks/s]
Agent 3 response: The result of 28 + 7*14 + 2 - 13*16 is calculated by following the order of operations (multiplicati...

--- Problem 14/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 677.59it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.64s/it, est. speed input: 25.97 toks/s, output: 25.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.64s/it, est. speed input: 25.97 toks/s, output: 25.00 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.64s/it, est. speed input: 25.97 toks/s, output: 25.00 toks/s]
Agent 1 response: The calculations align with the order of operations (multiplication first, then left-to-right additi...

--- Problem 14/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 679.24it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.47s/it, est. speed input: 34.29 toks/s, output: 25.01 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.47s/it, est. speed input: 34.29 toks/s, output: 25.01 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.48s/it, est. speed input: 34.29 toks/s, output: 25.01 toks/s]
Agent 2 response: The wind does not choose the mountain.  
The moon reflects the sky’s silence.  
The answer is -80....

--- Problem 14/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 682.78it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.10s/it, est. speed input: 22.84 toks/s, output: 25.02 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.10s/it, est. speed input: 22.84 toks/s, output: 25.02 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.10s/it, est. speed input: 22.84 toks/s, output: 25.02 toks/s]
Agent 3 response: The calculation follows standard order of operations:  
1. Multiplication: 7×14 = 98 and 13×16 = 208...

--- Problem 14/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 455.11it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.32s/it, est. speed input: 40.52 toks/s, output: 25.05 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.32s/it, est. speed input: 40.52 toks/s, output: 25.05 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:19<00:00, 19.32s/it, est. speed input: 40.52 toks/s, output: 25.05 toks/s]
Agent 1 response: The calculation adheres to standard mathematical order of operations:  
1. Multiplication: 7×14 = 98...

--- Problem 14/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 478.09it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.72s/it, est. speed input: 67.14 toks/s, output: 25.08 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.72s/it, est. speed input: 67.14 toks/s, output: 25.08 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.72s/it, est. speed input: 67.14 toks/s, output: 25.08 toks/s]
Agent 2 response: The stone does not question the path.  
The flame forgets its own heat.  
The answer is -80....

--- Problem 14/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 470.85it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.59s/it, est. speed input: 42.18 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.59s/it, est. speed input: 42.18 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.59s/it, est. speed input: 42.18 toks/s, output: 25.13 toks/s]
Agent 3 response: The calculation adheres to standard mathematical rules:  
1. **Multiplication first**: 7×14 = 98 and...
performance: 0.8571428571428571 0.09352195295828246

--- Problem 15/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 70%|███████   | 14/20 [1:48:58<17:05, 170.84s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1507.66it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.30s/it, est. speed input: 4.42 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.30s/it, est. speed input: 4.42 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.30s/it, est. speed input: 4.42 toks/s, output: 25.28 toks/s]
Agent 1 response: Following the order of operations (multiplication before addition/subtraction):  
3 + (17 * 7) + 3 -...

--- Problem 15/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1417.95it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.38s/it, est. speed input: 6.14 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.38s/it, est. speed input: 6.14 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.38s/it, est. speed input: 6.14 toks/s, output: 25.28 toks/s]
Agent 2 response: The moon is a stone.  
The stone is a question.  
What is the question?  
96....

--- Problem 15/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1518.57it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.23s/it, est. speed input: 3.28 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.23s/it, est. speed input: 3.28 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:22<00:00, 22.23s/it, est. speed input: 3.28 toks/s, output: 25.28 toks/s]
Agent 3 response: The result of 3 + 17*7 + 3 - 1*29 is calculated by following the order of operations (multiplication...

--- Problem 15/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 740.39it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.17s/it, est. speed input: 31.54 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.17s/it, est. speed input: 31.54 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.17s/it, est. speed input: 31.54 toks/s, output: 25.22 toks/s]
Agent 1 response: The calculation follows standard order of operations, confirming the result is **96**. The poetic an...

--- Problem 15/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 724.78it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.36s/it, est. speed input: 29.04 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.36s/it, est. speed input: 29.04 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.36s/it, est. speed input: 29.04 toks/s, output: 25.22 toks/s]
Agent 2 response: The sky is a clock.  
The clock is a whisper.  
What is the whisper?  
96....

--- Problem 15/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 760.80it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.98s/it, est. speed input: 22.68 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.98s/it, est. speed input: 22.68 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.98s/it, est. speed input: 22.68 toks/s, output: 25.21 toks/s]
Agent 3 response: The calculation follows standard order of operations: multiplication first, then addition/subtractio...

--- Problem 15/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 473.34it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 17.00s/it, est. speed input: 34.89 toks/s, output: 25.18 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 17.00s/it, est. speed input: 34.89 toks/s, output: 25.18 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 17.00s/it, est. speed input: 34.89 toks/s, output: 25.18 toks/s]
Agent 1 response: The mathematical process and poetic metaphors both align with the consistent result of **96**. The c...

--- Problem 15/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 556.64it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.22s/it, est. speed input: 53.22 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.22s/it, est. speed input: 53.22 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.22s/it, est. speed input: 53.22 toks/s, output: 25.14 toks/s]
Agent 2 response: The river is a mirror.  
The mirror reflects the code.  
What is the code?  
96....

--- Problem 15/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 583.03it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.44s/it, est. speed input: 27.71 toks/s, output: 25.09 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.44s/it, est. speed input: 27.71 toks/s, output: 25.09 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.44s/it, est. speed input: 27.71 toks/s, output: 25.09 toks/s]
Agent 3 response: The calculation adheres to standard order of operations, confirming the result is **96**. The poetic...
performance: 0.8666666666666667 0.0877707451472511

--- Problem 16/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 75%|███████▌  | 15/20 [1:51:21<13:32, 162.47s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1490.51it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.35s/it, est. speed input: 2.49 toks/s, output: 25.18 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.35s/it, est. speed input: 2.49 toks/s, output: 25.18 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:29<00:00, 29.35s/it, est. speed input: 2.49 toks/s, output: 25.18 toks/s]
Agent 1 response: The result of 5 + 21*9 + 3 - 21*28 is calculated by following the order of operations (PEMDAS/BODMAS...

--- Problem 16/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1352.13it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.70s/it, est. speed input: 6.07 toks/s, output: 25.21 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.70s/it, est. speed input: 6.07 toks/s, output: 25.21 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.70s/it, est. speed input: 6.07 toks/s, output: 25.21 toks/s]
Agent 2 response: The moon reflects the sun's light, yet remains silent.  
The answer is -391....

--- Problem 16/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1557.48it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it, est. speed input: 3.94 toks/s, output: 25.23 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it, est. speed input: 3.94 toks/s, output: 25.23 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it, est. speed input: 3.94 toks/s, output: 25.23 toks/s]
Agent 3 response: The result of 5 + 21*9 + 3 - 21*28 is calculated as follows:  
21*9 = 189, 21*28 = 588. Substituting...

--- Problem 16/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 733.14it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.50s/it, est. speed input: 33.53 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.50s/it, est. speed input: 33.53 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.50s/it, est. speed input: 33.53 toks/s, output: 25.13 toks/s]
Agent 1 response: The calculation adheres to standard arithmetic rules, prioritizing multiplication before addition/su...

--- Problem 16/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 746.18it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.06s/it, est. speed input: 38.24 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.06s/it, est. speed input: 38.24 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.06s/it, est. speed input: 38.24 toks/s, output: 25.13 toks/s]
Agent 2 response: The river flows to the sea, yet the sea is never full.  
The answer is -391....

--- Problem 16/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 749.52it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.96s/it, est. speed input: 30.09 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.96s/it, est. speed input: 30.09 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.96s/it, est. speed input: 30.09 toks/s, output: 25.14 toks/s]
Agent 3 response: The calculation follows standard order of operations (multiplication before addition/subtraction):  ...

--- Problem 16/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 493.51it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.20s/it, est. speed input: 35.90 toks/s, output: 25.10 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.20s/it, est. speed input: 35.90 toks/s, output: 25.10 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.20s/it, est. speed input: 35.90 toks/s, output: 25.10 toks/s]
Agent 1 response: The arithmetic expression adheres to standard order of operations (multiplication first, then additi...

--- Problem 16/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 489.87it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.40s/it, est. speed input: 77.52 toks/s, output: 25.10 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.40s/it, est. speed input: 77.52 toks/s, output: 25.10 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.40s/it, est. speed input: 77.52 toks/s, output: 25.10 toks/s]
Agent 2 response: The wind does not carry the scent of the mountain.  
The answer is -391....

--- Problem 16/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 446.44it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.27s/it, est. speed input: 35.81 toks/s, output: 25.11 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.27s/it, est. speed input: 35.81 toks/s, output: 25.11 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.27s/it, est. speed input: 35.81 toks/s, output: 25.11 toks/s]
Agent 3 response: The arithmetic follows standard order of operations (multiplication before addition/subtraction):  
...
performance: 0.875 0.08267972847076846

--- Problem 17/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 80%|████████  | 16/20 [1:53:50<10:32, 158.19s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1439.36it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.46s/it, est. speed input: 4.49 toks/s, output: 25.27 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.46s/it, est. speed input: 4.49 toks/s, output: 25.27 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.46s/it, est. speed input: 4.49 toks/s, output: 25.27 toks/s]
Agent 1 response: The result of the expression 17 + 25*11 + 1 - 9*29 is 32.  
Answer: 32....

--- Problem 17/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1521.88it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.04s/it, est. speed input: 3.89 toks/s, output: 25.25 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.04s/it, est. speed input: 3.89 toks/s, output: 25.25 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:20<00:00, 20.04s/it, est. speed input: 3.89 toks/s, output: 25.25 toks/s]
Agent 2 response: The moon does not illuminate the stone. The stone does not ask why. The answer is thirty-two....

--- Problem 17/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1498.50it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.69s/it, est. speed input: 6.42 toks/s, output: 25.24 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.69s/it, est. speed input: 6.42 toks/s, output: 25.24 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.69s/it, est. speed input: 6.42 toks/s, output: 25.24 toks/s]
Agent 3 response: The result is 32....

--- Problem 17/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 992.03it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.83s/it, est. speed input: 20.54 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.83s/it, est. speed input: 20.54 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.83s/it, est. speed input: 20.54 toks/s, output: 25.22 toks/s]
Agent 1 response: The calculation adheres to standard arithmetic rules, confirming the result as 32. The consensus amo...

--- Problem 17/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1011.16it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.85s/it, est. speed input: 12.22 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.85s/it, est. speed input: 12.22 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.85s/it, est. speed input: 12.22 toks/s, output: 25.22 toks/s]
Agent 2 response: The river does not remember the source. The source does not ask for silence. The answer is thirty-tw...

--- Problem 17/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1003.18it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.45s/it, est. speed input: 13.14 toks/s, output: 25.25 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.45s/it, est. speed input: 13.14 toks/s, output: 25.25 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.45s/it, est. speed input: 13.14 toks/s, output: 25.25 toks/s]
Agent 3 response: The result of the expression is 32.  
Answer: 32....

--- Problem 17/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 737.40it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.13s/it, est. speed input: 31.08 toks/s, output: 25.24 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.13s/it, est. speed input: 31.08 toks/s, output: 25.24 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.13s/it, est. speed input: 31.08 toks/s, output: 25.24 toks/s]
Agent 1 response: The consistent consensus among agents and the arithmetic validation reaffirm the result as 32.  
Ans...

--- Problem 17/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 748.45it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.59s/it, est. speed input: 27.80 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.59s/it, est. speed input: 27.80 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.59s/it, est. speed input: 27.80 toks/s, output: 25.26 toks/s]
Agent 2 response: The wind does not measure the mountain. The mountain does not seek the breeze. The answer is thirty-...

--- Problem 17/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 754.24it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.30s/it, est. speed input: 26.08 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.30s/it, est. speed input: 26.08 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.30s/it, est. speed input: 26.08 toks/s, output: 25.26 toks/s]
Agent 3 response: The calculation follows standard arithmetic rules, with multiplication prioritized over addition and...
performance: 0.8823529411764706 0.07814248990059663

--- Problem 18/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 85%|████████▌ | 17/20 [1:55:57<07:26, 148.92s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1556.91it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.71s/it, est. speed input: 4.18 toks/s, output: 25.30 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.71s/it, est. speed input: 4.18 toks/s, output: 25.30 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:17<00:00, 17.71s/it, est. speed input: 4.18 toks/s, output: 25.30 toks/s]
Agent 1 response: The result of the expression is 121....

--- Problem 18/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1498.50it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.87s/it, est. speed input: 4.13 toks/s, output: 25.28 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.87s/it, est. speed input: 4.13 toks/s, output: 25.28 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.87s/it, est. speed input: 4.13 toks/s, output: 25.28 toks/s]
Agent 2 response: The moon reflects the sun's light.  
The sound of one hand clapping.  
A bell without a sound.  
121...

--- Problem 18/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1453.33it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.49s/it, est. speed input: 4.55 toks/s, output: 25.29 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.49s/it, est. speed input: 4.55 toks/s, output: 25.29 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.49s/it, est. speed input: 4.55 toks/s, output: 25.29 toks/s]
Agent 3 response: The calculation follows the order of operations: multiplication first, then addition and subtraction...

--- Problem 18/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 831.05it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.57s/it, est. speed input: 21.41 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.57s/it, est. speed input: 21.41 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.57s/it, est. speed input: 21.41 toks/s, output: 25.26 toks/s]
Agent 1 response: The calculation follows the order of operations: multiplication first, then addition and subtraction...

--- Problem 18/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 810.18it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.22s/it, est. speed input: 23.89 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.22s/it, est. speed input: 23.89 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.22s/it, est. speed input: 23.89 toks/s, output: 25.26 toks/s]
Agent 2 response: The river flows uphill.  
A stone cannot be both smooth and rough.  
121....

--- Problem 18/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 825.00it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.70s/it, est. speed input: 22.85 toks/s, output: 25.26 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.70s/it, est. speed input: 22.85 toks/s, output: 25.26 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.70s/it, est. speed input: 22.85 toks/s, output: 25.26 toks/s]
Agent 3 response: The calculation confirms the result is **121**, as all steps and agent responses align with this val...

--- Problem 18/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 549.71it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.20s/it, est. speed input: 41.00 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.20s/it, est. speed input: 41.00 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.20s/it, est. speed input: 41.00 toks/s, output: 25.15 toks/s]
Agent 1 response: The calculation remains consistent with previous steps:  
1. **13 * 15 = 195**  
2. **7 * 13 = 91** ...

--- Problem 18/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 581.01it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.95s/it, est. speed input: 42.00 toks/s, output: 25.02 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.95s/it, est. speed input: 42.00 toks/s, output: 25.02 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.95s/it, est. speed input: 42.00 toks/s, output: 25.02 toks/s]
Agent 2 response: The wind does not know the shape of the mountain.  
A shadow without a source.  
121....

--- Problem 18/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 566.34it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.08s/it, est. speed input: 52.62 toks/s, output: 25.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.08s/it, est. speed input: 52.62 toks/s, output: 25.00 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.08s/it, est. speed input: 52.62 toks/s, output: 25.00 toks/s]
Agent 3 response: The calculation aligns with the order of operations (multiplication first, then addition/subtraction...
performance: 0.8333333333333334 0.08784104611578833

--- Problem 19/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 90%|█████████ | 18/20 [1:58:11<04:48, 144.38s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1488.40it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.68s/it, est. speed input: 2.62 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.68s/it, est. speed input: 2.62 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:28<00:00, 28.68s/it, est. speed input: 2.62 toks/s, output: 25.14 toks/s]
Agent 1 response: The result of 22 + 27*24 + 29 - 7*20 is calculated by following the order of operations (multiplicat...

--- Problem 19/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1479.47it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.19s/it, est. speed input: 5.99 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.19s/it, est. speed input: 5.99 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.19s/it, est. speed input: 5.99 toks/s, output: 25.16 toks/s]
Agent 2 response: The moon reflects the sun's light.  
A stone cannot sing.  
The answer is 559....

--- Problem 19/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1519.12it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.92s/it, est. speed input: 3.05 toks/s, output: 25.20 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.92s/it, est. speed input: 3.05 toks/s, output: 25.20 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.92s/it, est. speed input: 3.05 toks/s, output: 25.20 toks/s]
Agent 3 response: The result of 22 + 27*24 + 29 - 7*20 is calculated as follows: first, perform the multiplications (2...

--- Problem 19/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 719.06it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.25s/it, est. speed input: 35.27 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.25s/it, est. speed input: 35.27 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:12<00:00, 12.25s/it, est. speed input: 35.27 toks/s, output: 25.14 toks/s]
Agent 1 response: The calculation confirms the result is 559, as verified by both the order of operations and prior ag...

--- Problem 19/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 715.75it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.47s/it, est. speed input: 41.65 toks/s, output: 25.12 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.47s/it, est. speed input: 41.65 toks/s, output: 25.12 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.47s/it, est. speed input: 41.65 toks/s, output: 25.12 toks/s]
Agent 2 response: The river flows uphill.  
A shadow has no weight.  
The answer is 559....

--- Problem 19/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 722.28it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.43s/it, est. speed input: 28.07 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.43s/it, est. speed input: 28.07 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.43s/it, est. speed input: 28.07 toks/s, output: 25.15 toks/s]
Agent 3 response: The calculation follows standard order of operations: multiplication first (27*24 = 648; 7*20 = 140)...

--- Problem 19/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 542.60it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.52s/it, est. speed input: 41.89 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.52s/it, est. speed input: 41.89 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.52s/it, est. speed input: 41.89 toks/s, output: 25.13 toks/s]
Agent 1 response: The calculation adheres to standard mathematical rules (multiplication first, then sequential additi...

--- Problem 19/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 537.11it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.03s/it, est. speed input: 40.79 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.03s/it, est. speed input: 40.79 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.03s/it, est. speed input: 40.79 toks/s, output: 25.14 toks/s]
Agent 2 response: The mountain wears a crown of clouds.  
Even silence has a heartbeat.  
The answer is 559....

--- Problem 19/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 549.86it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.76s/it, est. speed input: 44.10 toks/s, output: 25.13 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.76s/it, est. speed input: 44.10 toks/s, output: 25.13 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.76s/it, est. speed input: 44.10 toks/s, output: 25.13 toks/s]
Agent 3 response: The calculation adheres to the order of operations: multiplication (27*24 = 648; 7*20 = 140) first, ...
performance: 0.8421052631578947 0.08365467518305539

--- Problem 20/20, Round 1, Agent 1/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B
 95%|█████████▌| 19/20 [2:00:42<02:26, 146.45s/it]
Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1463.98it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.31s/it, est. speed input: 3.13 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.31s/it, est. speed input: 3.13 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.31s/it, est. speed input: 3.13 toks/s, output: 25.22 toks/s]
Agent 1 response: The result of 15 + 12*17 + 14 - 20*23 is calculated by following the order of operations (multiplica...

--- Problem 20/20, Round 1, Agent 2/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1531.33it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.89s/it, est. speed input: 5.03 toks/s, output: 25.23 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.89s/it, est. speed input: 5.03 toks/s, output: 25.23 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:15<00:00, 15.89s/it, est. speed input: 5.03 toks/s, output: 25.23 toks/s]
Agent 2 response: Clouds in the sky, water in the jar.  
-227...

--- Problem 20/20, Round 1, Agent 3/3 ---
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 1452.82it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.61s/it, est. speed input: 3.56 toks/s, output: 25.22 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.61s/it, est. speed input: 3.56 toks/s, output: 25.22 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.61s/it, est. speed input: 3.56 toks/s, output: 25.22 toks/s]
Agent 3 response: The result of 15 + 12*17 + 14 - 20*23 is calculated as follows:  
1. Multiply 12*17 = 204 and 20*23 ...

--- Problem 20/20, Round 2, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 757.37it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.68s/it, est. speed input: 21.09 toks/s, output: 25.16 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.68s/it, est. speed input: 21.09 toks/s, output: 25.16 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.68s/it, est. speed input: 21.09 toks/s, output: 25.16 toks/s]
Agent 1 response: The calculation follows the order of operations: multiply first (12*17=204, 20*23=460), then combine...

--- Problem 20/20, Round 2, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 764.55it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.92s/it, est. speed input: 14.78 toks/s, output: 25.15 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.92s/it, est. speed input: 14.78 toks/s, output: 25.15 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:26<00:00, 26.92s/it, est. speed input: 14.78 toks/s, output: 25.15 toks/s]
Agent 2 response: The wind whispers numbers.  
The answer is -227....

--- Problem 20/20, Round 2, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 745.65it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 21.58 toks/s, output: 25.14 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 21.58 toks/s, output: 25.14 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it, est. speed input: 21.58 toks/s, output: 25.14 toks/s]
Agent 3 response: The calculation adheres to standard arithmetic rules (multiplication before addition/subtraction):  ...

--- Problem 20/20, Round 3, Agent 1/3 ---
Agent 1 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 529.18it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.45s/it, est. speed input: 31.47 toks/s, output: 25.04 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.45s/it, est. speed input: 31.47 toks/s, output: 25.04 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.45s/it, est. speed input: 31.47 toks/s, output: 25.04 toks/s]
Agent 1 response: The calculation adheres to standard arithmetic rules (multiplication before addition/subtraction):  ...

--- Problem 20/20, Round 3, Agent 2/3 ---
Agent 2 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 530.66it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.22s/it, est. speed input: 47.74 toks/s, output: 25.03 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.22s/it, est. speed input: 47.74 toks/s, output: 25.03 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.22s/it, est. speed input: 47.74 toks/s, output: 25.03 toks/s]
Agent 2 response: The river flows, the stone remains.  
The answer is -227....

--- Problem 20/20, Round 3, Agent 3/3 ---
Agent 3 receiving other agents' responses...
[ModelCache] Using cached model: Qwen/Qwen3-14B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|██████████| 1/1 [00:00<00:00, 538.70it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.38s/it, est. speed input: 36.79 toks/s, output: 25.03 toks/s][A
Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.38s/it, est. speed input: 36.79 toks/s, output: 25.03 toks/s][AProcessed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.38s/it, est. speed input: 36.79 toks/s, output: 25.03 toks/s]
100%|██████████| 20/20 [2:03:42<00:00, 156.46s/it]100%|██████████| 20/20 [2:03:42<00:00, 371.12s/it]
[rank0]:[W1204 11:32:55.757719882 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Agent 3 response: The calculation follows the standard order of operations, prioritizing multiplication before additio...
performance: 0.85 0.07984359711335655
============================================================
Results saved to: /home/ch269957/projects/slm_multiagent_debate/experiments/linux_single/results/math/math_Qwen3-14B_persona_enigma+zen+deep-sea_agents3_rounds3.p
Final performance: 0.850 ± 0.080
============================================================
[ModelCache] Shut down vLLM model: vllm:Qwen/Qwen3-14B
[ModelCache] All models shut down
